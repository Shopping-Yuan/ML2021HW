{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0NHRBly71SRtdCFsbqzIB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML2021HW/blob/Shopping_branch/ML2021HW1_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pytorch Setting:"
      ],
      "metadata": {
        "id": "qaaQpqayiLbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "8mZwtss3iFBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be29f715-d464-4114-eb60-cb666e4a9c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "#import pytorch\n",
        "import torch\n",
        "\n",
        "# torch.backends.cudnn: set CNN algorithmtorch.backends.cudnn\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# get the current available device ('cpu' or 'cuda')\n",
        "def get_device():\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = get_device()\n",
        "print(torch.cuda.is_available())\n",
        "device = get_device()\n",
        "\n",
        "#set random variable\n",
        "import numpy as np\n",
        "myseed = 1\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Set"
      ],
      "metadata": {
        "id": "EvBtNdcmjKTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write data_set_function\n",
        "#normalize data if needed\n",
        "def normalize(df):\n",
        "    return ((df - df.mean(axis = 0)) / (df.std(axis = 0)))\n",
        "# generate index_list for spliting train & validation set\n",
        "def got_index(df,mode):\n",
        "    index_list = []\n",
        "    first_day = 0\n",
        "    for i in range(df.shape[1]):\n",
        "      #count total data in that catetory\n",
        "      days = df.iloc[:,i].sum()\n",
        "\n",
        "      last_day = int(first_day + days-1)\n",
        "      split_day = int(first_day + days*0.9)\n",
        "\n",
        "      if mode == \"train\":\n",
        "        index_list += list(range(first_day,split_day+1))\n",
        "      elif mode == \"val\":\n",
        "        index_list += list(range(split_day+1,last_day+1))\n",
        "\n",
        "      first_day = last_day+1\n",
        "    return index_list\n",
        "\n",
        "#split train & validation set by index\n",
        "def covid19_train_val_f(mode,d_l = \"both\"):\n",
        "    train__val_df = pd.read_csv(data_info[mode][\"path\"])\n",
        "    print('Size of training data: {}'.format(train__val_df.shape))\n",
        "\n",
        "    train__val_df.iloc[:,41:] = normalize(train__val_df.iloc[:,41:])\n",
        "\n",
        "    index_list = got_index(train__val_df.iloc[:,1:41],mode)\n",
        "    train__val_df = train__val_df.iloc[ index_list,1:]\n",
        "    label = torch.FloatTensor(train__val_df.iloc[:, -1].to_numpy())\n",
        "    data = torch.FloatTensor(train__val_df.iloc[:, 0:-1].to_numpy())\n",
        "    return({\"data\":data , \"label\":label})\n",
        "\n",
        "def covid19_test_f(mode,d_l = \"data\"):\n",
        "    test_df = pd.read_csv(data_info[mode][\"path\"])\n",
        "    print('Size of testing data: {}'.format(test_df.shape))\n",
        "    test_df.iloc[:,40:] = normalize(test_df.iloc[:,40:])\n",
        "    data = torch.FloatTensor(test_df.to_numpy())\n",
        "    return(data)\n",
        "#create a dict of functions and path w.r.t. different mode\n",
        "data_info = {\n",
        "    \"train\":{\"function\":covid19_train_val_f,\"path\":\"./covid.train.csv\",\"data_or_label\":\"both\"},\n",
        "    \"val\":{\"function\":covid19_train_val_f,\"path\":\"./covid.train.csv\",\"data_or_label\":\"both\"},\n",
        "    \"test\":{\"function\":covid19_test_f,\"path\":\"./covid.test.csv\",\"data_or_label\":\"data\"}\n",
        "}"
      ],
      "metadata": {
        "id": "gWBDrmbiU5Ce"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite class Dataset\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Dataset_preparation(Dataset):\n",
        "  def __init__(self,mode,data_info):\n",
        "      self.mode = mode\n",
        "      self.data_or_label = data_info[mode][\"data_or_label\"]\n",
        "\n",
        "      if self.data_or_label == \"data\":\n",
        "        self.data = data_info[self.mode][\"function\"](self.mode,\"data\")\n",
        "      elif self.data_or_label == \"both\":\n",
        "        self.data = data_info[self.mode][\"function\"](self.mode,\"both\")[\"data\"]\n",
        "        self.label = data_info[self.mode][\"function\"](self.mode,\"both\")[\"label\"]\n",
        "      else :\n",
        "        self.label = data_info[self.mode][\"function\"](self.mode,\"label\")[\"label\"]\n",
        "\n",
        "      self.dim = self.data.shape[0]\n",
        "      print('Finished reading the {mode} set of Dataset ({len} samples found, each dim = {dim})'\n",
        "              .format(mode = self.mode, len =len(self.data), dim=self.dim))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      if self.data_or_label == \"data\":\n",
        "        return self.data[index]\n",
        "      elif self.data_or_label == \"both\":\n",
        "        return self.data[index], self.label[index]\n",
        "      else :\n",
        "        return self.label[index]\n",
        "  def __len__(self):\n",
        "      # Returns the size of the dataset\n",
        "      return len(self.data)"
      ],
      "metadata": {
        "id": "O_5yInY7LWzF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decide how to load data\n",
        "def prep_dataloader(mode,d_info,batch_size,n_jobs=0):\n",
        "    dataset = Dataset_preparation(mode,d_info)\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=False)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "pPAPaENVnMqE"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Sigmoid\n",
        "import torch.nn as nn\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            )\n",
        "\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "\n",
        "        return self.criterion(pred, target)"
      ],
      "metadata": {
        "id": "8D3Drze8Fi2s"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([5.0])\n",
        "model = NeuralNet(1)\n",
        "model_d = model.to(device)\n",
        "print(model_d(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fh9DHrQ9JK-",
        "outputId": "ffd80adc-9535-408d-d8d8-b9362f7b5ed8"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3131], grad_fn=<AddBackward0>)\n",
            "tensor([-0.3131], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_paras = {\n",
        "    # maximum number of epochs\n",
        "    'n_epochs': 3000,\n",
        "    # mini-batch size for dataloader\n",
        "    'batch_size': 270,\n",
        "    # optimization algorithm (optimizer in torch.optim)\n",
        "    'optimizer': 'SGD',\n",
        "    # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "    'optim_hparas': {\n",
        "        # learning rate of SGD\n",
        "        'lr': 0.001,\n",
        "        # momentum for SGD\n",
        "        'momentum': 0.9\n",
        "    },\n",
        "    # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'early_stop': 200,\n",
        "    # if loss small than this , early-stopping counter will reset(may update in validation process)\n",
        "    'early_stop_loss_init': 100.0,\n",
        "    # your model will be saved here\n",
        "    'save_path': './model.pth'\n",
        "}"
      ],
      "metadata": {
        "id": "qNHqYt34ZP5y"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_set,model_d,device):\n",
        "    # set model to training mode\n",
        "    model_d.train()\n",
        "    # iterate through the dataloader\n",
        "    for data , label in train_set:\n",
        "      # move data to device (cpu/cuda)\n",
        "      data , label = data.to(device), label.to(device)\n",
        "      # forward pass (compute output tensor)\n",
        "      pred = 100 * Sigmoid(model_d(data))\n",
        "      # compute loss\n",
        "      mse_loss = model_d.cal_loss(pred , label)\n",
        "      # set optimizer gradient to zero\n",
        "      optimizer.zero_grad()\n",
        "      # compute gradient (backpropagation)\n",
        "      mse_loss.backward()\n",
        "      # update model with optimizer\n",
        "      optimizer.step()\n",
        "      return mse_loss.item()"
      ],
      "metadata": {
        "id": "6jcKe6kSdIPE"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(val_set,model_d,device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    # iterate through the dataloader\n",
        "    for data , label in val_set:\n",
        "    # move data to device (cpu/cuda)\n",
        "      data_d, label_d = data.to(device), label.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = 100 * Sigmoid(model_d(data_d))\n",
        "        # compute loss\n",
        "        mse_loss = model_d.cal_loss(pred, label_d)\n",
        "      # accumulate loss\n",
        "      batch_size = len(data_d)\n",
        "      total_loss += mse_loss.item() * batch_size\n",
        "    # compute averaged loss\n",
        "    totol_size = len(val_set.dataset)\n",
        "    avg_loss =  total_loss/totol_size\n",
        "\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "zFMoWlxkc89K"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_set, model_d, device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "    preds = []\n",
        "    # iterate through the dataloader\n",
        "    for data in test_set:\n",
        "      # move data to device (cpu/cuda)\n",
        "      data_d = data.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = model_d(data_d)\n",
        "        # collect prediction\n",
        "        preds.append(pred.detach().cpu())\n",
        "    # concatenate all predictions and convert to a numpy array\n",
        "    preds = torch.cat(preds, dim=0).numpy()\n",
        "    return preds"
      ],
      "metadata": {
        "id": "DgYuELvCitWh"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_process(training_set, validation_set, model, h_paras, device):\n",
        "    #1: move model to device (cpu/cuda)\n",
        "    model_d = model.to(device)\n",
        "    #2: set optimizer = torch.optim.SGD(model_d.parameters(),lr=0.001,momentum=0.9)\n",
        "    optimizer = getattr(torch.optim, h_paras['optimizer'])(\n",
        "        model.parameters(), **h_paras['optim_hparas'])\n",
        "\n",
        "    #3: set epoch = h_paras['n_epochs'] = 3000\n",
        "    n_epochs = h_paras['n_epochs']\n",
        "\n",
        "    #4: record training loss\n",
        "    loss_record = {'train': [], \"val\": []}\n",
        "\n",
        "    #5: setting paras\n",
        "    # epoch para\n",
        "    epoch = 0\n",
        "    # early-stoping paras\n",
        "    early_stop_cnt = 0\n",
        "    min_loss = h_paras[\"early_stop_loss_init\"]\n",
        "\n",
        "    #start training\n",
        "    while epoch < n_epochs:\n",
        "\n",
        "      # Part1 : training process\n",
        "      # updata model weight and compute model loss\n",
        "      train_loss = train(training_set,model_d,device)\n",
        "      # save loss to loss_record['train']\n",
        "      loss_record['train'].append(train_loss)\n",
        "      # renew epoch para\n",
        "      epoch += 1\n",
        "\n",
        "      # Part2 validation process\n",
        "      # After each epoch, test your model\n",
        "      # on the validation (development) set.\n",
        "      val_loss = val(validation_set, model_d, device)\n",
        "      # save loss to loss_record[\"val\"]\n",
        "      loss_record[\"val\"].append(val_loss)\n",
        "\n",
        "      # Part3 early stopping\n",
        "      # Compute early-stopping counter\n",
        "      if val_loss < min_loss:\n",
        "        min_loss = val_loss\n",
        "        print('Saving model (epoch = {:4d}, loss = {:.4f})'\\\n",
        "        .format(epoch+1 , min_loss))\n",
        "      # Save model to specified path if your model improved\n",
        "        torch.save(model_d.state_dict(), h_paras['save_path'])\n",
        "        early_stop_cnt = 0\n",
        "      else:\n",
        "        early_stop_cnt += 1\n",
        "      # Check early stop criteria\n",
        "      if early_stop_cnt > h_paras['early_stop']:\n",
        "          # Stop training if your model stops improving\n",
        "          # for \"h_paras['early_stop']\" epochs.\n",
        "          break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_loss, loss_record"
      ],
      "metadata": {
        "id": "iuUnrvH7L9CG"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = prep_dataloader('train',data_info,h_paras['batch_size'])\n",
        "val_set = prep_dataloader('val',data_info,h_paras['batch_size'])\n",
        "test_set = prep_dataloader('test',data_info,h_paras['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KsKJk5fk32z",
        "outputId": "5880cca8-495d-466a-ecf1-1812011beff2"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data: (2700, 95)\n",
            "Size of training data: (2700, 95)\n",
            "Finished reading the train set of Dataset (2460 samples found, each dim = 2460)\n",
            "Size of training data: (2700, 95)\n",
            "Size of training data: (2700, 95)\n",
            "Finished reading the val set of Dataset (240 samples found, each dim = 240)\n",
            "Size of testing data: (893, 94)\n",
            "Finished reading the test set of Dataset (893 samples found, each dim = 893)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = NeuralNet(train_set.dataset.dim)\n",
        "# model_d = model.to(device)\n",
        "# optimizer = torch.optim.SGD(model_d.parameters(),lr = 0.001,momentum=0.9)\n",
        "# print(optimizer)"
      ],
      "metadata": {
        "id": "UUCsUXhiuGtq"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct model\n",
        "model = NeuralNet(train_set.dataset.dim)\n",
        "model_loss, model_loss_record = train_val_process(train_set, val_set, model, h_paras, device)"
      ],
      "metadata": {
        "id": "5alEFp4OMMuj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "2d0b6f07-bb6a-41bf-ef4e-00c6ad572830"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-a8294993e586>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Construct model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_loss_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_paras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-127-ca935aa2d8b5>\u001b[0m in \u001b[0;36mtrain_val_process\u001b[0;34m(training_set, validation_set, model, h_paras, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;31m# Part1 : training process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# updata model weight and compute model loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0;31m# save loss to loss_record['train']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mloss_record\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-1332888d3a0e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, model_d, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# forward pass (compute output tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-152-8c9faf6fd9ee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (270x93 and 2460x64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pred(preds, file):\n",
        "    print('Saving results to {}'.format(file))\n",
        "    # with open(file, 'w') as fp:\n",
        "    #     writer = csv.writer(fp)\n",
        "    #     writer.writerow(['id', 'tested_positive'])\n",
        "    #     for i, p in enumerate(preds):\n",
        "    #         writer.writerow([i, p])\n",
        "\n",
        "preds = test(test_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "metadata": {
        "id": "JcymugDXMZ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "model_loading = torch.load(h_paras['save_path'], map_location=device)  # Load your best model\n",
        "model.load_state_dict(model_loading)"
      ],
      "metadata": {
        "id": "RGl3nIhF6aBG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}