{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN1OBinRxY/dowyahbe6XDA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML2021HW/blob/main/ML2021HW1_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch 設置:\n",
        "torch.backends.cudnn 設定捲積的優化方式，無捲積層故關閉。"
      ],
      "metadata": {
        "id": "qaaQpqayiLbl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8mZwtss3iFBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e976e5-f519-4d2c-af6b-46de0709e9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "#import pytorch and set CNN algorithm\n",
        "import torch\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "def get_device():\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = get_device()\n",
        "print(torch.cuda.is_available())\n",
        "#set random variable\n",
        "import numpy as np\n",
        "myseed = 1\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite class Dataset\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class my_Dataset(Dataset):\n",
        "  def __init__(self,name,mode,data_set_function):\n",
        "    self.mode = mode\n",
        "    self.name = name\n",
        "    if self.mode == 'test':\n",
        "      self.data = torch.FloatTensor(data_set_function())\n",
        "    else:\n",
        "      self.data = torch.FloatTensor(data_set_function(mode)[\"data\"])\n",
        "      self.label = torch.LongTensor(data_set_function(mode)[\"label\"])\n",
        "\n",
        "    self.dim = self.data.shape[0]\n",
        "    print('Finished reading the {mode} set of {name} Dataset ({len} samples found, each dim = {dim})'\n",
        "            .format(mode = self.mode, name = self.name, len =len(self.data), dim=self.dim))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      if self.mode in ['train', 'val']:\n",
        "          return self.data[index], self.label[index]\n",
        "      else:\n",
        "          return self.data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)"
      ],
      "metadata": {
        "id": "O_5yInY7LWzF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write data_set_function\n",
        "train_path = \"./covid.train.csv\"\n",
        "test_path = \"./covid.test.csv\"\n",
        "def normalize(df):\n",
        "    return ((df - df.mean(axis = 0)) / (df.std(axis = 0)))\n",
        "def covid19_train_dev_f(mode):\n",
        "    train = pd.read_csv(train_path)\n",
        "    print('Size of training data: {}'.format(train.shape))\n",
        "    train.iloc[:,40:] = normalize(train.iloc[:,40:])\n",
        "    if mode == 'train':\n",
        "      train = train.iloc[ lambda x : (x+1).index % 67 <= 60]\n",
        "    elif mode == 'dev':\n",
        "      train = train.iloc[ lambda x : (x+1).index % 67 > 60]\n",
        "    label = train[:, -1]\n",
        "    data = train[:, 0:-1]\n",
        "    return({\"data\":data,\"label\":label})\n",
        "def covid19_test_f():\n",
        "    test = pd.read_csv(test_path)\n",
        "    print('Size of testing data: {}'.format(test.shape))\n",
        "    test.iloc[:,40:] = normalize(test.iloc[:,40:])\n",
        "    return(test)\n",
        "\n",
        "\n",
        "#decide how to load data\n",
        "def prep_dataloader(path, mode, batch_size, name , data_set_function , n_jobs=0,):\n",
        "    dataset = my_Dataset(path, name ,mode,data_set_function)\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "gWBDrmbiU5Ce"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# df = pd.DataFrame([[1,2],[3,4]])\n",
        "# print(df)\n",
        "# print(df.mean(axis = 0))\n",
        "# print(df - df.mean(axis = 0))\n",
        "# print(df - df.std(axis = 0))\n",
        "# print((df - df.mean(axis = 0)) / (df.std(axis = 0)))\n",
        "# df.iloc[:,1] = normalize(df.iloc[:,1])\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "EWdzDfwzXHrX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(train_path)\n",
        "train.iloc[:,40:] = normalize(train.iloc[:,40:])\n",
        "#print(train.shape,train.iloc[:,40:])\n",
        "train = train.iloc[ lambda x : (x+1).index % 67 <= 60]\n",
        "print(train.shape,train.iloc[:,40:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2vrhdBip7t5",
        "outputId": "1eb7bc53-ea59-4bd5-dc8d-de42a39393aa"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2460, 95)             WI       cli       ili  hh_cmnty_cli  nohh_cmnty_cli  \\\n",
            "0    -0.160706 -0.421079 -0.577816     -0.417165       -0.364755   \n",
            "1    -0.160706 -0.363059 -0.491867     -0.413845       -0.360231   \n",
            "2    -0.160706 -0.223143 -0.302724     -0.371899       -0.333764   \n",
            "3    -0.160706 -0.044600 -0.119538     -0.405599       -0.391493   \n",
            "4    -0.160706 -0.086325 -0.125244     -0.384383       -0.400303   \n",
            "...        ...       ...       ...           ...             ...   \n",
            "2695  6.220253 -0.798876 -0.840734     -0.459341       -0.456289   \n",
            "2696  6.220253 -0.935617 -0.976287     -0.455592       -0.422246   \n",
            "2697  6.220253 -0.963310 -0.988074     -0.458702       -0.420618   \n",
            "2698  6.220253 -0.987764 -0.993377     -0.531688       -0.490941   \n",
            "2699  6.220253 -1.021095 -1.046119     -0.596259       -0.552703   \n",
            "\n",
            "      wearing_mask  travel_outside_state  work_outside_home      shop  \\\n",
            "0        -0.936361              1.341933           0.977202  1.737093   \n",
            "1        -1.055204              1.343473           1.001152  1.776766   \n",
            "2        -0.974661              1.217415           0.958796  1.581422   \n",
            "3        -1.031305              1.083262           0.956247  1.490828   \n",
            "4        -1.056945              1.188056           1.077577  1.511227   \n",
            "...            ...                   ...                ...       ...   \n",
            "2695      0.247105             -0.614743           0.207729 -1.107280   \n",
            "2696      0.185824             -0.511785           0.392634 -1.154861   \n",
            "2697      0.220032             -0.598494           0.457648 -1.160468   \n",
            "2698      0.216319             -0.600178           0.452246 -1.191366   \n",
            "2699      0.231659             -0.661448           0.429968 -1.153442   \n",
            "\n",
            "      restaurant  ...  restaurant.2  spent_time.2  large_event.2  \\\n",
            "0       1.259734  ...      1.280017      1.105229       1.257730   \n",
            "1       1.233936  ...      1.257114      1.070052       1.251725   \n",
            "2       1.255728  ...      1.241368      1.094978       1.259532   \n",
            "3       1.232894  ...      1.061420      1.033728       1.128170   \n",
            "4       1.217194  ...      0.975504      1.084273       1.057811   \n",
            "...          ...  ...           ...           ...            ...   \n",
            "2695   -0.265644  ...     -0.263320     -0.786716      -0.513831   \n",
            "2696   -0.217257  ...     -0.318322     -0.820091      -0.534045   \n",
            "2697   -0.283008  ...     -0.286151     -0.823382      -0.536333   \n",
            "2698   -0.337847  ...     -0.348346     -0.849557      -0.548305   \n",
            "2699   -0.305771  ...     -0.374096     -0.842225      -0.547244   \n",
            "\n",
            "      public_transit.2  anxious.2  depressed.2  felt_isolated.2  \\\n",
            "0            -0.743581  -1.181373    -0.595693        -0.938286   \n",
            "1            -0.706333  -1.261098    -0.767401        -1.010328   \n",
            "2            -0.672473  -1.044597    -0.431607        -1.096609   \n",
            "3            -0.766945  -1.231949    -0.516217        -1.180716   \n",
            "4            -0.706519  -1.461651    -0.393943        -1.147953   \n",
            "...                ...        ...          ...              ...   \n",
            "2695         -0.594068  -1.533310    -1.163962        -0.184840   \n",
            "2696         -0.574474  -1.579595    -1.091489        -0.259769   \n",
            "2697         -0.440497  -1.736224    -1.163770        -0.199650   \n",
            "2698         -0.373315  -1.625812    -1.061365        -0.040093   \n",
            "2699         -0.398492  -1.533827    -0.943181         0.019403   \n",
            "\n",
            "      worried_become_ill.2  worried_finances.2  tested_positive.2  \n",
            "0                -1.743184           -0.184290           0.560895  \n",
            "1                -1.711999           -0.363659           0.638064  \n",
            "2                -1.800174           -0.305049           0.621493  \n",
            "3                -1.991626           -0.317462           0.454806  \n",
            "4                -1.973283           -0.238235           0.491793  \n",
            "...                    ...                 ...                ...  \n",
            "2695              0.512916           -1.079549          -0.449175  \n",
            "2696              0.485757           -1.021438          -0.486346  \n",
            "2697              0.465726           -1.113868          -0.501071  \n",
            "2698              0.476005           -1.141682          -0.518949  \n",
            "2699              0.554618           -1.168690          -0.606293  \n",
            "\n",
            "[2460 rows x 55 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = my_Dataset(\"Covid19\",\"train\",covid19_train_dev_f)\n",
        "print(train_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "gqTAN27IhfMA",
        "outputId": "157681ae-03b9-4fdb-8b5a-9fb62003c76b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data: (2700, 95)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), -1)' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-fb1523997a98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Covid19\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcovid19_train_dev_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-3f3d9da7a023>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, data_set_function)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-f0c901041429>\u001b[0m in \u001b[0;36mcovid19_train_dev_f\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m67\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3807\u001b[0m                 \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5923\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5924\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5925\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5927\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), -1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import Sigmoid\n",
        "import torch.nn as nn\n",
        "class Multiply100Layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Multiply100Layer, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 100.0*x\n",
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid(),\n",
        "            Multiply100Layer(),\n",
        "        )\n",
        "\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return model(x)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "\n",
        "        return self.criterion(pred, target)"
      ],
      "metadata": {
        "id": "8D3Drze8Fi2s"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "metadata": {
        "id": "iuUnrvH7L9CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "fIelUG-ZL_t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "metadata": {
        "id": "6BtHDzFzMCQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "metadata": {
        "id": "QuZEfeW1MH-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = False                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 3000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.001,                 # learning rate of SGD\n",
        "        'momentum': 0.9              # momentum for SGD\n",
        "    },\n",
        "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "metadata": {
        "id": "HW5oRVrrME6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device\n",
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)\n",
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)"
      ],
      "metadata": {
        "id": "5alEFp4OMMuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "metadata": {
        "id": "JcymugDXMZ4T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}