{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML2021HW/blob/Shopping_vscode_branch/HW5/HW05_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "###Part 0 setting and installing package\n",
        "------\n",
        "###Part 1 preparing data set\n",
        "------\n",
        "######load data file\n",
        "######clean data\n",
        "######pick up line pairs\n",
        "######tokenize : using sentencepiece\n",
        "######make data set\n",
        "------\n",
        "###Part 2 make model\n",
        "------\n",
        "######positional encoding layer\n",
        "######multihead attention layer\n",
        "######encoder layer(s)\n",
        "######decoder layer(s)\n",
        "######transformer layer\n",
        "------\n",
        "###Part 3 training and validation process\n",
        "------\n",
        "######Noam optimizer\n",
        "######label smoothing\n",
        "######beam search\n",
        "######bleu\n",
        "######training and validation function\n",
        "######main function\n",
        "------\n"
      ],
      "metadata": {
        "id": "WTv4XN2qB_fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting\n",
        "======\n",
        ">Here are all parameters using in this project."
      ],
      "metadata": {
        "id": "iVQ2D_mLcx4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setting = {\n",
        "# information of the path of dataset\n",
        "\"data_info\" : {\n",
        "    \"drive_path\":\"/content/drive\",\n",
        "    \"document\":\"/content/drive/MyDrive\",\n",
        "    \"raw_file_name\":\"/ted2020.tgz\",\n",
        "    \"unzip_path\":\"/train_dev/\",\n",
        "    \"source\":{\n",
        "        \"lang\":\"en\",\n",
        "        \"raw_data_path\":\"/train_dev/raw.en\",\n",
        "        \"clean_data_path\":\"/train_dev/clean_en.txt\",\n",
        "        \"tokenized_train_data\":\"/train_dev/tokenized_train_data_en.txt\",\n",
        "        \"tokenized_val_data\":\"/train_dev/tokenized_val_data_en.txt\"\n",
        "        },\n",
        "    \"target\":{\n",
        "        \"lang\":\"zh\",\n",
        "        \"raw_data_path\":\"/train_dev/raw.zh\",\n",
        "        \"clean_data_path\":\"/train_dev/clean_zh.txt\",\n",
        "        \"tokenized_train_data\":\"/train_dev/tokenized_train_data_zh.txt\",\n",
        "        \"tokenized_val_data\":\"/train_dev/tokenized_val_data_zh.txt\"\n",
        "        }\n",
        "},\n",
        "# tokenized setting for spm\n",
        "\"tokenized_setting\" : {\n",
        "    \"vocab_size\" : 8000,\n",
        "    \"character_coverage\" : 1,\n",
        "    \"model_type\" : \"bpe\", # \"unigram\",\n",
        "    \"input_sentence_size\" : 400000,\n",
        "    \"shuffle_input_sentence\" : True,\n",
        "    \"normalization_rule_name\" : \"nmt_nfkc_cf\",\n",
        "    \"pad_id\":0,\n",
        "    \"unk_id\":1,\n",
        "    \"bos_id\":2,\n",
        "    \"eos_id\":3,\n",
        "    \"max_l\":400\n",
        "},\n",
        "# model structure setting\n",
        "\"model\" : {\n",
        "      \"encoder_embedding_dimension\" : 256,\n",
        "      \"decoder_embedding_dimension\" : 256,\n",
        "      \"feedforward_dimension\" : 2048,\n",
        "      \"num_heads\" : 2,\n",
        "      \"dropout_p\" : 0.0,\n",
        "      \"layer_num\" : 6\n",
        "},\n",
        "\n",
        "# setting in training and validation process ,\n",
        "# including optimization setting.\n",
        "\"training_hparas\" : {\n",
        "    \"total_step\" : 40000,\n",
        "    \"do_valid_step\" : 4000,\n",
        "    \"early_stop_step\" : 2,\n",
        "    \"train_batch_size\" : 40,\n",
        "    \"valid_batch_size\" : 100,\n",
        "    \"workers\" : 0,\n",
        "    \"label_smoothing\" : 0.1,\n",
        "    \"beam_num\" : 2,\n",
        "    \"optimization\":{\n",
        "        \"factor\" : 2,\n",
        "        \"warmup\"  : 4000,\n",
        "        \"optimizer\" : {\n",
        "                \"lr\" : 0,\n",
        "                \"betas\" : (0.9, 0.98),\n",
        "                \"eps\" : 1e-9,\n",
        "                \"weight_decay\" : 0.0001\n",
        "                }\n",
        "            },\n",
        "    \"model_saving_path\" : \"/content/drive/MyDrive/model.pth\",\n",
        "    \"model_temporary_saving_path\" : \"/content/drive/MyDrive/temporary_model.pth\"\n",
        "}\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "-WoR-01STMor"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing package\n",
        "------"
      ],
      "metadata": {
        "id": "cdURO12Sntrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used in part 1\n",
        "!pip install sentencepiece\n",
        "# used in part 1 and 3\n",
        "!pip install tqdm\n",
        "# used in part 2\n",
        "!pip install torchinfo\n",
        "# used in part 3\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ti-UGuHNhh",
        "outputId": "01715f9e-ff30-4f90-9db5-16a4a865b461"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing data set\n",
        "=============\n",
        "\n",
        "load data file\n",
        "-------------\n",
        ">Here I load dataset from my drive,  \n",
        ">but it also can be download from the link below."
      ],
      "metadata": {
        "id": "mMkT3K4JXs60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1 : download dataset from drive to google colab\n",
        "# original dataset is in \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\"\n",
        "\n",
        "path_doc = setting[\"data_info\"][\"document\"]\n",
        "rawdata_file_name = setting[\"data_info\"][\"raw_file_name\"]\n",
        "rawdata_file_path = path_doc + rawdata_file_name\n",
        "unzip_path = path_doc + setting[\"data_info\"][\"unzip_path\"]\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive_path = setting[\"data_info\"][\"drive_path\"]\n",
        "drive.mount(drive_path)\n",
        "\n",
        "# copy file from drive\n",
        "# import shutil\n",
        "# shutil.copyfile(path_doc + rawdata_file_name, rawdata_file_path)\n",
        "\n",
        "# step 2 : unzip dataset\n",
        "import tarfile\n",
        "# open file\n",
        "file = tarfile.open(rawdata_file_path)\n",
        "# extracting file\n",
        "file.extractall(unzip_path)\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X23RaTWe9hoU",
        "outputId": "18fd2d14-f15d-44ec-b2af-ea4acc48bc1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean data\n",
        "------\n",
        ">First each dataset (source or target) is clean  \n",
        ">seperately, change to halfwidth and remove/replace  \n",
        ">some kind of punctuations.\n",
        "\n",
        ">Also because the number of sentences in one line may be  \n",
        ">different in line pairs of source and target set (its an error),  \n",
        ">some special punctuations is add to the end of sentences  \n",
        ">for the next process dealing with these problem by  \n",
        ">using sentence pairs instead of lines pairs to form datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "-y54N2UNimor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "# convert fullwidth to halfwidth\n",
        "def to_halfwidth(string):\n",
        "  return \"\".join(unicodedata.normalize('NFKC',letter) for letter in string)\n",
        "def clean_s_zh(s):\n",
        "    s = to_halfwidth(s)\n",
        "    # step 1 : delete — _\n",
        "    delete = \" _()[]\"\n",
        "    delete_rules = s.maketrans(\"\",\"\",delete)\n",
        "    s = s.translate(delete_rules)\n",
        "\n",
        "    # step 2 : replace “” with \"\"\n",
        "    to_be_replace = '“”'\n",
        "    replace = '\"\"'\n",
        "    replace_dict = dict(zip(to_be_replace,replace))\n",
        "\n",
        "    # step 3 : add **END** before and after punctuation\n",
        "\n",
        "    \"\"\"\n",
        "    The number of sentences in one line may be different\n",
        "    in line pairs of source and target set.\n",
        "    \"**END**\" is add after \"。!?\" and \".!?\", which can be used\n",
        "    to check if the number of sentence in the pair are equal\n",
        "    in the next process.\n",
        "    also in english, \".\" may be use in abbreviation,\n",
        "    these different use must be identified.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    punctuation = \"。!?\"\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "\n",
        "    replace_rules = s.maketrans(replace_dict)\n",
        "    s = s.translate(replace_rules)\n",
        "\n",
        "    zh_list = s.strip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "    return zh_list\n",
        "\n",
        "def clean_s_en(s):\n",
        "    s = to_halfwidth(s)\n",
        "\n",
        "    replace_dict = {}\n",
        "\n",
        "    delete = \"-()[]\"\n",
        "    for char in delete:\n",
        "      replace_dict[char] = \"\"\n",
        "\n",
        "    punctuation = \"!?\"\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "    replace_rules = s.maketrans(replace_dict)\n",
        "    s = s.translate(replace_rules)\n",
        "\n",
        "    # Identify if \".\" is used in abbreviation,\n",
        "    # if not, add \"**END**\" after it.\n",
        "    pattern = re.compile(r\"(?<!([.\\s\\r\\n\\f][a-zA-Z]))[.]\")\n",
        "    s = pattern.sub(\"**END**\",s)\n",
        "\n",
        "    # test pattern\n",
        "    # pattern = re.compile(r\"(?<!([.\\s\\r\\n\\f][a-zA-Z]))[.]\")\n",
        "    # result = pattern.sub(\"**END**\",\"There are many people in U.S. w.r.t. in Taiwan.Thank you.\")\n",
        "\n",
        "    en_list = s.strip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "    return en_list"
      ],
      "metadata": {
        "id": "5dwWeVz-sPI2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pick up line pairs\n",
        "------\n",
        ">pick up line pairs has equal number of sentences and  \n",
        ">split them into sentences to form sourse/target dataset.  \n",
        ">Remove sentences with too many words for training and validation."
      ],
      "metadata": {
        "id": "M2EfnpIXV91l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using \"**END**\" to split line pairs to check if they have equal sentence\n",
        "def divide_by_END(s):\n",
        "    list_s = []\n",
        "    for line_string in s.strip(\"**END**\").split(\"**END**\"):\n",
        "      if line_string not in [\"\",\" \"]:\n",
        "         list_s.append(line_string)\n",
        "    return(list_s)\n",
        "'''\n",
        "warning : devide_en_again function is apply just beacause\n",
        "in \"this\" dataset english sentences end with \":\" or \";\"\n",
        "sometimes not splited well.\n",
        "If the dataset is change, this part may need to be\n",
        "eliminated or modified.\n",
        "'''\n",
        "def devide_en_again(s,punctuation = \":;\"):\n",
        "    replace_dict = {}\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "\n",
        "    replace_rules_src = s.maketrans(replace_dict)\n",
        "    new_s = divide_by_END(s.translate(replace_rules_src))\n",
        "    return new_s\n",
        "\n",
        "# remove \"sentence\" if it is too long.\n",
        "def remove_too_long(src_list,tgt_list,threshold):\n",
        "    too_long_src = 0\n",
        "    too_long_tgt = 0\n",
        "    remove = False\n",
        "    new_s = []\n",
        "    new_t = []\n",
        "    for i in range(len(src_list)):\n",
        "      if ((len(src_list[i])>threshold)):\n",
        "        remove = True\n",
        "        too_long_src += 1\n",
        "      if (len(tgt_list[i])>threshold):\n",
        "        remove = True\n",
        "        too_long_tgt += 1\n",
        "      if remove == False:\n",
        "        new_s.append(src_list[i])\n",
        "        new_t.append(tgt_list[i])\n",
        "      else :\n",
        "        remove = False\n",
        "    return(new_s,new_t,too_long_src,too_long_tgt)\n",
        "\n",
        "# pick up good line pairs for traning and validation model\n",
        "def check_data_pairs(src_list,tgt_list,threshold):\n",
        "    index = 0\n",
        "    new_src_list = []\n",
        "    new_tgt_list = []\n",
        "\n",
        "    same = 0\n",
        "    add_next = 0\n",
        "    split_again = 0\n",
        "    not_use = 0\n",
        "\n",
        "    while(index < len(src_list)):\n",
        "\n",
        "      src = divide_by_END(src_list[index])\n",
        "      tgt = divide_by_END(tgt_list[index])\n",
        "\n",
        "      # case 1 : src is as long as tgt , finished.\n",
        "      if len(src) == len(tgt):\n",
        "        new_src_list += src\n",
        "        new_tgt_list += tgt\n",
        "        same += 1\n",
        "        index += 1\n",
        "\n",
        "      else :\n",
        "        # if it is not the last one : both src and tgt add next sentence\n",
        "        if index != len(src_list)-1:\n",
        "          src_add_next = divide_by_END(src_list[index] + src_list[index+1])\n",
        "          tgt_add_next = divide_by_END(tgt_list[index] + tgt_list[index+1])\n",
        "          # case 2 : src_add_next is as long as tgt_add_next , finished.\n",
        "          if len(src_add_next) == len(tgt_add_next):\n",
        "            new_src_list += src_add_next\n",
        "            new_tgt_list += tgt_add_next\n",
        "            add_next += 2\n",
        "            index += 2\n",
        "\n",
        "          # using new punctuation to divide tgt (english) sentence.\n",
        "          # note that this part could cause negative effects if the dataset is change.\n",
        "          else :\n",
        "            src_add_next = devide_en_again(src_list[index] + src_list[index+1])\n",
        "            # case 3 : src_add_next is as long as tgt_add_next , finished.\n",
        "            if len(src_add_next) == len(tgt_add_next):\n",
        "              new_src_list += src_add_next\n",
        "              new_tgt_list += tgt_add_next\n",
        "              split_again +=2\n",
        "              index += 2\n",
        "\n",
        "            # case 4 : sentence will not be used.\n",
        "            else :\n",
        "              not_use += 1\n",
        "              # if to_do == 1 :\n",
        "              #   print(index,src_add_next,tgt_add_next,len(src_add_next),len(tgt_add_next))\n",
        "              index += 1\n",
        "\n",
        "        # if it is the last one\n",
        "        else :\n",
        "          not_use += 1\n",
        "          index += 1\n",
        "    # print information\n",
        "    print(f\"The original total number of line is {index}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences is {same}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences after combine the next lines is {add_next}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences after combine the next lines\"+\\\n",
        "       f\"and resplit english lines using :; is {split_again}.\")\n",
        "    print(f\"The number of line we don't use is {not_use}.\")\n",
        "    print(f\"Note that {index} = {same}+{add_next}+{split_again}+{not_use}.\")\n",
        "\n",
        "    # remove long lines\n",
        "    print(f\"The total number of sentence pairs before remove long sentences is {len(new_src_list)}.\")\n",
        "    new_src_list,new_tgt_list,too_long_src,too_long_tgt = remove_too_long(new_src_list,new_tgt_list,threshold)\n",
        "    print(f\"The finally total number of sentence pairs using is {len(new_src_list)}.\")\n",
        "    print(f\"Note that {len(new_src_list)} are the number of sentence pairs, not line pairs\")\n",
        "\n",
        "    return(new_src_list,new_tgt_list)"
      ],
      "metadata": {
        "id": "UVYvYCpuDQDa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load and clean data\n",
        "------"
      ],
      "metadata": {
        "id": "1KPMwJwck437"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and clean data\n",
        "def load_file(path,function):\n",
        "    with open(path, \"r\") as f:\n",
        "      data = f.read()\n",
        "      return function(data)\n",
        "# saving to new path\n",
        "def clean_data_and_save(\n",
        "    path_doc,raw_src_path,raw_tgt_path,\n",
        "    clean_src_path,clean_tgt_path,threshold\n",
        "    ):\n",
        "    raw_src_path = path_doc + raw_src_path\n",
        "    raw_tgt_path = path_doc + raw_tgt_path\n",
        "    src = load_file(raw_src_path,clean_s_en),\n",
        "    tgt = load_file(raw_tgt_path,clean_s_zh),\n",
        "    # src , tgt are tuples with only one term : src_list, tgt_list\n",
        "    src_list = src[0]\n",
        "    tgt_list = tgt[0]\n",
        "    clean_src_list, clean_tgt_list = check_data_pairs(src_list,tgt_list,threshold)\n",
        "    with open(path_doc + clean_src_path, \"w\") as f:\n",
        "      f.write(\"\\n\".join(clean_src_list))\n",
        "    with open(path_doc + clean_tgt_path, \"w\") as f:\n",
        "      f.write(\"\\n\".join(clean_tgt_list))\n",
        "# test clean_data_and_save\n",
        "# clean_data_and_save(\n",
        "#     path_doc = setting[\"data_info\"][\"document\"],\n",
        "#     raw_src_path = setting[\"data_info\"][\"source\"][\"raw_data_path\"],\n",
        "#     raw_tgt_path = setting[\"data_info\"][\"target\"][\"raw_data_path\"],\n",
        "#     clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "#     clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "#     threshold = setting[\"tokenized_setting\"][\"max_l\"]\n",
        "# )"
      ],
      "metadata": {
        "id": "DhVI2xylk1tr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize\n",
        "------\n",
        ">using sentencepiece to tokenize sentences,  \n",
        ">first make the english/chinese dictionary separately,  \n",
        ">then use these dict to encode sentence pair in dataset,  \n",
        ">including add bos/eos/padding to tokenized sentences.  \n",
        ">Finally split then into train/val set and save."
      ],
      "metadata": {
        "id": "S_-APGe5okQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as data\n",
        "def tokenized(clean_data_path,\n",
        "       vocab_size,\n",
        "       lang,\n",
        "       tokenized_setting\n",
        "       ):\n",
        "  model_prefix = f\"spm_{vocab_size}_{lang}\"\n",
        "  spm.SentencePieceTrainer.train(\n",
        "      input=clean_data_path,\n",
        "      **tokenized_setting,\n",
        "      model_prefix=model_prefix,\n",
        "  )\n",
        "  return(model_prefix)\n",
        "\n",
        "def get_tokenizers(path_doc,vocab_size,src_lang,tgt_lang):\n",
        "  src_tokenizer = spm.SentencePieceProcessor(model_file = path_doc + f\"/spm_{vocab_size}_{src_lang}\" +\".model\")\n",
        "  tgt_tokenizer = spm.SentencePieceProcessor(model_file = path_doc + f\"/spm_{vocab_size}_{tgt_lang}\" +\".model\")\n",
        "  return src_tokenizer,tgt_tokenizer\n",
        "\n",
        "def bos_eos_padding(dataset,\n",
        "          max_l,\n",
        "          src_tokenizer,\n",
        "          tgt_tokenizer\n",
        "          ):\n",
        "\n",
        "\n",
        "  padding_src = []\n",
        "  padding_tgt = []\n",
        "  len_s = 0\n",
        "  len_t = 0\n",
        "  for src,tgt in dataset:\n",
        "    s = src_tokenizer.encode(src, out_type=int)\n",
        "    s = np.append(s,[3])\n",
        "    s = np.append([2],np.pad(s,(0, max_l-len(s)-1), constant_values = 0))\n",
        "    padding_src.append(s)\n",
        "\n",
        "    t = tgt_tokenizer.encode(tgt, out_type=int)\n",
        "    t = np.append(t,[3])\n",
        "    t = np.append([2],np.pad(t,(0, max_l-len(t)-1), constant_values = 0))\n",
        "    padding_tgt.append(t)\n",
        "\n",
        "  return(list(zip(padding_src,padding_tgt)))\n",
        "# test SentencePieceProcessor and bos_eos_padding\n",
        "# s_src = spm.SentencePieceProcessor(model_file=\"/content/spm8000_en.model\")\n",
        "# s_src.encode(\"hello world!\", out_type=int)\n",
        "# bos_eos_padding([(\"hello world\",\"_哈囉\")],5,10)\n",
        "\n",
        "def data_set_preparing(path_doc,\n",
        "            clean_src_path,\n",
        "            clean_tgt_path,\n",
        "            max_l,\n",
        "            src_tokenizer,\n",
        "            tgt_tokenizer,\n",
        "            st_train_path,\n",
        "            st_val_path,\n",
        "            tt_train_path,\n",
        "            tt_val_path,\n",
        "            ):\n",
        "    src_set = []\n",
        "    tgt_set = []\n",
        "\n",
        "    with open(path_doc+clean_src_path,\"r\") as in_f :\n",
        "      for line in tqdm(in_f):\n",
        "        src_set.append(line)\n",
        "    with open(path_doc+clean_tgt_path,\"r\") as in_f :\n",
        "      for line in tqdm(in_f):\n",
        "        tgt_set.append(line)\n",
        "\n",
        "    dataset = list(zip(src_set,tgt_set))\n",
        "    dataset = bos_eos_padding(dataset,max_l,src_tokenizer,tgt_tokenizer)\n",
        "    train_set, valid_set = data.random_split(dataset,[0.99,0.01])\n",
        "    # print(train_set[0][0])\n",
        "\n",
        "    with open(path_doc + st_train_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(train_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[0])+\"\\n\")\n",
        "    with open(path_doc + st_val_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(valid_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[0])+\"\\n\")\n",
        "    with open(path_doc + tt_train_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(train_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[1])+\"\\n\")\n",
        "    with open(path_doc + tt_val_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(valid_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[1])+\"\\n\")"
      ],
      "metadata": {
        "id": "ByrUmAvFkKk9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized_data(vocab_size,tokenized_setting,max_l,path_doc,clean_src_path,\n",
        "          clean_tgt_path,src_lang,tgt_lang,st_train_path,st_val_path,\n",
        "          tt_train_path,tt_val_path,):\n",
        "  tokenized(path_doc + clean_src_path,vocab_size,src_lang,tokenized_setting)\n",
        "  tokenized(path_doc + clean_tgt_path,vocab_size,tgt_lang,tokenized_setting)\n",
        "  src_tokenizer,tgt_tokenizer = get_tokenizers(path_doc,vocab_size,src_lang,tgt_lang)\n",
        "  data_set_preparing(path_doc,clean_src_path,clean_tgt_path,max_l,src_tokenizer,\n",
        "           tgt_tokenizer,st_train_path,st_val_path,tt_train_path,tt_val_path)\n",
        "  return src_tokenizer,tgt_tokenizer\n",
        "\n",
        "# test tokenized_data()\n",
        "# src_tokenizer,tgt_tokenizer = tokenized_data(\n",
        "#     vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "#     tokenized_setting = {k:setting[\"tokenized_setting\"][k] for k in \\\n",
        "#               set(list(setting[\"tokenized_setting\"].keys()))-{\"vocab_size\",\"max_l\"}},\n",
        "#     max_l = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "#     path_doc = setting[\"data_info\"][\"document\"],\n",
        "#     clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "#     clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "#     src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "#     tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],\n",
        "#     st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "#     st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "#     tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "#     tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"])"
      ],
      "metadata": {
        "id": "RkIHpc6qkRqh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make data set\n",
        "------\n",
        "> Using tokenized data to make dataset.  \n",
        "> Classmethod : padding_mask_batch which  \n",
        "> where the key padding mask is constucted  \n",
        "> also defined here."
      ],
      "metadata": {
        "id": "FV3kHGqlggdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class myDataset(Dataset):\n",
        "  def __init__(self,src_path,tgt_path):\n",
        "\n",
        "    self.src_path = src_path\n",
        "    self.tgt_path = tgt_path\n",
        "\n",
        "    src_list = []\n",
        "    with open(self.src_path,\"r\") as f :\n",
        "      d_l = f.readlines()\n",
        "      for line in tqdm(d_l):\n",
        "        int_list = [int(i) for i in line.split()]\n",
        "        src_list.append(int_list)\n",
        "    self.src = torch.LongTensor(src_list)\n",
        "\n",
        "    tgt_list = []\n",
        "    with open(self.tgt_path,\"r\") as f :\n",
        "      l_l = f.readlines()\n",
        "      for line in tqdm(l_l):\n",
        "        int_list = [int(i) for i in line.split()]\n",
        "        tgt_list.append(int_list)\n",
        "    self.tgt = torch.LongTensor(tgt_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.src[index], self.tgt[index]\n",
        "\n",
        "  # make key padding mask\n",
        "  @classmethod\n",
        "  def padding_mask_batch(cls,batch,pad_id):\n",
        "    \"\"\"Collate a batch of data.\"\"\"\n",
        "    src, tgt = zip(*batch)\n",
        "    src = torch.stack(src)\n",
        "    tgt = torch.stack(tgt)\n",
        "    src_padding = (src == pad_id)\n",
        "    tgt_padding = (tgt == pad_id)\n",
        "\n",
        "    return src, tgt , src_padding, tgt_padding\n",
        "# test myDataset\n",
        "# data = []\n",
        "# with open(\"/content/train_dev/tokenized_train_data_en.txt\",\"r\") as f :\n",
        "#   d_l = f.readlines()\n",
        "#   for line in tqdm(d_l):\n",
        "#     int_list = [int(i) for i in line.split()]\n",
        "#     data.append(int_list)\n",
        "# print(data[0])"
      ],
      "metadata": {
        "id": "dbfi-DvrlDhI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "def get_data_set(train_batch_size,valid_batch_size,num_workers,path_doc,\n",
        "         st_train_path,st_val_path,tt_train_path,tt_val_path,pad_id):\n",
        "\n",
        "  train_set = myDataset(src_path = path_doc + st_train_path,\n",
        "              tgt_path = path_doc + tt_train_path,\n",
        "              )\n",
        "  valid_set = myDataset(src_path = path_doc + st_val_path,\n",
        "              tgt_path = path_doc + tt_val_path,\n",
        "              )\n",
        "  train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = train_batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = num_workers,\n",
        "    pin_memory = True,\n",
        "    collate_fn = lambda x : myDataset.padding_mask_batch(x,\n",
        "                   pad_id = pad_id)\n",
        "  )\n",
        "  valid_loader = DataLoader(\n",
        "    valid_set,\n",
        "    batch_size = valid_batch_size,\n",
        "    num_workers = num_workers,\n",
        "    pin_memory = True,\n",
        "    collate_fn = lambda x : myDataset.padding_mask_batch(x,\n",
        "                   pad_id = pad_id)\n",
        "  )\n",
        "  del train_set,valid_set\n",
        "  gc.collect()\n",
        "  return train_loader,valid_loader\n",
        "# test get_data_set()\n",
        "# train_set,valid_set = get_data_set()\n",
        "# batch = next(iter(valid_set))\n",
        "# src,tgt,src_mask,tgt_mask = batch\n",
        "# print(src.shape)"
      ],
      "metadata": {
        "id": "YBFKMSM45ppM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make model\n",
        "======\n",
        "positional encoding layer\n",
        "------\n",
        ">The first layer is embedding layer, where each integers  \n",
        ">in encoder sentence will be represent by a vector.   \n",
        ">I use build-in class in pytorch to finish these part,    \n",
        ">and combine it with encoder layers to form my encoder.\n",
        "\n",
        ">The layer below is the second layer :positional encoding layer  \n",
        ">in this layer the position infomation is add to each \"word\"  \n",
        ">in the sentence.\n",
        ">Here I use parameters instead of constant as  \n",
        ">position infomation so they will change during training process."
      ],
      "metadata": {
        "id": "RZAzqY3bwds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self,max_sentence_length,embedding_dimension):\n",
        "      super().__init__()\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.encoding_values = nn.Parameter(nn.init.normal_(torch.empty(max_sentence_length,1, embedding_dimension)))\n",
        "    def forward(self, x):\n",
        "        # the shape of x : [batch,length,e_dim]\n",
        "        # the shape of self.encoding_values : [batch,length,e_dim]\n",
        "        x = x + self.encoding_values.unsqueeze(0)\n",
        "        x = x.squeeze(-2)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "EoKH9m1LznWO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multihead attention layer\n",
        "------\n"
      ],
      "metadata": {
        "id": "OURB2Fg-4lE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import math\n",
        "from torchinfo import summary\n",
        "# This part is modify from pytorch : torch.nn.functional.scaled_dot_product_attention\n",
        "# Efficient implementation equivalent to the following:\n",
        "class Scaled_Dot_Product_Attention(nn.Module):\n",
        "    def __init__(self,max_sentence_length,dropout_p):\n",
        "      super().__init__()\n",
        "      self.dropout_p = dropout_p\n",
        "      self.max_l = max_sentence_length\n",
        "      attn_bias = torch.zeros(self.max_l, self.max_l)\n",
        "      temp_mask = torch.ones(self.max_l, self.max_l, dtype=torch.bool).tril(diagonal=0)\n",
        "      attn_bias = attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
        "      self.register_buffer(\"attn_bias\",attn_bias)\n",
        "\n",
        "    def forward(self, is_last_batch, query, key, value, padding_mask=None, is_causal=False, scale=None) -> torch.Tensor:\n",
        "      # Efficient implementation equivalent to the following:\n",
        "\n",
        "      scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
        "      attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
        "\n",
        "      if is_causal:\n",
        "        if is_last_batch:\n",
        "          self.attn_bias = self.attn_bias[:query.size(-2),:query.size(-2)]\n",
        "        self.attn_bias.to(query.dtype)\n",
        "        attn_weight += self.attn_bias\n",
        "\n",
        "      if padding_mask is not None:\n",
        "          if padding_mask.dtype == torch.bool:\n",
        "            padding_mask = torch.zeros_like(padding_mask,dtype = float).masked_fill_(padding_mask, (float(\"-inf\")))\n",
        "\n",
        "          padding_mask = padding_mask.unsqueeze(0).unsqueeze(0)\n",
        "          padding_mask.to(query.dtype)\n",
        "\n",
        "          attn_weight = attn_weight.transpose(-4,-2)\n",
        "          attn_weight += padding_mask\n",
        "          attn_weight = attn_weight.transpose(-4,-2)\n",
        "\n",
        "      attn_weight = torch.softmax(attn_weight, dim=-1)\n",
        "      attn_weight = torch.dropout(attn_weight, self.dropout_p, train=True)\n",
        "      return attn_weight @ value\n",
        "# test scaled_dot_product_attention\n",
        "# t = torch.rand([2,3,4,5])\n",
        "# mask = torch.tensor([[False,False,True,True],[False,True,False,True]],dtype = torch.bool)\n",
        "# print(scaled_dot_product_attention(\"cpu\",t,t,t,padding_mask= mask, is_causal=True))\n",
        "# from torch.nn.functional import scaled_dot_product_attention\n",
        "class My_MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, max_sentence_length, kv_input_dimension, embedding_dimension, num_heads, dropout_p, if_decoder = False):\n",
        "        '''\n",
        "        embedding_dimension = input dimension\n",
        "        note that there are residual sublayers in MultiHeadedAttention\n",
        "        '''\n",
        "        super().__init__()\n",
        "        assert embedding_dimension % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
        "        self.max_l = max_sentence_length\n",
        "        self.kv_d = kv_input_dimension\n",
        "        self.d = embedding_dimension\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_p = dropout_p\n",
        "        self.is_causal = if_decoder\n",
        "        self.sdpa = Scaled_Dot_Product_Attention(self.max_l,self.dropout_p)\n",
        "        self.linear_for_q = nn.Linear(self.d, self.d)\n",
        "        self.linear_for_kv = nn.Linear(self.kv_d, 2 * self.d)\n",
        "        self.linear_out_project = nn.Linear(self.d, self.d)\n",
        "\n",
        "    def forward(self, is_last_batch, q_input_data, kv_input_data , padding_mask = None):\n",
        "\n",
        "        query = self.linear_for_q(q_input_data)\n",
        "        key, value = self.linear_for_kv(kv_input_data).split(self.d,dim = -1)\n",
        "\n",
        "        query,key,value = \\\n",
        "          map(lambda x : x.view(x.size(0),x.size(1),self.num_heads,self.d//self.num_heads),[query,key,value])\n",
        "        query,key,value = \\\n",
        "          map(lambda x : x.transpose(-2,-3),[query,key,value])\n",
        "\n",
        "        x = self.sdpa(is_last_batch,query,key,value,padding_mask = padding_mask,is_causal = self.is_causal)\n",
        "        x = x.transpose(-2,-3).contiguous()\n",
        "        x = x.view(x.size(0),x.size(1),self.d)\n",
        "        x = self.linear_out_project(x)\n",
        "\n",
        "        return x\n",
        "# test My_MultiHeadedAttention\n",
        "# model = My_MultiHeadedAttention(64,128,2,0.0)\n",
        "# q_input = torch.rand(32,400,128)\n",
        "# kv_input = torch.rand(32,400,64)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(q_input,kv_input,mask).size())\n",
        "# print(summary(model,device = \"cpu\",q_input_data = q_input, kv_input_data = kv_input,padding_mask = mask))"
      ],
      "metadata": {
        "id": "PLWLkr9UaKFD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoder layer(s)\n",
        "------"
      ],
      "metadata": {
        "id": "T0IjI-zC5fqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class My_Encoder_Layer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,embedding_dimension,feedforward_dimension,num_heads,dropout_p):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "\n",
        "    self.attention = My_MultiHeadedAttention(self.max_l, self.emb_dim, self.emb_dim, self.num_heads, self.dropout_p)\n",
        "    self.layer_norm_attn = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_attn_layernorm = nn.Dropout(self.dropout_p)\n",
        "\n",
        "    self.feedforward = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_feedforward = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_feedforward_layernorm = nn.Dropout(self.dropout_p)\n",
        "\n",
        "\n",
        "  def forward(self,is_last_batch,x,padding_mask):\n",
        "    x = x + self.attention(is_last_batch,x,x,padding_mask)\n",
        "    x = self.layer_norm_attn(x)\n",
        "\n",
        "    x = self.drop_out_attn_layernorm(x)\n",
        "\n",
        "    x = x + self.feedforward(x)\n",
        "    x = self.layer_norm_feedforward(x)\n",
        "    x = self.drop_out_feedforward_layernorm(x)\n",
        "\n",
        "    return x\n",
        "# test My_Encoder_Layer\n",
        "# model = My_Encoder_Layer(\"cpu\",128,256,2,0.0)\n",
        "# input = torch.rand((32,400,128))\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(input,mask).size())\n",
        "# print(summary(model,input_data = input,padding_mask = mask))\n",
        "# print(model.state_dict().keys())\n",
        "class My_Encoder(nn.Module):\n",
        "  def __init__(self,max_sentence_length,dictionary_length,embedding_dimension,feedforward_dimension,\n",
        "         padding_idx, num_heads, dropout_p, layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.padding_idx = padding_idx\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "\n",
        "    self.encoder_embedding = nn.Embedding(self.dict_l,self.emb_dim,self.padding_idx)\n",
        "    self.positional_encoding = Positional_Encoding(self.max_l,self.emb_dim)\n",
        "    self.encoder = nn.ModuleList([My_Encoder_Layer(self.max_l,self.emb_dim,self.fwd_dim,\\\n",
        "                    self.num_heads,self.dropout_p) for i in range(layer_num)])\n",
        "\n",
        "  def forward(self,is_last_batch,input,padding_mask):\n",
        "    x = self.encoder_embedding(input.unsqueeze(-1))* math.sqrt(self.emb_dim)\n",
        "    x = self.positional_encoding(x)\n",
        "\n",
        "    for index,module in enumerate(self.encoder):\n",
        "      if index == 0:\n",
        "        x = module(is_last_batch,x,padding_mask)\n",
        "      else:\n",
        "        x = module(is_last_batch,x,None)\n",
        "    return x\n",
        "# test My_Encoder\n",
        "# model = My_Encoder(\"cpu\",400,8000,128,256,0,2,0.0,2)\n",
        "# input = torch.randint(0,7999,(32,400),dtype = torch.long)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(input,mask).size())\n",
        "# print(summary(model,input_data = input,padding_mask = mask))\n",
        "# print(model.state_dict().keys())"
      ],
      "metadata": {
        "id": "PYhd7muASnrY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "decoder layer(s)\n",
        "------"
      ],
      "metadata": {
        "id": "4O_rI3QV55Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class My_Decoder_Layer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,encoder_embedding_dimension,embedding_dimension,feedforward_dimension,num_heads,dropout_p):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.encoder_dim = encoder_embedding_dimension\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "\n",
        "    self.self_attention = My_MultiHeadedAttention \\\n",
        "     (self.max_l,self.emb_dim,self.emb_dim, num_heads = self.num_heads,\\\n",
        "     dropout_p = self.dropout_p, if_decoder = True)\n",
        "    self.layer_norm_sa = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_sa = nn.Dropout(0)\n",
        "\n",
        "    self.feedforward_sa = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_sa_fw = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_sa_fw = nn.Dropout(0)\n",
        "\n",
        "    self.cross_attention = My_MultiHeadedAttention \\\n",
        "    (self.max_l,self.encoder_dim, self.emb_dim, num_heads = self.num_heads,\n",
        "    dropout_p = self.dropout_p, if_decoder = True)\n",
        "    self.layer_norm_ca = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_ca = nn.Dropout(0)\n",
        "\n",
        "    self.feedforward_ca = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_ca_fw = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_ca_fw = nn.Dropout(0)\n",
        "\n",
        "  def forward(self,is_last_batch,encoder_input,input,padding_mask):\n",
        "\n",
        "    x = input + self.self_attention(is_last_batch,input,input,padding_mask)\n",
        "    x = self.layer_norm_sa(x)\n",
        "    x = self.drop_out_sa(x)\n",
        "\n",
        "    x = x + self.feedforward_sa(x)\n",
        "    x = self.layer_norm_sa_fw(x)\n",
        "    x = self.drop_out_sa_fw(x)\n",
        "\n",
        "    x = x + self.cross_attention(is_last_batch,x,encoder_input,padding_mask)\n",
        "    x = self.layer_norm_ca(x)\n",
        "    x = self.drop_out_ca(x)\n",
        "\n",
        "    x = x + self.feedforward_ca(x)\n",
        "    x = self.layer_norm_ca_fw(x)\n",
        "    x = self.drop_out_ca_fw(x)\n",
        "\n",
        "    return x\n",
        "class My_Decoder(nn.Module):\n",
        "  def __init__(self,max_sentence_length, dictionary_length, encoder_embedding_dimension,\n",
        "         embedding_dimension, feedforward_dimension, padding_idx, num_heads, dropout_p, layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.encoder_dim = encoder_embedding_dimension\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.padding_idx = padding_idx\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "\n",
        "    self.decoder_embedding = nn.Embedding(self.dict_l,self.emb_dim,padding_idx=self.padding_idx)\n",
        "    self.positional_encoding = Positional_Encoding(self.max_l,self.emb_dim)\n",
        "    self.decoder = nn.ModuleList([My_Decoder_Layer(self.max_l,self.encoder_dim,self.emb_dim,\\\n",
        "                    self.fwd_dim,self.num_heads,self.dropout_p) for i in range(self.layer_num)])\n",
        "    # self.encoder = My_Encoder_Layer(self.emb_dim,self.fwd_dim)\n",
        "\n",
        "    self.generator = nn.Linear(self.emb_dim,self.dict_l)\n",
        "\n",
        "  def forward(self,is_last_batch,encoder_input,input,padding_mask):\n",
        "    x = self.decoder_embedding(input.unsqueeze(-1))* math.sqrt(self.emb_dim)\n",
        "    x = self.positional_encoding(x)\n",
        "    # x = self.encoder(x,padding_mask)\n",
        "    for index,module in enumerate(self.decoder):\n",
        "      if index == 0:\n",
        "        x = module(is_last_batch,encoder_input,x,padding_mask)\n",
        "      else:\n",
        "        x = module(is_last_batch,encoder_input,x,None)\n",
        "    x = self.generator(x)\n",
        "    x = F.log_softmax(x,dim = -1)\n",
        "    return x\n",
        "# test My_Decoder\n",
        "# model = My_Decoder(\"cpu\",400,8000,128,64,256,0,2,0.0,2)\n",
        "# encoder_input = torch.rand(32,400,128)\n",
        "# input = torch.randint(0,7999,(32,400),dtype = torch.long)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(encoder_input = encoder_input,input = input, padding_mask = mask).size())\n",
        "# print(summary(model,encoder_input = encoder_input,input = input, padding_mask = mask))\n",
        "# print(model.state_dict().keys())"
      ],
      "metadata": {
        "id": "rEjaTbhyBmEV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformer layer\n",
        "------"
      ],
      "metadata": {
        "id": "1gcz18nz6QTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Transformer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,dictionary_length,padding_idx,\n",
        "         encoder_embedding_dimension,decoder_embedding_dimension,\n",
        "         feedforward_dimension,num_heads,dropout_p,layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.padding_idx = padding_idx\n",
        "    self.en_dim = encoder_embedding_dimension\n",
        "    self.de_dim = decoder_embedding_dimension\n",
        "    self.fw_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "    self.encoder = My_Encoder \\\n",
        "     (self.max_l,self.dict_l,self.en_dim,self.fw_dim,\n",
        "      self.padding_idx,self.num_heads,self.dropout_p,self.layer_num)\n",
        "    self.decoder = My_Decoder \\\n",
        "     (self.max_l,self.dict_l,self.en_dim,self.de_dim,self.fw_dim,\n",
        "      self.padding_idx,self.num_heads,self.dropout_p,self.layer_num)\n",
        "\n",
        "  def forward(self,is_last_batch,src,tgt,src_mask,tgt_mask):\n",
        "    memory = self.encoder(is_last_batch,src,src_mask)\n",
        "    outputs = self.decoder(is_last_batch,memory,tgt,tgt_mask)\n",
        "    return outputs\n",
        "\n",
        "def build_model(max_sentence_length,dictionary_length,padding_idx,encoder_embedding_dimension,\n",
        "         decoder_embedding_dimension,feedforward_dimension,num_heads,dropout_p,layer_num):\n",
        "  return My_Transformer(max_sentence_length,dictionary_length,padding_idx,\n",
        "              encoder_embedding_dimension,decoder_embedding_dimension,\n",
        "              feedforward_dimension,num_heads,dropout_p,layer_num)\n",
        "# test My_Transformer\n",
        "# model = My_Transformer(\"cpu\",400,8000,0,128,64,256,2,0,2)\n",
        "# src = torch.randint(0,8000,(32,400),dtype = torch.long)\n",
        "# tgt = torch.randint(0,8000,(32,400),dtype = torch.long)\n",
        "# src_mask = torch.cat(((torch.FloatTensor(32,200).uniform_() > 1),(torch.FloatTensor(32,200).uniform_() > 0.15)),dim =1)\n",
        "# tgt_mask = torch.cat(((torch.FloatTensor(32,100).uniform_() > 1),(torch.FloatTensor(32,300).uniform_() > 0.15)),dim =1)\n",
        "# out = model(src,tgt,src_mask,tgt_mask)\n",
        "# print(out.size(),out.dim(),out[0][0])\n",
        "# print(summary(model,src = src,tgt = tgt,src_mask = src_mask,tgt_mask = tgt_mask))\n",
        "# print(model.state_dict().keys())\n",
        "\n",
        "# test build_model\n",
        "# model = build_model()\n",
        "# batch = next(iter(train_set))\n",
        "# src, tgt, src_mask, tgt_mask = batch\n",
        "# print(type(src),src.shape)\n",
        "# print(summary(model,src = src,tgt = tgt,src_mask = src_mask,tgt_mask = tgt_mask))\n",
        "# outputs = model(src,tgt,src_mask,tgt_mask)\n",
        "# print(outputs.shape)"
      ],
      "metadata": {
        "id": "PBDq_h1jKCo7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training and validation process\n",
        "======\n",
        "Noam optimizer\n",
        "------"
      ],
      "metadata": {
        "id": "sPbMfCre6cSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "class NoamOpt:\n",
        "    def __init__(self,dictionary_length,factor,warmup,optimizer):\n",
        "        self.dict_len = dictionary_length\n",
        "        self.factor = factor\n",
        "        self.warmup = warmup\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self._rate = 0\n",
        "    def step(self):\n",
        "        self._step += 1\n",
        "        self._rate = self.factor *(self.dict_len ** (-0.5) * \\\n",
        "        min(self._step ** (-0.5), self._step * self.warmup ** (-1.5)))\n",
        "\n",
        "        self.optimizer.param_groups[0][\"lr\"] = self._rate\n",
        "        self.optimizer.step()\n",
        "    def zero_grad(self):\n",
        "        return self.optimizer.zero_grad()\n",
        "\n",
        "    def set_step(self,step):\n",
        "        self._step = step\n",
        "# test NoamOpt:\n",
        "# x = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
        "# x.param_groups[0][\"lr\"]"
      ],
      "metadata": {
        "id": "Lb8BnuysNCOQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "label smoothing\n",
        "------"
      ],
      "metadata": {
        "id": "3TyyebUNOeI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "  def __init__(self,batch_size,dictionary_length,padding_id,smoothing):\n",
        "        super().__init__()\n",
        "        self.dict_len = dictionary_length\n",
        "        self.smoothing = smoothing\n",
        "        self.padding_id = padding_id\n",
        "        shift = torch.full(size = (batch_size,1), dtype = torch.long, fill_value = self.padding_id)\n",
        "        self.register_buffer(\"shift\",shift)\n",
        "  def forward(self, is_last_batch, outputs , label):\n",
        "\n",
        "    # step1 : when using label in validation, shift is needed.\n",
        "    # label_shift : {type : tensor , shape : batch  X (max_sentence_length-1)\n",
        "    # value : int}\n",
        "    label_shift = label[:,1:]\n",
        "    # shift : {type : tensor , shape : batch  X 1 ,value : self.padding_id}\n",
        "\n",
        "    # label_shift : {type : tensor , shape : batch  X max_sentence_length\n",
        "    # value : int}\n",
        "    if is_last_batch:\n",
        "      label_shift = torch.cat((label_shift,self.shift[:label.size(0),:]),dim = 1)\n",
        "\n",
        "    else:\n",
        "      label_shift = torch.cat((label_shift,self.shift),dim = 1)\n",
        "\n",
        "    # step2 : convert label to onehot tensor, then apply label smoothing\n",
        "    # label_onehot : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : 0 or 1}\n",
        "    label_onehot = F.one_hot(label_shift,self.dict_len).float()\n",
        "    # add : {type : float}\n",
        "    add = self.smoothing / (self.dict_len)\n",
        "    # label_onehot : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : add or 1+add}\n",
        "    label_onehot += add\n",
        "    # label_smoothed : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : add or 1+add-self.smoothing}\n",
        "    label_smoothed = label_onehot.masked_fill_((label_onehot > 1),float(1-self.smoothing+add))\n",
        "\n",
        "    '''\n",
        "    Question : Is padding really needed?\n",
        "    '''\n",
        "    # step3 : use padding mask to ignore to loss from padding id, then calculate loss.\n",
        "    # loss : {type : tensor , shape : batch  X max_sentence_length X 1, value : float}\n",
        "    loss = -1*torch.sum((outputs*label_smoothed),dim = -1)\n",
        "    # label_padding_mask {type : tensor , shape : batch  X max_sentence_length, value : bool}\n",
        "    label_padding_mask = (label == self.padding_id)\n",
        "    # mask_loss : {type : tensor , shape : batch  X max_sentence_length,\n",
        "    # value : 0 or add or 1+add-self.smoothing}\n",
        "    mask_loss = loss.masked_fill_(label_padding_mask,0)\n",
        "    # # ignore_index_number : {type : int}\n",
        "    # ignore_index_number = (mask_loss == 0).sum().item()\n",
        "    # avg_loss : {type : int}\n",
        "    # avg_loss = mask_loss.sum()/(mask_loss.size(0)*mask_loss.size(1)-ignore_index_number)\n",
        "    avg_loss = mask_loss.sum()/mask_loss.size(0)\n",
        "    return(avg_loss)\n",
        "\n",
        "# test LabelSmoothedCrossEntropyCriterion\n",
        "# cal1 = LabelSmoothedCrossEntropyCriterion()\n",
        "# print(cal1(outputs,tgt))\n",
        "\n",
        "# ignore_index not work correctly\n",
        "# def LabelSmoothedCrossEntropy(outputs , label,dictionary_length,smooth,padding_id):\n",
        "#   print(outputs.shape)\n",
        "#   print(label.shape)\n",
        "#   label_onehot = label.transpose(-1,-2).squeeze()\n",
        "#   outputs = outputs.transpose(-1,-2)\n",
        "#   cal_loss = nn.CrossEntropyLoss(ignore_index = padding_idx,reduction = \"mean\", label_smoothing=smooth)\n",
        "#   return cal_loss(outputs,label_onehot)"
      ],
      "metadata": {
        "id": "8JltOQM_wq4m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://arxiv.org/pdf/1512.00567.pdf page 7\n",
        "\n",
        "#Ref 1 : Hong-Yi Li ML2021 HW5\n",
        "\n",
        "# class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "#     def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
        "#         super().__init__()\n",
        "#         self.smoothing = smoothing\n",
        "#         self.ignore_index = ignore_index\n",
        "#         self.reduce = reduce\n",
        "\n",
        "#     def forward(self, lprobs, target):\n",
        "#         if target.dim() == lprobs.dim() - 1:\n",
        "#             target = target.unsqueeze(-1)\n",
        "#         # nll: Negative log likelihood，the cross-entropy when target is one-hot. following line is same as F.nll_loss\n",
        "#         nll_loss = -lprobs.gather(dim=-1, index=target)\n",
        "#         #  reserve some probability for other labels. thus when calculating cross-entropy,\n",
        "#         # equivalent to summing the log probs of all labels\n",
        "#         smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
        "#         if self.ignore_index is not None:\n",
        "#             pad_mask = target.eq(self.ignore_index)\n",
        "#             nll_loss.masked_fill_(pad_mask, 0.0)\n",
        "#             smooth_loss.masked_fill_(pad_mask, 0.0)\n",
        "#         else:\n",
        "#             nll_loss = nll_loss.squeeze(-1)\n",
        "#             smooth_loss = smooth_loss.squeeze(-1)\n",
        "#         if self.reduce:\n",
        "#             nll_loss = nll_loss.sum()\n",
        "#             smooth_loss = smooth_loss.sum()\n",
        "#         # when calculating cross-entropy, add the loss of other labels\n",
        "#         eps_i = self.smoothing / lprobs.size(-1)\n",
        "#         loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
        "#         return loss\n",
        "\n",
        "#Ref 2 : By hemingkx : https://github.com/hemingkx/ChineseNMT\n",
        "\n",
        "# class LabelSmoothing(nn.Module):\n",
        "#     \"\"\"Implement label smoothing.\"\"\"\n",
        "\n",
        "#     def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "#         super(LabelSmoothing, self).__init__()\n",
        "#         self.criterion = nn.KLDivLoss(size_average=False)\n",
        "#         self.padding_idx = padding_idx\n",
        "#         self.confidence = 1.0 - smoothing\n",
        "#         self.smoothing = smoothing\n",
        "#         self.size = size\n",
        "#         self.true_dist = None\n",
        "\n",
        "\n",
        "#     def forward(self, x, target):\n",
        "#         assert x.size(1) == self.size\n",
        "#         true_dist = x.data.clone()\n",
        "#         true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "#         true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "#         true_dist[:, self.padding_idx] = 0\n",
        "#         mask = torch.nonzero(target.data == self.padding_idx)\n",
        "#         if mask.dim() > 0:\n",
        "#             true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "#         self.true_dist = true_dist\n",
        "#         return self.criterion(x, Variable(true_dist, requires_grad=False))"
      ],
      "metadata": {
        "id": "uaE0-tA9Q9cq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "beam search\n",
        "------"
      ],
      "metadata": {
        "id": "33m5daxZ7Cpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "class Decode_With_Beam_Search(nn.Module):\n",
        "    def __init__(self,batch_size,model,beam_num,max_sentence_length,\n",
        "           dictionary_length,bos_id,padding_id):\n",
        "      super().__init__()\n",
        "      self.batch_size = batch_size\n",
        "      self.model = model\n",
        "      self.beam_num = beam_num\n",
        "      self.max_sentence_length = max_sentence_length\n",
        "      self.dictionary_length = dictionary_length\n",
        "      self.bos_id = bos_id\n",
        "      self.padding_id = padding_id\n",
        "      # decoder_input : {type : tensor , shape : Batch X 1 , value : bos_id}\n",
        "      decoder_input = torch.full(size = (self.batch_size,1),fill_value = self.bos_id)\n",
        "      self.register_buffer(\"decoder_input\",decoder_input)\n",
        "      # repeat : {type : tensor , shape : Batch ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = torch.full([self.batch_size],fill_value = self.beam_num)\n",
        "      self.register_buffer(\"repeat\",repeat)\n",
        "      # decoder_probability {type : tensor , shape : Batch X beam_num X 1, value : 0.1}\n",
        "      decoder_probability = torch.full(size = (self.batch_size,self.beam_num,1),fill_value = 0.0)\n",
        "      self.register_buffer(\"decoder_probability\",decoder_probability)\n",
        "\n",
        "      # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "      padding = torch.full(size = (batch_size*self.beam_num,self.max_sentence_length),fill_value = self.padding_id)\n",
        "      self.register_buffer(\"padding\",padding)\n",
        "\n",
        "      # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "      row = torch.tensor(range(self.batch_size)).unsqueeze(1)\n",
        "      self.register_buffer(\"row\",row)\n",
        "\n",
        "    def forward(self,is_last_batch,src,src_mask):\n",
        "\n",
        "      if is_last_batch:\n",
        "        batch = src.size(0)\n",
        "      else :\n",
        "        batch = self.batch_size\n",
        "\n",
        "      if self.beam_num > batch:\n",
        "        beam_num = batch\n",
        "      else :\n",
        "        beam_num = self.beam_num\n",
        "\n",
        "      decoder_input = self.decoder_input[:batch,:]\n",
        "      repeat = self.repeat[:batch]\n",
        "      decoder_probability = self.decoder_probability[:batch,:,]\n",
        "      padding = self.padding[:batch*beam_num,:]\n",
        "      row = self.row[:batch,:]\n",
        "\n",
        "      # decoder_beam_expand : {type : tensor , shape : (Batch X beam_num) X 1 ,value : bos_id}\n",
        "      decoder_beam_expand = torch.repeat_interleave(decoder_input,repeat,dim=0)\n",
        "\n",
        "      # memory : {type : tensor , shape : Batch X max_sentence_length X encoder_output_dim ,value : arbitary float}\n",
        "      memory = self.model.encoder(is_last_batch,src,src_mask)\n",
        "      # memory_beam_expand : {type : tensor ,\n",
        "      # shape : (Batch X n_beam) X max_sentence_length X encoder_output_dim ,value : float}\n",
        "      memory_beam_expand = torch.repeat_interleave(memory,repeat,dim=0)\n",
        "\n",
        "      gc.collect()\n",
        "\n",
        "      for id in range(self.max_sentence_length-1):\n",
        "\n",
        "        # decoder_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "        # decoder_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "        new_decoder_beam_expand , new_decoder_probability = self.get_next_word(is_last_batch,memory_beam_expand,\n",
        "        decoder_beam_expand,decoder_probability,id,batch,beam_num,padding,repeat,row)\n",
        "\n",
        "        decoder_beam_expand,decoder_probability = new_decoder_beam_expand , new_decoder_probability\n",
        "        if id%10 ==0:\n",
        "          print(new_decoder_beam_expand[0])\n",
        "        gc.collect()\n",
        "\n",
        "      # out_beam_expand : {type : tensor , shape : Batch X beam_num X (max_sentence_length) ,value : 0 or 1}\n",
        "      decoder_beam_expand = decoder_beam_expand.view(batch,beam_num,self.max_sentence_length)\n",
        "      # max_probability : {type : tensor , shape :  Batch  X 1 ,value : int(max prob index)}\n",
        "      max_probability = torch.argmax(input = decoder_probability,dim = 1)\n",
        "      # max_probability_expand : {type : tensor , shape :  Batch  X 1 X max_sentence_length ,\n",
        "      # value : [[A,A,A....],[B,B,B...],...](A,B are int)}\n",
        "      max_probability_expand = max_probability.expand(batch, self.max_sentence_length).unsqueeze(1)\n",
        "      # decoder_out : {type : tensor , shape :  Batch X max_sentence_length ,\n",
        "      # value : [[int,int,...],[int,int...],...]}\n",
        "      decoder_out =  torch.gather(input = decoder_beam_expand ,dim = 1, index = max_probability_expand).squeeze(1)\n",
        "\n",
        "      print(decoder_out[0])\n",
        "      return decoder_out,F.one_hot(decoder_out,self.dictionary_length).float()\n",
        "\n",
        "    def get_next_word(self,is_last_batch,memory,out,out_probability,id,batch,beam_num,padding,repeat,row):\n",
        "      # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "      padding = padding[:,:self.max_sentence_length-(id+1)]\n",
        "      # out_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length,\n",
        "      # value : [[bos_id],[any_id],...[padding_id],....] X Batch}\n",
        "      out_padding = torch.cat((out,padding),dim = 1)\n",
        "      # tgt_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length ,value: bool}\n",
        "      tgt_padding = (out_padding == self.padding_id).squeeze(-1)\n",
        "      # out_add : {type : tensor , shape : Batch X beam_num X dictionary_length ,value : int}\n",
        "      out_add = self.model.decoder(is_last_batch,memory,out_padding,tgt_padding)[:,id,:]\\\n",
        "            .view(batch,beam_num,self.dictionary_length)\n",
        "      # out_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "      # out_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "      out , out_probability = self.beam_search_one_step(batch,beam_num,repeat,row,out,out_probability,out_add)\n",
        "\n",
        "      gc.collect()\n",
        "      return(out , out_probability)\n",
        "\n",
        "    def beam_search_one_step(self,batch,beam_num,repeat,row,sentences,p_sentences,n_beam_output):\n",
        "    # sentences : {type : tensor , shape : (batch X beam_num) X now_sentences_length X 1 value : int}\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num X 1 value : log_softmax probability}\n",
        "    # n_beam_output : {type : tensor , shape : batch X beam_num X dictionary_length,\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk in [0,1])}\n",
        "\n",
        "      '''\n",
        "      TO DO : (set beam num = K)\n",
        "      for every batch:\n",
        "      expand sentences(total number = K) K times (so there are K-square sentences),then concat with\n",
        "      the index of top K consequence of each beam(total K beams) in n_beam_output (so there are also K-square values).\n",
        "      '''\n",
        "      # sentences : {type : tensor , shape : batch X beam_num X now_sentences_length value : int}\n",
        "      sentences = sentences.view(batch,beam_num,-1)\n",
        "      # repeat : {type : tensor , shape : beam_num ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = repeat[:beam_num]\n",
        "      # sentences_expand : {type : tensor , shape : batch X (beam_num X beam_num) X now_sentences_length ,\n",
        "      # value : [[[A,B...] X beam_num times,[C,D...] X beam_num times}...] A,B,C,D...are int}\n",
        "      sentences_expand = torch.repeat_interleave(sentences,repeat,dim=1)\n",
        "\n",
        "      # topk_prob : {type : tensor , shape : batch X beam_num X beam_num, value : log_softmax probability}\n",
        "      # topk_index : {type : tensor , shape : batch X beam_num X beam_num, value : int}\n",
        "      topk_prob, topk_index = torch.topk(n_beam_output,dim = -1,k = beam_num)\n",
        "\n",
        "      # topk_index : {type : tensor , shape : batch X (beam_num X beam_num) X 1, value : int}\n",
        "      topk_index = topk_index.view(batch,-1,1)\n",
        "      # sentences : {type : tensor , shape : batch X (beam_num X beam_num) X (now_sentences_length+1), value : int}\n",
        "      sentences_expand = torch.cat((sentences_expand,topk_index),dim = -1)\n",
        "      '''\n",
        "      TO DO :\n",
        "      multipies p_sentences with the probability of top K consequence of each beam(total K beams) in n_beam_output\n",
        "      (so there are also K-square values).\n",
        "\n",
        "      The final step is to choose Top K consequence from K-square sentences by using p_sentences.\n",
        "      '''\n",
        "\n",
        "      # p_sentences : {type : tensor , shape : batch X (beam_num X beam_num),\n",
        "      # value : [P1,P2,P3...] X beam_num times (Pk is log_softmax probability)}\n",
        "      p_sentences = (p_sentences+topk_prob).view(batch,-1)\n",
        "      # p_sentences : {type : tensor , shape : batch X beam_num, value : log_softmax probability}\n",
        "      # p_index : {type : tensor , shape : batch X beam_num, value : int}\n",
        "      p_sentences, p_index = torch.topk(p_sentences, dim = 1, k = beam_num)\n",
        "      p_sentences = p_sentences.unsqueeze(-1)\n",
        "      # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "      # sentences : {type : tensor , shape : batch X beam_num X (now_sentences_length+1), value : log_softmax probability}\n",
        "      new_sentences = sentences_expand[row, p_index].view(batch*beam_num,-1)\n",
        "      sentences.data = new_sentences.data\n",
        "      gc.collect()\n",
        "      return sentences,p_sentences\n",
        "\n",
        "# test decode_with_beam_search\n",
        "# batch = 3\n",
        "# beam_num = 2\n",
        "# sentences = torch.randint(0,8000,(batch*beam_num,5))\n",
        "# p_sentences = torch.log(torch.rand((batch , beam_num , 1)))\n",
        "# n_beam_output = torch.rand((batch , beam_num , 8000))\n",
        "# print(sentences,p_sentences,n_beam_output)\n",
        "# print(beam_search_one_step(sentences,p_sentences,n_beam_output))\n",
        "# repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "# sentences_expand = torch.repeat_interleave(sentences.view(batch,beam_num,-1),repeat,dim=1)\n",
        "# print(sentences_expand,sentences_expand.shape)\n",
        "# decode_model = Decode_With_Beam_Search(32,model,2,400,8000,2,0)\n",
        "# outputs_in_word,outputs = decode_model(False,src,src_mask)\n",
        "# print(output[0])"
      ],
      "metadata": {
        "id": "6hrE6wYFxTIs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def beam_search_one_step(device,sentences,p_sentences,n_beam_output):\n",
        "    # sentences : {type : tensor , shape : (batch X beam_num) X now_sentences_length X 1 value : int}\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num X 1 value : log_softmax probability}\n",
        "    # n_beam_output : {type : tensor , shape : batch X beam_num X dictionary_length,\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk in [0,1])}\n",
        "\n",
        "    '''\n",
        "    TO DO : (set beam num = K)\n",
        "    for every batch:\n",
        "    expand sentences(total number = K) K times (so there are K-square sentences),then concat with\n",
        "    the index of top K consequence of each beam(total K beams) in n_beam_output (so there are also K-square values).\n",
        "    '''\n",
        "    batch = n_beam_output.size(0)\n",
        "    beam_num = n_beam_output.size(1)\n",
        "    # sentences : {type : tensor , shape : batch X beam_num X now_sentences_length value : int}\n",
        "    sentences = sentences.view(batch,beam_num,-1)\n",
        "    # repeat : {type : tensor , shape : beam_num ,value : beam_num}\n",
        "    # each row repeat beam_num times before concatenate\n",
        "    repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "    repeat = repeat.to(device)\n",
        "    # sentences_expand : {type : tensor , shape : batch X (beam_num X beam_num) X now_sentences_length ,\n",
        "    # value : [[[A,B...] X beam_num times,[C,D...] X beam_num times}...] A,B,C,D...are int}\n",
        "    sentences_expand = torch.repeat_interleave(sentences,repeat,dim=1)\n",
        "\n",
        "    # topk_prob : {type : tensor , shape : batch X beam_num X beam_num, value : log_softmax probability}\n",
        "    # topk_index : {type : tensor , shape : batch X beam_num X beam_num, value : int}\n",
        "    topk_prob, topk_index = torch.topk(n_beam_output,dim = -1,k = beam_num)\n",
        "\n",
        "    # topk_index : {type : tensor , shape : batch X (beam_num X beam_num) X 1, value : int}\n",
        "    topk_index = topk_index.view(batch,-1,1)\n",
        "    # sentences : {type : tensor , shape : batch X (beam_num X beam_num) X (now_sentences_length+1), value : int}\n",
        "    sentences_expand = torch.cat((sentences_expand,topk_index),dim = -1)\n",
        "    '''\n",
        "    TO DO :\n",
        "    multipies p_sentences with the probability of top K consequence of each beam(total K beams) in n_beam_output\n",
        "    (so there are also K-square values).\n",
        "\n",
        "    The final step is to choose Top K consequence from K-square sentences by using p_sentences.\n",
        "    '''\n",
        "\n",
        "    # p_sentences : {type : tensor , shape : batch X (beam_num X beam_num),\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk is log_softmax probability)}\n",
        "    p_sentences = (p_sentences+topk_prob).view(batch,-1)\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num, value : log_softmax probability}\n",
        "    # p_index : {type : tensor , shape : batch X beam_num, value : int}\n",
        "    p_sentences, p_index = torch.topk(p_sentences, dim = 1, k = beam_num)\n",
        "    p_sentences = p_sentences.unsqueeze(-1)\n",
        "    # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "    row = torch.tensor(range(batch)).unsqueeze(1)\n",
        "    row = row.to(device)\n",
        "    # sentences : {type : tensor , shape : batch X beam_num X (now_sentences_length+1), value : log_softmax probability}\n",
        "    new_sentences = sentences_expand[row, p_index].view(batch*beam_num,-1)\n",
        "    sentences.data = new_sentences.data\n",
        "    gc.collect()\n",
        "    return sentences,p_sentences\n",
        "\n",
        "def get_next_word(model,is_last_batch,device,memory,out,out_probability,id,batch,beam_num,max_sentence_length,dictionary_length,padding_id):\n",
        "    # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "    padding = torch.full(size = (batch*beam_num,max_sentence_length-(id+1)),fill_value = padding_id)\n",
        "    padding = padding.to(device)\n",
        "    # out_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length,\n",
        "    # value : [[bos_id],[any_id],...[padding_id],....] X Batch}\n",
        "    out_padding = torch.cat((out,padding),dim = 1)\n",
        "    # tgt_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length ,value: bool}\n",
        "    tgt_padding = (out_padding == padding_id).squeeze(-1)\n",
        "    # out_add : {type : tensor , shape : Batch X beam_num X dictionary_length ,value : int}\n",
        "    out_add = model.decoder(is_last_batch,memory,out_padding,tgt_padding)[:,id,:].view(batch,beam_num,dictionary_length)\n",
        "    # out_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "    # out_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "    out , out_probability = beam_search_one_step(device,out,out_probability,out_add)\n",
        "\n",
        "    gc.collect()\n",
        "    return(out , out_probability)\n",
        "\n",
        "def decode_with_beam_search(device,is_last_batch,model,src,src_mask,beam_num,max_sentence_length,\n",
        "               dictionary_length,bos_id,padding_id):\n",
        "    with torch.no_grad():\n",
        "      batch = src.size(0)\n",
        "      # decoder_input : {type : tensor , shape : Batch X 1 , value : bos_id}\n",
        "      decoder_input = torch.full(size = (batch,1),fill_value = bos_id)\n",
        "      decoder_input = decoder_input.to(device)\n",
        "      # repeat : {type : tensor , shape : Batch ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = torch.full([batch],fill_value = beam_num)\n",
        "      repeat = repeat.to(device)\n",
        "      # decoder_beam_expand : {type : tensor , shape : (Batch X beam_num) X 1 ,value : bos_id}\n",
        "      decoder_beam_expand = torch.repeat_interleave(decoder_input,repeat,dim=0)\n",
        "\n",
        "      # decoder_probability {type : tensor , shape : Batch X beam_num X 1, value : 0.1}\n",
        "      decoder_probability = torch.full(size = (batch,beam_num,1),fill_value = 0.0)\n",
        "      decoder_probability = decoder_probability.to(device)\n",
        "\n",
        "      # memory : {type : tensor , shape : Batch X max_sentence_length X encoder_output_dim ,value : arbitary float}\n",
        "      memory = model.encoder(is_last_batch,src,src_mask)\n",
        "      # memory_beam_expand : {type : tensor ,\n",
        "      # shape : (Batch X n_beam) X max_sentence_length X encoder_output_dim ,value : float}\n",
        "      memory_beam_expand = torch.repeat_interleave(memory,repeat,dim=0)\n",
        "\n",
        "      gc.collect()\n",
        "\n",
        "      for id in range(max_sentence_length-1):\n",
        "\n",
        "        # decoder_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "        # decoder_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "        new_decoder_beam_expand , new_decoder_probability = \\\n",
        "        get_next_word(model,is_last_batch,device,memory_beam_expand,decoder_beam_expand,\n",
        "               decoder_probability,id,batch,beam_num,max_sentence_length,dictionary_length,padding_id)\n",
        "\n",
        "        decoder_beam_expand,decoder_probability = new_decoder_beam_expand , new_decoder_probability\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "      # out_beam_expand : {type : tensor , shape : Batch X beam_num X (max_sentence_length) ,value : 0 or 1}\n",
        "      decoder_beam_expand = decoder_beam_expand.view(batch,beam_num,max_sentence_length)\n",
        "      # max_probability : {type : tensor , shape :  Batch  X 1 ,value : int(max prob index)}\n",
        "      max_probability = torch.argmax(input = decoder_probability,dim = 1)\n",
        "      # max_probability_expand : {type : tensor , shape :  Batch  X 1 X max_sentence_length ,\n",
        "      # value : [[A,A,A....],[B,B,B...],...](A,B are int)}\n",
        "      max_probability_expand = max_probability.expand(batch, max_sentence_length).unsqueeze(1)\n",
        "      # decoder_out : {type : tensor , shape :  Batch X max_sentence_length ,\n",
        "      # value : [[int,int,...],[int,int...],...]}\n",
        "      decoder_out =  torch.gather(input = decoder_beam_expand ,dim = 1, index = max_probability_expand).squeeze(1)\n",
        "    print(decoder_out[0])\n",
        "    return decoder_out,F.one_hot(decoder_out,dictionary_length).float()\n",
        "\n",
        "# test decode_with_beam_search\n",
        "# batch = 3\n",
        "# beam_num = 2\n",
        "# sentences = torch.randint(0,8000,(batch*beam_num,5))\n",
        "# p_sentences = torch.log(torch.rand((batch , beam_num , 1)))\n",
        "# n_beam_output = torch.rand((batch , beam_num , 8000))\n",
        "# print(sentences,p_sentences,n_beam_output)\n",
        "# print(beam_search_one_step(sentences,p_sentences,n_beam_output))\n",
        "# repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "# sentences_expand = torch.repeat_interleave(sentences.view(batch,beam_num,-1),repeat,dim=1)\n",
        "# print(sentences_expand,sentences_expand.shape)\n",
        "# output = decode_with_beam_search(model,src,src_mask,2,400,8000,)\n",
        "# print(output[0])"
      ],
      "metadata": {
        "id": "sz_zI5fDh9UU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bleu\n",
        "------"
      ],
      "metadata": {
        "id": "Pt1o-F1Ik8cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torcheval.metrics.functional.text import bleu\n",
        "def get_bleu_score(outputs,tgt,tgt_tokenizer,eos_id):\n",
        "    outputs = np.array(outputs.detach().tolist())\n",
        "    outputs = [x[:np.nonzero(x == eos_id)[0][0]].tolist() if len(np.nonzero(x == eos_id)[0])>0 \\\n",
        "              else x.tolist() for x in outputs ]\n",
        "\n",
        "    outputs_decode = tgt_tokenizer.decode(outputs)\n",
        "    out = [outputs_decode[i] for i in range(len(outputs_decode)) if len(outputs_decode[i])>= 4]\n",
        "    print(out)\n",
        "    out = [\" \".join(list(x)) for x in out]\n",
        "    print(out)\n",
        "    tgt_decode = tgt_tokenizer.decode(tgt.detach().tolist())\n",
        "    tgt = [tgt_decode[i] for i in range(len(outputs_decode)) if len(outputs_decode[i])>= 4]\n",
        "    print(tgt)\n",
        "    tgt = [\" \".join(list(x)) for x in tgt]\n",
        "    print(tgt)\n",
        "    return bleu.bleu_score(out, tgt, n_gram=4).detach().item()\n",
        "# test bleu\n",
        "# test_tokenizer = spm.SentencePieceProcessor(model_file = \"/content/spm_8000_zh.model\")\n",
        "# candidates = torch.tensor([[21,3,9,99,42],[5,78,89,3,31]])\n",
        "# references = torch.tensor([[18,5,9,3,42],[3,5,78,89,50]])\n",
        "# get_bleu_score(candidates,references,test_tokenizer,3)"
      ],
      "metadata": {
        "id": "ISpHxGVQk7dh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train and validation function\n",
        "------"
      ],
      "metadata": {
        "id": "GF4GshwGjz-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "def train_one_epoch(device,model,loss_calculator,is_last_batch,\n",
        "          src,tgt,src_mask,tgt_mask,dictionary_length,\n",
        "          optimizer):\n",
        "\n",
        "    outputs = model(is_last_batch,src,tgt,src_mask,tgt_mask)\n",
        "\n",
        "    loss = loss_calculator(is_last_batch,outputs,tgt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return loss.detach().item(),outputs[0].detach()\n",
        "\n",
        "def valid(device,model,loss_calculator,batch_size_setting,valid_loader,beam_num,max_sentence_length,\n",
        "      dictionary_length,bos_id,eos_id,pad_id,tgt_tokenizer):\n",
        "    batch_loss = []\n",
        "    batch_bleu_score = []\n",
        "    with torch.no_grad():\n",
        "      for val_batch in tqdm(valid_loader,desc=\"valid_step\", unit=\" step\"):\n",
        "        src,tgt,src_mask,tgt_mask = val_batch\n",
        "        src,tgt,src_mask = src.to(device),tgt.to(device),src_mask.to(device)\n",
        "\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        is_last_batch = False\n",
        "        if batch_size != batch_size_setting:\n",
        "          is_last_batch = True\n",
        "        decode_model = Decode_With_Beam_Search(batch_size,model,beam_num,max_sentence_length,\n",
        "                            dictionary_length,bos_id,pad_id)\n",
        "        decode_model.to(device)\n",
        "        outputs_in_word,outputs = decode_model(is_last_batch,src,src_mask)\n",
        "        # outputs_in_word,outputs = decode_with_beam_search(device,is_last_batch,model,src,src_mask,beam_num,\\\n",
        "        #       max_sentence_length,dictionary_length,bos_id,pad_id)\n",
        "\n",
        "\n",
        "        loss = loss_calculator(is_last_batch,outputs,tgt)\n",
        "\n",
        "        bleu_score = get_bleu_score(outputs_in_word,tgt,tgt_tokenizer,eos_id)\n",
        "\n",
        "        batch_loss.append(loss)\n",
        "        batch_bleu_score.append(bleu_score)\n",
        "\n",
        "      avg_valid_loss = batch_loss.sum()/len(batch_loss).detach().item()\n",
        "      avg_bleu_score = batch_bleu_score.sum()/len(batch_bleu_score).detach().item()\n",
        "\n",
        "    return avg_valid_loss,avg_bleu_score"
      ],
      "metadata": {
        "id": "bwXkljhMFqKV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function\n",
        "------"
      ],
      "metadata": {
        "id": "R7I8W9cQj7ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def main(setting,dataset_is_prepare = False,load_model = False):\n",
        "\n",
        "    # set random seed\n",
        "    myseed = 1\n",
        "    np.random.seed(myseed)\n",
        "    torch.manual_seed(myseed)\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "    # data set & tokenizer\n",
        "    if not dataset_is_prepare:\n",
        "        clean_data_and_save(\n",
        "        path_doc = setting[\"data_info\"][\"document\"],\n",
        "        raw_src_path = setting[\"data_info\"][\"source\"][\"raw_data_path\"],\n",
        "        raw_tgt_path = setting[\"data_info\"][\"target\"][\"raw_data_path\"],\n",
        "        clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "        clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "        threshold = setting[\"tokenized_setting\"][\"max_l\"])\n",
        "\n",
        "        src_tokenizer,tgt_tokenizer = tokenized_data(\n",
        "            vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            tokenized_setting = {k:setting[\"tokenized_setting\"][k] for k in \\\n",
        "                      set(list(setting[\"tokenized_setting\"].keys()))-{\"vocab_size\",\"max_l\"}},\n",
        "            max_l = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "            path_doc = setting[\"data_info\"][\"document\"],\n",
        "            clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "            clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "            src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "            tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],\n",
        "            st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "            st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "            tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "            tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"])\n",
        "    else:\n",
        "        src_tokenizer,tgt_tokenizer = get_tokenizers(\n",
        "            path_doc = setting[\"data_info\"][\"document\"],\n",
        "            vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "            tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],)\n",
        "\n",
        "    # data loader\n",
        "    train_batch_size_setting = setting[\"training_hparas\"][\"train_batch_size\"]\n",
        "    valid_batch_size_setting = setting[\"training_hparas\"][\"valid_batch_size\"]\n",
        "    train_loader,valid_loader = get_data_set(\n",
        "        train_batch_size = train_batch_size_setting,\n",
        "        valid_batch_size = valid_batch_size_setting,\n",
        "        num_workers = setting[\"training_hparas\"][\"workers\"],\n",
        "        path_doc = setting[\"data_info\"][\"document\"],\n",
        "        st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "        st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "        tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "        tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"],\n",
        "        pad_id = setting[\"tokenized_setting\"][\"pad_id\"])\n",
        "    train_iter = iter(train_loader)\n",
        "    valid_iter = iter(valid_loader)\n",
        "\n",
        "    # model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model =  build_model(\n",
        "          max_sentence_length = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "          dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "          padding_idx = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "          encoder_embedding_dimension = setting[\"model\"][\"encoder_embedding_dimension\"],\n",
        "          decoder_embedding_dimension = setting[\"model\"][\"decoder_embedding_dimension\"],\n",
        "          feedforward_dimension = setting[\"model\"][\"feedforward_dimension\"],\n",
        "          num_heads = setting[\"model\"][\"num_heads\"],\n",
        "          dropout_p = setting[\"model\"][\"dropout_p\"],\n",
        "          layer_num = setting[\"model\"][\"layer_num\"])\n",
        "\n",
        "    if load_model:\n",
        "      checkpoint = torch.load(setting[\"training_hparas\"][\"model_temporary_saving_path\"])\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_loss_calculator = LabelSmoothedCrossEntropyCriterion(\n",
        "                batch_size = train_batch_size_setting,\n",
        "                dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "                padding_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "                smoothing = setting[\"training_hparas\"][\"label_smoothing\"])\n",
        "\n",
        "    valid_loss_calculator = LabelSmoothedCrossEntropyCriterion(\n",
        "            batch_size = valid_batch_size_setting,\n",
        "            dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            padding_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "            smoothing = 0)\n",
        "\n",
        "    train_loss_calculator,valid_loss_calculator = \\\n",
        "    train_loss_calculator.to(device),valid_loss_calculator.to(device)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), **(setting[\"training_hparas\"][\"optimization\"][\"optimizer\"]))\n",
        "\n",
        "    if load_model:\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "\n",
        "    Noam_optimizer = NoamOpt(\n",
        "             dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "             factor = setting[\"training_hparas\"][\"optimization\"][\"factor\"],\n",
        "             warmup = setting[\"training_hparas\"][\"optimization\"][\"warmup\"],\n",
        "             optimizer = optimizer)\n",
        "    if load_model:\n",
        "      Noam_optimizer.set_step(checkpoint['step'])\n",
        "\n",
        "    # step\n",
        "    total_step = setting[\"training_hparas\"][\"total_step\"]\n",
        "    early_stop_epoch = setting[\"training_hparas\"][\"early_stop_step\"]\n",
        "    do_valid_steps = setting[\"training_hparas\"][\"do_valid_step\"]\n",
        "    early_stop_count = 0\n",
        "    progress_bar = tqdm(total = do_valid_steps, desc=\"train_step\", unit=\" step\")\n",
        "\n",
        "    # output datas\n",
        "    train_loss_every_batchs = []\n",
        "    valid_loss = []\n",
        "    bleu_score = []\n",
        "    best_bleu_score = 0\n",
        "\n",
        "    for step in range(total_step):\n",
        "\n",
        "      # training\n",
        "      # iter batch\n",
        "      try:\n",
        "        train_batch = next(train_iter)\n",
        "      except StopIteration:\n",
        "        train_iter = iter(train_loader)\n",
        "        train_batch = next(train_iter)\n",
        "\n",
        "      # compute batch loss and update parameters in model\n",
        "      model.train()\n",
        "\n",
        "      src,tgt,src_mask,tgt_mask = train_batch\n",
        "      src,tgt,src_mask,tgt_mask = src.to(device),tgt.to(device),\\\n",
        "                     src_mask.to(device),tgt_mask.to(device)\n",
        "      batch_size = src.size(0)\n",
        "\n",
        "      is_last_batch = False\n",
        "      if batch_size != train_batch_size_setting:\n",
        "        is_last_batch = True\n",
        "\n",
        "      train_loss, test_sentence = train_one_epoch(\n",
        "              device = device,\n",
        "              model = model,\n",
        "              loss_calculator = train_loss_calculator,\n",
        "              is_last_batch = is_last_batch,\n",
        "              src = src,\n",
        "              tgt = tgt,\n",
        "              src_mask = src_mask,\n",
        "              tgt_mask = tgt_mask,\n",
        "              dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "              optimizer = Noam_optimizer)\n",
        "\n",
        "      train_loss_every_batchs.append(train_loss)\n",
        "      if (step+1) % (do_valid_steps//20) == 0:\n",
        "        print(train_loss_every_batchs[-1])\n",
        "        print(tgt_tokenizer.decode(torch.argmax(test_sentence,dim = -1).tolist()))\n",
        "        print(tgt_tokenizer.decode(tgt.detach().tolist()))\n",
        "\n",
        "      progress_bar.update()\n",
        "      if (step+1) % do_valid_steps == 0:\n",
        "\n",
        "        print(train_loss_every_batchs[-1])\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        model.eval()\n",
        "        avg_val_loss,avg_bleu_score = valid(\n",
        "                        device = device,\n",
        "                        model = model,\n",
        "                        loss_calculator = valid_loss_calculator,\n",
        "                        batch_size_setting = valid_batch_size_setting,\n",
        "                        valid_loader = valid_loader,\n",
        "                        beam_num = setting[\"training_hparas\"][\"beam_num\"],\n",
        "                        max_sentence_length = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "                        dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "                        bos_id = setting[\"tokenized_setting\"][\"bos_id\"],\n",
        "                        eos_id = setting[\"tokenized_setting\"][\"eos_id\"],\n",
        "                        pad_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "                        tgt_tokenizer = tgt_tokenizer)\n",
        "        valid_loss.append(avg_val_loss)\n",
        "        bleu_score.append(avg_bleu_score)\n",
        "\n",
        "        # print avg loss\n",
        "        print(f\"average train loss = {sum(train_loss_every_batchs[-1*do_valid_steps:-1])/len(do_valid_steps):.4f}\")\n",
        "        print(f\"average valid loss = {valid_loss[-1]:.4f}\")\n",
        "        print(f\"average valid loss = {bleu_score[-1]:.4f}\")\n",
        "\n",
        "        # saving model and check early stop criterion\n",
        "        if bleu_score[-1] > best_bleu_score:\n",
        "          torch.save(model.state_dict(), setting[\"training_hparas\"][\"model_saving_path\"])\n",
        "        else :\n",
        "          early_stop_count += 1\n",
        "\n",
        "        if early_stop_count == early_stop_epoch:\n",
        "          break\n",
        "\n",
        "        progress_bar = tqdm(total = do_valid_steps, desc=\"train_step\", unit=\" step\")\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    return train_loss_every_batchs,valid_loss,bleu_score"
      ],
      "metadata": {
        "id": "e7hn-NAjHSQ5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(setting,dataset_is_prepare = False)\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aGUYF3WnrI9F",
        "outputId": "5648ca60-eb10-44ec-873c-07db14151cd2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original total number of line is 394066.\n",
            "The number of line pairs have the equal sentences is 350485.\n",
            "The number of line pairs have the equal sentences after combine the next lines is 12288.\n",
            "The number of line pairs have the equal sentences after combine the next linesand resplit english lines using :; is 2972.\n",
            "The number of line we don't use is 28321.\n",
            "Note that 394066 = 350485+12288+2972+28321.\n",
            "The total number of sentence pairs before remove long sentences is 388642.\n",
            "The finally total number of sentence pairs using is 387943.\n",
            "Note that 387943 are the number of sentence pairs, not line pairs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "387943it [00:00, 1028753.67it/s]\n",
            "387943it [00:00, 752853.65it/s]\n",
            "100%|██████████| 384064/384064 [01:44<00:00, 3689.84it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 4111.35it/s]\n",
            "100%|██████████| 384064/384064 [01:50<00:00, 3487.94it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 4216.01it/s]\n",
            "100%|██████████| 384064/384064 [00:30<00:00, 12540.78it/s]\n",
            "100%|██████████| 384064/384064 [00:32<00:00, 11778.27it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 16514.10it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 15927.38it/s]\n",
            "train_step:   5%|▌         | 200/4000 [03:07<1:00:42,  1.04 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178.5497589111328\n",
            ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "['不知道為什麼,我開始對設計有興趣,', '應當說明的是我們非常小心地做這件事', '因為我們可以與十至十二人一起工作個幾年,有時則在海裡待上兩三個月的時間,', '克:它近很多,但也小很多,也許大小和我們剛看到的差不多?', '如果設計能提供另外一半,一切會變怎樣呢?', '行為經濟學家會說這種行為是厭惡損失我們有強烈的防衛本能以保護自己的東西', '讓我們放棄狹隘的自私自利以便擁抱改變以便能和那地區的人民一同歡慶一個偉大的未來一同歡慶希望與寬容', '我在北德州一座塵土飛揚的平原小鎮長大,父親是警長,祖父是牧師。', '今年九月,聯邦法庭判定一家公司根據應徵者是否有細髮辮來決定是否僱用這個人的歧視行為是合法的。', '他們開始從每個病人省免了三萬元給付。', '問題不在於你發明的炸彈能投得多准,而是你要如何用它們.更重要的是,你是否應該用它們.', '分離科技將會變得非常重要。', '我認為有更好的解決之道', '我不想成為瘋狂的女人年復一年地嘗試屢戰屢敗,屢敗屢戰但我相信我可以從古巴游到佛羅里達我也會從古巴游到佛羅里達', '那通常是指的是男生', '一個最近的研究估計顯示,如果沒有抗生素,每六個人當中就會有一位死亡。', '而在許多方面,駭客建造了美國。', '接著,我們注入癌症細胞來模仿癌症細胞在整個體內轉移的過程。', '要做這件事很恐怖,因為這些傳統領袖都已經習慣這些幾百年的傳統了。', '填入這些新粒子使圖案完整讓我們得到完整的e8', '從更衣室到比賽場地的走廊上,我當時跟silvio一起走,這樣他才能抓著我的肩膀,讓我引導他們。', '讓我瞭解其中的脈絡', '我們是唯一看見錯覺的嗎?', '海森堡測不準原理,或\"不確定性原理\"是少數可以從量子物理領域拓展到普羅大眾文化的物理原理之一', '在你們左手邊的圖是ip網址配對圖一個利用電腦產生的ip網址配對圖', '人們很願意得到:如果他們得等12個月,他們也願意等13個月。', '我在選舉日那天做志願者,負責選後民意調查。', '我們不可能隨時關閉它。', '今日的加拿大是由大部分的加拿大人不想要的政黨所帶領的', '對史提夫.格蘭特來說,一股漩渦有著跟', '我所知道最墮落、最邪惡的人,是有過大賣暢銷書的男作家。', '首先,我意識到很多我做的選擇是不理性的。', '事實上這就是恆星所做的事。', '在美國,即使是一個破產的賭徒都有二次機會。', '描繪一下100%。', '就在單挑開始前不久,他寫下了所有他的數學點子,發信給他所有的朋友,說「拜託,拜託」,時間是兩百年前,「拜託,拜託,要確保這些內容最後一定要被刊出。', '而且史丹福大學已經做一項長達五年的研究此研究詳細記錄了藉由理想的化身玩遊戲是如何影響我們現實世界的思考和行為使我們更有勇氣,更有企圖心更加約束自己向目標前進。', '現在我確認持有股票。', '所以他們調整了2012年奧林匹克的預算就是因為樂觀偏見', '而如果你將保險的概念應用得更廣泛些,你就可以運用更有力的市場機制力量,來提供你回饋資訊。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  10%|█         | 400/4000 [06:16<56:51,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129.79409790039062\n",
            ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "['因為捕撈執照費用所得大約是捕獲魚類上岸價格的一成,是在碼頭上岸的價格,不是店裡販售的價格。', '那就是共享價值。', '多元宇宙的想法有些奇怪。', '」', '這相當於一美元就有一億倍的增長能力從我還是個學生至今,這就是我們所經歷的.', '不管你和阿歷克斯怎麼決定,我們都支持你們。', '就這樣。', '那種魚的一切都被改變了。', '我們必須創新。', '有點太困難,最好還是留給別人做。', '我看著正義的問題變成了錢的問題,讓人懷疑美國司法體制的正當性。', '我常去最熱門的酒吧,但其實我更想要與好友自在的享用晚餐。', '我也沒辦法解答---那好玩嗎?', '我們應該重視人,更勝於重視疾病。', '而在具有這樣情形的小孩大腦中,它的母語是無法被清楚的表徵。', '姆索學習了超過30種醫療技能,從篩檢營養不良兒童,到用智慧手機來評估孩童咳嗽的原因,到協助愛滋病患者,並提供後續照護給失去肢體的病人。', '所以下一步是什麼?', '如果是她自找的,她允許事情發生,我們怎麼能稱之為強暴?', '單一栽培可能會致命。', '這個計畫讓我最欽佩、欣賞的地方是,除了它是在解決人的實際需要以外,同時它提供了絕佳的典範,展現了人類面對瑣碎汪洋的勇氣。', '事實是我回不去了,你們也一樣。', '我現在最多的時間都是在做這個。', '然而,治療後的一年,他的腫瘤瘋狂生長回來。', '我說那是無稽之談。', '」', '國家主義在近期內不會消失。', '45年後,1997年,深藍擊敗了當時的西洋棋世界冠軍卡司帕洛夫,', '我的確在書中找到一句話在我的人生中造成很大的不同,那句話就是:「我們在想像中所受的苦比在現實中還多」,塞內卡說的。', '那這個字呢?', '我丟了我的臉。', '但呼吸器接管這個程序,在呼吸系統失靈的時候,將氧氣帶入身體。', '我不信這套,但你時常會聽到有些人能夠預測未來大概都是僥倖猜中的吧我們也只能聽到這些不尋常的故事', '所以為了知道到底原子核有多大我們必須把原子從藍莓的大小放大到美式足球場一樣', '但她記下了地址並同意去那裡。', '有好人特徵的人絕對還是會犯錯。', '我愛雙關語和其與無意識的關聯。', '以下是他所發布文章中的一段', '藉由玩火,小孩子學習到一些關於火的基本原理,像是進氣、燃燒跟排氣。', '有些人相信一位全能的神會使他們復活而其他人相信萬能的科學會使他們復活這些都說明人們不是因著證據相信這些故事', '這些是隨視覺自然而來的。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  15%|█▌        | 600/4000 [09:26<53:51,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "154.82237243652344\n",
            ",,,我們,,,,,,,,,,的,,,。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "['而如今,每兩個男性得到大學學位的同時,就有三個女人亦達到相同成就。', '任何一個道德的工作都會依賴於實踐的智慧。', '使用藻類也有弊端:它的成本較高。', '就像是,參加日本茶道宴會時大家不會還要求外帶才能快點到下個景點', '而其結構正是使自然運作的力量,由此便可一目了然。', '不知道各位是否看得出來。', '在這裡,莎士比亞給予茱麗葉另一個事物的名稱,也就是\"太陽\"', '我希望他們做得比現在這樣更好。', '我思考很久的正是這個,因為這是我們目前做東西的方法。', '」', '別再回來監獄了!', '我想salmanrushdie會很忿怒,因為如果你有發現的話,我更動了紐約的地圖。', '」決定把核料變成核武。', '我不認為我們有在做些甚麼。', '所以我下一部電影名叫「帕亞尼」意思是水', '我搬到離我母親比較近的地方,我太太通常與我一同旅行,當我的孩子有假期時,若他們不回家,我會去找他們。', '但同時也需要文化和關係上的革命,', '所以完全不意外地,思想的大綻放是基於茶和咖啡飲品開始盛行於英格蘭。', '如果你是個生物學家,並瞭解鯊魚你就想評估一下自己的處境到底有多危險所以就有個問題馬上跳進你的大腦裡就是——視頻:哪種鯊魚?', '我公司的名字「人生之樂」就是法文所以我就陸續收到從阿拉巴馬和橘郡等地來的信說要抵制我的公司因為他們認為我們是法國公司', 'vannevarbush是大戰期間,美國政府的首席科學顧問。', '細菌可以被重新編程,讓它們不會造成感染,且能夠攜帶抗癌藥物,扮演特洛伊木馬,從腫瘤內部進攻。', '我們零零碎碎地聽到關於生命的資訊。', '第二,知識中的差距讓他們無法發覺自己的錯誤。', '這就是自助式:找出方法、詞語和圖像把你的家庭故事告訴孩子。', '理解到這個事實,讓我有能力選擇我該繼續憤怒,還是放下?', '我21歲時——我21歲時,發生了特雷文馬丁謀殺案。', '通常,神經多樣型大腦只能針對兩種情緒狀態,在任何時間點做成表格並清楚計數,因此,它們就不可能會針對現在的情況來做情緒上的調適。', '但我們卻發現到,讓車子長時間保持自動駕駛,在緊急狀況,把控制權交還給使用者其實是個很糟的計畫。', '去年落成的自由大學的圖書館,就是一個例子。', '中國透明度的國際排名近期來在170個國家中為第70到80名且持續向上', '她需要那種溫柔,那種深根在同情當中,且同時也仍然投入在正義和自由當中的溫柔。', '這就是我們需要的,我們需要與你們所有人的合作。', '沈默的大眾之所以沈默,是因為他們缺少詞彙。', '意味著我們每五個親友當中有兩個會被診斷出罹患某種癌症,而一個會病故。', '即使你掌握了95%的知識,那剩下的5%呢?', '但是,要完全改變架構,這不是一條簡單的路,也不是終點。', '我最近到海地工作,', '在我們傳播教育和科技時,我們就成了模因的帶原媒介,其他模因的寄主們當然要將我們視為敵人,嚴重威脅到他們所愛之模因的敵人—那是他們願意為之捐軀獻身的模因。', '例如,科學家已能分辨分佈世界各地,難以找著的藍鯨聚落']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  20%|██        | 800/4000 [12:35<50:48,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136.83880615234375\n",
            ",,,,我,,,,。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "['我當時17歲,體重64磅。', '現今,在工作場所,同時有五個世代的人,我們可以像是分別的孤立主義國家那樣運作,或者,我們可以開始想辦法建立橋樑,跨越世代的界線。', '這網站是個很棒的雙向溝通的管道。', '這是約翰杜麗勘,卡拉什人的薩滿。', '這是他們會去的地方,', '總括說,我們作為男人被教育認為女人的價值較少,看待她們是男人的財富和玩物.', '他們得要跟你說的是你是不是可以在裡面戴帽子、', '但有時,因為創作的結構,因為創作的階層,會很難看見其他東西。', '從巴黎協定簽署之後,氣候圖就一直向上飆升,每年都在破記錄。', '畢竟,牠有自己的美感標準。', '我使用影像分析軟體把珊瑚的外層用白色來強調,你們可以看到,仍然有一些小藍點在那一層之上。', '看看數據就可以明白', '畢竟,我們在這裡就是要一起夢想、一起合作、一起對抗氣候變遷、一起保護我們的地球。', '「沒錯。', '如果這還不算丟臉的話,我當時是在義大利收到罰單的。', '這個要求夠低吧。', '所以護理師勃洛克就提出一個實驗。', '在吉佳利以外,現今大約有20%盧安達國家血液供應遞送由我們做的。', '我來舉一個例子', '嗯,你們會很快搜索下記憶,作一個快速掃描,對你來說記起這些單詞太容易了,ring,rang,rung,而記起pare,park就很難:它們在腦海中出現得更慢。', '這場演講和我以前的演講完全不同', '使用這種技術,這是在三維空間的映射。', '這其實是一個腦波感應器當我在這裡演講時它就在讀取我大腦的電波活動', '而這不單是理論上的事,若暗能量到處都是如此強,宇宙早就被撕碎了,星星與星系也不會形成,我們也不會存在。', '因為我想獨佔它', '所以這些都是公開承認秘密其實談談我們是婦女的事實而且我們相信,我們有一組價值觀和經營方式去令我們相比過往的經驗而發展得更為持續的.', '還不提led燈本身就是高度節能的燈具要是全世界都改裝', '他們說:「比利,他們做事無法專注。', '您可以創建表單,一旦你創建了表單,你可以把他們推送到各種常見的手機上。', '1920年代和1960年代也是,', '我知道,我知道。', '和其他人一樣,他們說:「哎呀,多謝醫生!', '如果黑猩猩做了自私的選擇也就像現在那樣選了紅色籌碼它要把籌碼交給我們我們接過籌碼把它放在桌上那裡總共有二個食物要當獎品在這情況下只有右邊那隻黑猩猩得到食物', '我們將下潛機械的體積愈縮愈小,', '但那有比救人一命更重要嗎?', '但是女性當時也擔任著重要的角色發動、組織、上街示威', '然後保羅覺得牠只是同情他,', '每年夏天,就在鎮中心', '我們在自己的身體裡有一個池塘,', '在醫務室裏我的化療持續了4個半月']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  25%|██▌       | 1000/4000 [15:45<47:34,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142.5438690185547\n",
            "在是的,,的的是,的的的的的的。的。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "['超過1800人喪命於這場造成北美大陸史上最嚴重經濟破壞的自然災害中。', '確實反對了把頭髮弄成藍色', '而比這一切更糟糕的是我對自我的價值認同也隨之蒸發。', '在面對似乎不可能的挑戰時,女人和女孩是可能性的強大來源。', '右邊這張圖我再取了這個珊瑚的一小片把它放進核反應堆激發核裂變經過足夠長的時間它開始衰變你看到那些在珊瑚上的痕跡是肉眼可見的珊瑚中鈾的分布', '與其他各位看過的文章一樣,這篇文章講的是千篇一律的東西,', '還有我剛剛提到的google新聞是由一個研究者創立的', '就在那裏,我們找到了核的粒腺體基因', '表面上,我們住在民主國家,我們應該要得知一些世界上發生的事情。', '舉例來說,我們大部分見到像這樣有人看似傷心的圖片,都會立即有輕微、明顯的身體反應:心跳加快、開始流汗。', '肯定不會嘛!', '所以那些駱駝你可能都認不出來。', '但是2007年和2008年的大衰退,和大崩盤,打破了這個繁榮假象。', '我心想:「不可能。', '幾年前,我做的是企業女權主義者夢寐以求的工作。', '它意味著透過我祖母的舌頭、我媽媽的食物、我祖父的歌曲,來佩帶我的驕傲,我的皮膚鮮明地描述著落下驢子的故事,還有睡在星空之毯底下的那些歲月。', '這有個正直的人。', '而這是我們正在設計的,', '所以當我在某處展示作品,總有人問:「它有什麼重要性?', '我們還是會搭末班車回家,我們還是會隻身走在街道上,因為我們不會讓這樣做就會置自己於險境的想法,深深植入腦中。', '保羅開玩笑說,這和跟父母討論傳宗接代不一樣;你會想快速帶過這個話題,然後假裝這個話題從來沒有出現。', '這意味著,你不能把你的基因給你的醫生,請他或她幫你檢查,像是,檢查是否有變異,在沒有專利持有者的同意下。', '我搭乘深海潛水艇潛入世界各地的水域,', '他花了一生的時間在收藏,關於文化大革命的東西,之後的一些東西他還堅持收藏以至於他的博物館里現在有超過8百萬件收藏品這些收藏品記錄了當代中國人民的歷史', '它形成了現實反映周遭的環境', '謝謝各位。', '星系間的空間--星系間的空間是徹底黑暗的,極端地黑暗.', '全部加起來,它們在全世界的票房一共有250億美金,這就表示有數億人曾經離開他們的家,去坐在陌生人的旁邊,當燈光暗下來之後,欣賞了這些電影。', '這對能源來說可以是一個好的結果。', '\"', '布:但我們的領導型態是階層式的。', '現在我們就可以依自己的意願來瀏覽資訊。', '」', '而且我們要採取類似剔除限制的行動', '這就是多數人溝通的方式', '因為我們不知道的事其實會傷害我們', '在佛祖的角度上,他們將會在未來接收到那些教訓', '我可以看看你的財務記錄。', '相反地,你所看到的東南亞是地球上最和平、最繁榮的角落之一,有著第二成功的區域多邊組織:東南亞國家協會。', '就像我說的,那兩樣東西是在大小和形狀上是一模一樣的。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  30%|███       | 1200/4000 [18:55<44:29,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116.98796844482422\n",
            ",把他們,的,,,,,。,的,。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "['現在我們從沙霸的角度看他們看到的東西。', '賴瑞:當然了,你之前就問過我這件事,所以我一直在思考這個問題。', '戰力也提升了。', '這些故事主要點出的重點是,教學是社會性的,受惠於社會框架支持。', '後來我們想辦法將它縮小為伺服器大小的盒子。', 'asl被分割為不同的文法單位。', '他們對我觸動很大。', '非常感謝。', '在巴西,資源回收者回收了90%的可回收物。', '我之前從沒認真思考過分子的可能,', '但為了確保聯準會不受千變萬化的日常政治影響沒有任何政府單位有直接控制權', '首先,受害者,說出恐怖經歷的倖存者。', '有些科技領域中最優秀、最聰明的人才服務於新創的外送公司摩托車租賃公司或是研究更好的方法運送大麻', '我也很喜歡看動物如何去適應非洲的地景。', '要是我不在了,我女兒會怎樣', '圓的面積是「πr平方」。', '今天有誰寫下任何東西?', '再次的,這是很多不同基因引起的。', '他們讓逗號小姐站在前面', '同樣說明也可延伸至其他器官衰竭例如腎衰竭,肝功能衰竭急性呼吸功能衰竭以及由心導管手術造成的損傷', '我們談到慣性和器官捐贈還有勾選方格', '他還點頭了呢。', '因此,你在屏幕上看到的大部分的點並非是單獨的恆星,而是一系列恆星,或者是我們所稱之星系。', '」', '但當我想起六零年代,', '聽起來很好,對嗎?', '整整四年,當我們的學生走過大廳時,那些鏈環都會一直掛在我們頭上。', '有沒有人剛好知道答案呀?', '下午4點。', '」', '」', '24小時後,我的社工就是每幾個月就來訪查的陌生人在車子裡等我跟父母道別', '我們想要理解萬物。', '但是如果你再進一步了解女性割禮你就會發現,這個習俗與伊斯蘭毫無關係它只是北非的一個習俗比伊斯蘭更早產生', '並且我們把所有的原始數據到算進去時,進行很有趣的處理。', '那時,我下了決定,把我從《弗林特是家人》個人展得到的收益和羅伯特·勞森伯格基金會的慷慨贊助都交給摩西·維斯特。', '我們閱讀,有時為了解過去。', '拿我來說,蚊子很少叮我,但我的太太阿曼達是牠們的最愛,原因就是我倆表皮上的微生物形成了不同的化學物質,導致蚊蟲的反應不同。', '所以,鳥在你的窗戶外面叫也許可以代表常態或許是因為,我們作為一個物種百萬年來,我們已經太習慣每天早上聽到那個聲音', '少了人類照顧,牛也活不了,因為牠們已被人類馴化']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  35%|███▌      | 1400/4000 [22:04<41:15,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142.890380859375\n",
            "把在一個的,的,。。。。。。「。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。的。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "['我們發現一些特殊活動在腦中許多不同部位發生,事實上最重要的活動是發生在', '要想在第二次機器時代保持人性,除了創作出美麗的事物外,我們別無選擇。', '意思就是,我們沒有把對方看作是單獨的個體。', '牠們叮、咬還騷擾食物', '獻給瑪琳馬可麥克——她已經有第三齣劇被演出,在外外外外百老匯的劇界,在都柏林。', '牠使用一塊大石頭,將一顆蛋砸開,成為牠應得的餐點——不過,當大型鳥類離開之後,牠又會繞回到瞪羚的屍體所在。', '事實上,就是因為這個世代才出現了「工作狂」一詞。', '我把所發現的收集在一本書裡按時間順序排列,標記名稱贊助人、媒材和日期。', '這本來是不會有問題的。', '有沒有人能救救我!', '霍利·懷特觀察到,在健康的公共空間裏,很多不同空間都賦予不一樣的連繫方式。', '於是我做了一連串的工作有關法文和英文中相同的詞語。', '這裡看到的只是一部分。', '不在兒子身邊讓我煎熬了好幾個月」。', '我認為當公司有多元化的團隊而其中又有傑出的女性參與工程研發小組他們會創造出令人讚嘆的東西這我們每天都親眼見證', '只是當時還不知道還要多少年才能做到那個地步', '這些母親都該獲得對過程孰悉,且經驗豐富的臨床人員之協助。', '許多間大學正在嘗試開設有關於解決衝突之類的課程,也有許多政府嘗試著阻止邊境上的小規模戰爭,我們的生活正被暴力包圍著,不論是行車糾紛,或者是家暴事件,又或者是老師毆打學生甚至置之於死地只是因為她功課沒寫完,到處都是這種事情。', '還有,剛才我提到過昆蟲當中非常流行性吞噬的嗎?', '紅色通常是在停止標誌上', '我一直在談「不思」的情況', '謝謝。', '接下來,我要來談談我們目前所面臨的挑戰,自動化給我們所帶來的挑戰。', '最後,很多技術商品化', '不論怎麼稱呼它們,全世界都有數十億人穿這種橡膠鞋底的鞋子。', '但他們遠遠落後停在習慣性以人種區分來治療病患。', '我記得當我們知道那不是演習時,學生臉上驚恐的表情。', '聽起來挺簡單的,把二氧化碳從空氣中去除。', '那張照片是我待在那裡的最後一晚拍的。', '你只能再活六個月到一年。', '我們到底是超人,還是荷馬辛普森呢?', '維多利亞時期的魔法師會將其形容為機械奇蹟,那就是機器人,一個會思考的機器。', '他回答說,「我以前是個銀行家而現在我是個金礦工人。', '我很感恩,因為她成為我第一位良師益友,幫助我做自己。', '這些動物之所以不同是因為牠們的基因不同', '」我今天想要跟你們分享,海洋中我的最愛,那就是這些多到不可思議讓海洋閃閃發光的生物一開始我是被這看起來很奇特的wasp潛水裝所吸引這不是什麼字母的縮寫,只是有人覺得看起來像一種昆蟲', '由此一個列表就誕生了。', '他接著說:\"我們去你那兒看看那把椅子吧。', '這項危機留給人類兩個選項。', '在奈洛比同一所貧民窟,我遇見一名年輕的女生意人,她在家裡製作背包。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  40%|████      | 1600/4000 [25:15<38:08,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132.51016235351562\n",
            ",。。。。。。。。。。。年年\n",
            "['接下來讓我們來談健康議題', '那些房子是由日曬的石頭和石塊做成的。', '就像太空人有幸欣賞極少人得以看見的景致,他驚奇地看著自己重新呼吸,並且夢想著爬回家門。', '當然,我仍然認為法令有責任去制止非法行為,不論是在德國或其它地方。', '這是他們的作品,', '銷售的管道被大眾化了,那是好事。', '我們需要改變我們現在的做法管理這些資源', '相反的,一定是某種組織方式會隨著蟻群成長而跟著改變,', '我更清楚了一件事,要泡一杯咖啡,需要的不只是一個村子的人,', '」', '重點是,當有更多行為被輕推之後,不一致就會減少。', '假以時日,而我想那將會是我們這幾天所感受到的,人類精神的精髓點點滴滴由許多主講者所傳達出的', '不到幾星期,一樣的事又發生了。', '按下會解除環繞瑰寶的力場10秒', '閱讀餵飽我的心靈和靈魂', '是時候開始為我們的耳朵而設計了。', '它的傳染性不輸給水痘致命程度和伊波拉一樣它醞釀數個月才會爆發所以,發現任何危險徵兆前全世界可能已經被感染了', '謝謝!', '而你现在可以看到的是一個從試管中升起的行業,一個和自然和諧共存的礦業。', '他們交出很多點子,我大聲唸出好點子,然後撕成碎片丟掉。', '膠合板、許多的傢俱和木質層壓的地板所用的黏著劑中「甲醛」是主要的成分也許你聽過這個物質', '他死後,在有40萬人觀看的現場直播中他的大腦被保存、掃描、切成了2,000多個切片拍攝成有單神經元解析度的電子腦地圖', '這些發現告訴我們地球這類的行星可能只是宇宙生命的冰山一角。', '越來越廣大的田卻不只用來餵飽我們', '有鴿子棲息在天線上。', '愛鸚斯坦:讓我們為大家跳舞吧。', '要記得,如果你在半空中碰撞導致昏迷你會變成自由落體直到撞上地面', '你們現在在笑但這本書改變了我的生命', '然而大自然會有其補償之道例如雌性生物能夠一次產出很多蛋來克服那些不利的局面', '令我感到很難堪的是,我們美國人正正就是這個環球反毒戰背後的推手。', '聲音不斷地持續著,一連好幾天,持續好幾周,揮之不去,以旁觀者的口吻描述我做的每一件事:', '我們的關係仍然重要', '很多動物都喜歡集結成群這是自然界中最美妙的一件事', '我在研究所的時候,有一次碰巧聽到我的祖母跟她一位年長的朋友聊到我的工作。', '幾年前,我認為我可以把網路的這個點子以及我們對網路的專長帶到不同的領域去,也就是,用來了解成功。', '讓它說一些關於夢的事情,來視覺藝術學院你將會實現你的夢想。', '智慧型手機如何定位你的位置?', '他的視覺印象會告訴他,幻肢正在擺動,對吧?', '自我改造給人自主的感覺,給人活力,甚至令人興奮。', '牠們在眼不見心為淨的情況下被屠宰在鄉下的某處']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  45%|████▌     | 1800/4000 [28:24<34:54,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134.0919647216797\n",
            "所以,,,我把你們的,你想法千。。。。。。。。。。。。。。。。。。。。。。的。的的的的你的的你的\n",
            "['所以聽著,我謝謝您們給我的幾分鐘時間。', '所以為了瞭解暗能量的證據,我們需要討論一些史蒂芬霍金在上一段節目中談到的那個現象,', '我們正在創造有能力失敗的組織,但與此並存的,是在失敗時能有人清楚地負責。', '我用前一天剛剛在那什維爾所發生的故事來作為我演講的開場。', '用海洋塑膠做成的鞋子:對環境很好,對事業也很好。', '換言之,你的表現是你的事,但你的成功是我們所有人的事。', '往右邊指的是需要技術的勞動業,然後是比較不需要專業技能的非勞動業,最右邊則是需要專業知識的職業--像是醫生、律師,或是大型公司的主管。', '這就是告訴我,到頭來,如果你繼續嘗試——你仍然有可能成功,且一再成功。', '有時候非常的有趣。', '就告訴大家有關─她要我說些有關─我們家有個樂隊叫做leahy。', '一個值得注意以及違背常理的現象已經被找出來了,科學家們稱其為「創傷後成長」。', '如果要讓城市巴士進入,根據標準,規劃者必須要設計很奢侈的二十五公尺寬道路。', '所有這些字詞,都曾經被用來誹謗那些族群。', '沒得選,更大的分子也沒得選,比如這三個分子。', '我們沒有什麼籌碼可用。', '我們已經和超過25個國家打仗,自二次世界大戰以來。', '此張圖代表我們目前人造環境正遇到的處境', '呃,這樣對吧...', '明白意思了。', '你知道的,我脫離了運動,他卻還在其中。', '反正就是這個烤盤有問題', '也許你們之中有人去過', '這是歷史上第一次,都市的人口超過鄉村,', '免費是真的非常非常有意思', '慈悲的第一個利益是它創造了一些高效能的商業領袖。', '第二個是機遇讓不同社群進行更多的交流。', '你是在自動駕駛。', '那天一點都不好笑。', '因為我們是使用創新技術來做數位保存的考古學家,我們想到了一個點子。', '那個宣言就刻在這個圓柱體上這項宣言是由接受上帝指引的統治者頒布的他不僅推翻了伊拉克的暴君更帶給人民自由', '那些作品的內容包括氣球航行到月球,還有病危的病人進入催眠狀態時,能夠從另一個世界說話。', '我對我的孩子說:\"當你募到錢的時候,我們就會把你喜歡的藝術品,掛在牆上。', '哪有海豚?', '雖然聽起來很瘋狂,但我相信我們可以重新恢復投票的喜悅。', '但,我們得要想辦法協助他處理這些強大的情緒,同時還要教導他閱讀和數學等核心技能。', '飛機:糟糕透頂了因為飛行員安德烈亞斯·盧比茨證明了他可以強迫149個人陪他一起自殺將一架飛機開去撞法國阿爾卑斯山', '好消息是,這項技術為一些不可思議的事情打開了一扇門。', '到了2050年淨現值能減少五兆美元這裡是指總值是相對於目前的營運成本而言但我們必須先假設碳排放及其他隱性或外部成本為零但這只是保守估計', '另外蓋洛普民調顯示,十分之七的美國人相信核戰終將發生,而最少有一半的美國人將在這核戰中喪生。', '這邊有點太亮了,所以人們想到了這樣有趣的解決方式。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  50%|█████     | 2000/4000 [31:34<31:43,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135.35107421875\n",
            "這些的的的的,,,了的,的,,,有的」的的」的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "['當微生物消耗糖分時細菌產生酸性的副產物例如「乳酸」', '這個矛盾和自己的無能為力使愛因斯坦陷入了所謂的精神緊張的狀態', '我以前涉獵極深,但後來,我轉而研究其他現象了', '現在我想你展示今天所發生的交通事故', '所以我鼓勵你們拿起一些黏土,拿一些鹽、一些糖,然後開始玩。', '第一,你可以用你的腳步、耳朵和鈔票去音樂現場。', '我最喜歡的片段是在道金斯教授作嘔的時候。', '不只是很大聲很招搖的。', '謝謝各位', '曼哈頓居民平均汽油消耗之低是美國其他地方1920年代以來所未見耗電量是達拉斯的一半', '目前用封閉光生物反應器的問題有:設備成本高,都採用自動化操作,難以用於大規模生產。', '機器學習其實還在起步階段,而這讓我感到無比興奮。', '這些問題已經存在很久了,', '科學創造理解事物的方式', '獸醫檢查過沒問題也可以釘馬蹄鐵但你就是不能騎牠', '而下一個企劃,是由這位藝術家jaochimparisvega帶來,他有興趣的主題是--他相信藝術在各個角落待命--需要一點刺激讓它發生。', '它從一個地方獲得利潤然後將它們交給生態資源保護。', '事件發生以後,假如我當時沒有機會接受優質的手術治療的話,可能就會引致一場大災難。', '那不是上帝在說話,好嗎?', '我們打算去沒有人要去的地方,而且也沒有人可以去的地方,在三周後,我們了解了一些事。', '這字眼好像只讓我們興奮的準備我們將有的第一次的宗教交流和告解,我們還以為這些都只是跟白裙和白面紗有關的,', '這是一個謎一直是極難被釐清的謎。', '所以,不能總是只展現出最先的或最有名的人事物,我們也有責任要展現出平凡星期六的美容院,門把式耳環的藝術......', '我指的損失是像恐龍消失了一樣,真的沒有了,再也看不見了。', '而我不會花任何時間來解決她的問題,因為我沒興趣。', '你的軍服的每一寸都要維護好。', '信不信由你,我們是要保護他的安全。', '在這個過程中,非洲的自主權已經被剝奪', '我該如何在十分鐘內說完聯結三個世代的女人的故事還有他們身上緊密關係是如何在生命裡展現力量又是如何影響一位四歲的女孩三十年前她和妹妹還有母親和祖母在一艘在中國海的小船上擠了五天五夜', '越南軍甚至誘使美軍對山腳進行轟炸以取得建造和維護道路所需的礫石', '你不太相信訊息。', '但即使有了真實隨機數字產生器,我們還要面對第二大的網路威脅:安全金鑰交換的問題。', '歹徒經常做出那些你常常在電視都看得到的橋段', '我和團隊與頂尖大學以及國防部門合作,使這項讓人興奮的技術能更成熟,成為下一代的安全產品。', '這個蒐集土壤的舉動本身能帶來某種形式的精神慰藉。', '但不該主導教育文化', '你人生中除了在不得已的情況下,還有什麼時候你會願意把錢給政府?', '你一定得這麼回答,\"媽媽,人性就是我的事。', '這是基於一個現實的假設,我們已經達到了開採巔峰', '就這樣被忽略了']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  55%|█████▌    | 2200/4000 [34:44<28:35,  1.05 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130.52285766601562\n",
            "是斯斯的「不的因為是,的因為「的「的,。。的。的。。的的。。。。。。。。。。。。。。。。。。。。。。。的。。。。。。。的。。。。。的。。。。。。的。。。。。。的。。的的。。。。。。的的。的。。。。。。。的。。。。。。。。的。用。。的的。的。。用的。的的。的的的的的的的的的的的的的的的的人的的的用的\n",
            "['亞馬遜是世界的肺,因為它強大的功能,在森林與大氣間交換維生氣體。', '因為有\"領導人\"與\"領導的人\"', '泰國是世界上蝦子最大的出口國。', '是的,我們是怪胎。', '這真的很重要,因爲這種洞見,並不包含在任何維基百科的網頁中。', '那讓他有很深的連結。', '我稱專案的這項特徵為「並列」,現在我們就來看幾個例子。', '所以我有了個疑問', '如果珊瑚死的速度這麼快,礁怎麼能撐得過來?', '所以演化的技巧就是讓他們變得美麗讓他們擁有某種吸引力讓你光是看著他們就感到歡樂', '而我的目標是要從無中生有。', '我們在演化過程中發展出兩種發聲方式。', '而當我們無私時會有種難以言喻的狂喜我們尋找各種言詞來表達這種內心的悸動', '長久以來,我們告訴自己工具及科技可以控制大自然突然之間,我們必須面對自己的軟弱我們束手無策看著原油由地底衝出就算用盡方法也無法阻止油漏-試圖「蓋頂」、「封頂」以及最讓人難忘的,投擲「垃圾彈」--這個天才法子要發射廢棄輪胎及高爾夫球堵住地底的漏洞', '我只知道失去工作的感受,', '原因是歷史記錄以很快的速度數位化', '他們讓你活著。', '而那裡還有數以萬計的山脈還未被勘測。', '但這個故事的重點是,網路約會不一定會很爛。', '並不是很相通,但是滿值的思考的', '想像你是個頭腦。', '我知道你們之中有許多a級水準的學生,最近才剛拿到你的gcse的結果。', '而製作竹子模型也是一門藝術,也是工程的核心部分。', '」', '也可能不是', '除此以外,我也寫歌和短篇小說。', '在知更鳥的視網膜裏---這不是玩笑---知更鳥的視網膜中有種隱色素蛋白,它對光很敏感。', '因為不可能知道有多少比例的紅寶石是用非法取得之財富所購買,罰金將要透過一個益智比賽來決定,比賽是由這名商人對抗國王最聰明的顧問——你。', '在19世紀,albert王子當時建立了albert城。', '正確答案是金星表面溫度極高正如蘇聯的金星飛行器所證實金星的氣溫高達華氏900度', '如果我們扣除成本關於進步是毫無疑問的。', '在大西洋和北極海的深處格陵蘭鯊可以活超過400年而北極貝的壽命長達500年', '我們的實力奠基在「多樣性上」。', '每個人都可以這樣作。', '我和我的室友,嘉莉,一起報讀,她當時是一個傑出的文學學生--而發展成一個傑出的文學學者--而我的弟弟--聰明的傢伙,但是一個打水球的醫學預科生,是個二年級學生。', '而製造戰爭——是我們擅長的事情。', '水溫是85華氏度,你的體重開始減輕和消耗熱量,當你慢慢靠近', '當你不被允許在公開場合表達想法,你會開始擅長讀出那些沒有說出口的事。', '有些國家在試圖擺脫地雷,其他國家卻用得更兇。', '但是有一個限制']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  60%|██████    | 2400/4000 [37:53<25:16,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118.5411148071289\n",
            "所以,我我,,,我,我照片的。。。。。。。。。。。。。。。。。。。。。。。的的的的。的。的。。的,。。。。的的的的\n",
            "['所以,以他們之名,我把這張空白的幻燈片送給你們。', '蒂:謝謝。', '講者:在這段錄音被寄出給他女兒之前,他先在牢房裏聽過一遍,他哭了。', '在現代化之前的義大利,欠下大筆債務的失敗業主會被全裸地帶到公共廣場上,在廣場上,他們得要用屁股撞擊一塊特殊的石頭,同時旁邊的群眾會嘲笑他們。', '疫苗,就像其他藥物可以帶來潛在的反面影響', '它是如此艱難和怪異,以致於我們有時會想,我們是否被耍了。', 'kb:好,我現在要將它拿下來,你沒事,你沒問題。', '所以,我們開始做我們最擅長的。', '為什麼我們失去了吃蟲的胃口?', '你知道他們是為什麼盤算你的石油?', '這是件了不起的事!', '透過在一支臂桿製造延遲,干涉儀的功能就變成像是開關,放出脈衝光。', '在醫學上,我們稱這道皺摺為「過敏性敬禮徵」。', '同時這個世界於我們日常世界非常迥異,這個世界包括幾萬億原子。', '我很高興你們認同。', '像死胡同,原地打轉一樣像塞車,談話遇到僵局一樣', '我是第一代的公民。', '彈奏出好音樂,不只是在於我能彈出什麼更重要的是對音樂的聆聽', '你的人生是怎麼回事?', '地球上的科學家可以將數位指示發送到那台dbc,製造新的藥物或製造合成有機物體,來產生氧氣、食物、燃料,或建造出材料,用這種方式,讓該星球更適合人類居住。', '但這並不是好的生活。', '我們的太陽在銀河系中只是四千億顆恆星中的一顆並且我們知道許多其它星球都有其行星系統', '證據是根據什麼得到的?', '電腦使我們可以避免煩差事這可是非同小可的一件事', '我們能要求政府負責,', '我是第一個受試者。', '而對我意義最大的,又再一次的,是女性的身影。', '但接著在某個時點,新穎性從宇宙中消失了。', '這些則可以當作是相較於原始狀況的百分比這是前工業時期,1750年', '這個例子將會說明接下來事情會怎麼發生。', '所以我們換了個方法,使用十二公尺寬的道路,建築物仍保持完整,還能在不妥協掉太多建設的情況下引進城市巴士。', '然後她告訴我四年前發生的一個故事', '醫界有著很長的歷史將女性的生育過程視為疾病、需要治療的概念,而這已造成許多花費,包括過多的剖腹產、子宮切除術、及開出荷爾蒙治療藥,而藥物的傷害大於增進婦女健康。', '它聽起來是這樣的。', '我是最小的,我是妹妹。', '團員裡有個聰明的黎巴嫩人,他叫南阿布.納沙,是我們在第一次巡演時招募到的團員,他最近才到洛杉磯的喜劇名人堂裡表演過。', '\"', '「叔叔,這是什麼?', '這兩種情況都曾經世界上發生過。', '想像你的腦有以下的飛快對話:「嗯~這些方格可能蠻重要的」']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  65%|██████▌   | 2600/4000 [41:02<22:02,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122.4717788696289\n",
            "說年。。。。。,。。。。,。,。,。。,,,的。,,上的,。,的說的的的上,的,上,,的,在,的在的的的的的,的的的的的的上上的的的的「的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "['也就是五分之一的人類。', '每個孩子都有在學校喝牛奶的權利。', '我們能夠在需要的地方印出藥物。', '感謝你給出的數字', '有一些較基本的是你們可能會想要知道的。', '在時間上,從毫秒到千年同樣也是14數量級', '下面這幅圖,我們看到無論是雄性還是雌性發出的叫聲都能傳播很遠的距離。', '偽造者會製造假藥。', '我打算列出一張能力和特性的清單,我要你們想想看這些每個能力你所佔據的位置,與其它人相比', '他只是關心的方式不同要花些時間才能理解', '這是像工匠或技師一樣的工作。', '但我發現的是幾乎找不到任何人能提供這治療或護理。', '我很後悔沒有在津巴布韋大聲疾呼,我對自己發誓,做為紐約市衛生專員,我將利用每一個機會,去發警報,以及爭取對醫療平等的支持。', '這是真正的afm,原子力顯微鏡資料,這些資料來自於我在固態光學暨能源中心的同事。', '她健康地活下來,今年30歲。', '隨著我們的生活愈來愈數位化,試圖以遏止使用裝置來重拾情緒是一場必敗的仗。', '別擔心──你如果是這樣的人也沒有任何問題。', '。', '我也帶來了一個這樣的東西,演講完畢後你們可以到外面玩一玩。', '想像一下這些微型機器人穿越過碎石來尋找倖存者。', '那時候剛開始要選舉', '我不建議誰一月中旬,裸體地,坐在屋頂滴水器上', '在這樣的不公正下,弗林特市居民團結起來。', '究竟是什麼讓世界上的數學家如此感興趣呢?', '當我哭泣時,我讓他們擁抱我,', '第三部分是數位光投影系統,位於容器的下方,可在紫外光區域照明。', '為了抵抗這件事,我們不只是要更努力,而是要開創某些情境,如此其它訊息來源就不會誤導我們,這也是為何許多管弦樂隊甄選樂手時要在幕後,這樣他們接收到的就只會是重要的訊息。', 'kb:別分散我的注意力就行。', '而在我心靈交戰的核心我感到是音樂這條路選擇了我而我有點幼稚地以為skidrow這種地方需要的是像paulfarmer醫師的人而不是又一個在bunkerhill演奏的古典音樂家', '對全球農業市場來說,這個翻盤極重要。', '人們為了千百種不同的理由研究科學。', '他有一塊鐵塊', '我們讓人們給它們起名字,和它們一起玩耍、互動,大約用了一個小時。', '人們在網路社會媒體上提出各式各樣的方式,來避免思考這個問題。', '所以,當你和一群陌生人同處在一個地方,又聽到我談到性,你可能就會有嫌惡感——那很正常。', '他把這項興趣帶到醫學院,在那裡,他學到我們所有的感官間都有很深的連結。', '關懷就好比是一種監控鏡頭,它是我們腦中的低解析度監控鏡頭關懷別人決定了你是否會多活幾年。', '然而這些案例經常都沒有被裁決。', '如今計算機科學實際上有一套策略來處理軟體和硬體的功能。', '對質時,它維持溫和柔善。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  70%|███████   | 2800/4000 [44:11<18:55,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105.7579574584961\n",
            "我們天我們我們,,,,沒了我們。。。。。。。。。。。。。。。。。。。。。。。的的。\n",
            "['一旦有了導電的銅就進入情況了,', '」', '今日眾位所見的繁華在昨日並不存在。', '這基本上是為什麼有各式各樣的不信任存在於民意代表和其所代表的民眾之間', '但是時常我會把自己放在一個惡人的角度', '人類自古以來即苦於此詛咒', '」', '那是什麼?', '此處這三個碟子代表我們設計的積體電路,會大規模縮小目前的大型系統。', '但是十九世紀後期發生了改變,這是第一次,人們可以認真從事科學事業,就像自然歷史學家達爾文那樣。', '然後在這邊你們看到了同一位病患治療後六個月的x光片,你們可以看到再生的組織,當你在顯微鏡下仔細觀察後,你可以發現它已經完全癒合了。', '但,在這種突破出現之前,我們的最佳策略就是全世界的實驗室同心協力,同步投入不同的方法。', '我們得平心靜氣地想一想,小規模耕作與大規模耕作有什麼優缺點;', '至少目前還沒有', '於是我們在他的廚房中--他和他的太太judy站在一起,還有他的保鑣sean--於是我說:「就如同我在email中所說,你可能有個特別的異常頭腦,使你變得特別?', '有些很棒,運動,禱告', '粘菌在創作過程中有最後決定權。', '我十歲時得知自己是雙性人,大多數的情況下,我都能接受這項資訊。', '可以在任何時間出現在世界的任何地方', '」', '更不用提處在壓力很大的環境中了。', '讓窮人買得起也預留以後的擴張性。', '對女性的物化,媒體發揮著重要的作用。', '城市需要有權力才能發行債券、加稅、有效分區、建立負擔得起的住房。', '但我就是相信,如果我們能開始強化社區的社會結構,如果我們在最脆弱的鄰坊中推動經濟機會,這一切都始於健康、可取得、美味、與文化契合的食物。', '」', '所以由於很多原因,二次世界大戰後的數十年成為歷史上非常異常的一個時代。', '土壤只是覆蓋地表那薄薄的一層,卻有力量改變地球的命運。', '那麼,讓我們退後一步來看。', '這首歌穿越時空而來長長的時空', '我愛虛幻世界,我最喜歡做的事就是早上在姆明谷醒來,', '科學家和醫生希望,利用以上所有的幹細胞,製造出新的人體組織進行治療,同時他們也能利用幹細胞,了解人體的運作方式。', '然後我會說:「不,對不起。', '有很多詞彙固然方便很多', '小說揭除嫉妒的神秘面紗。', '愛因斯坦很喜歡這個理論', '牠們在哪裡?', '機構討厭被人家稱為阻礙。', '你還記得\"勇敢傳說\"剛上映時電影評論家說什麼嗎?', '再做一次。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  75%|███████▌  | 3000/4000 [47:19<15:42,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124.08379364013672\n",
            "我從想談這個東西,。。。。的的的的的的的的的的的的的的的的的的的的\n",
            "['我第一次來到了這個鄉村.', '因此,行星的基本特徵包括他們受萬有引力吸引而凝聚成一體這個事實。', '每年有6000名過去將死於這種疾病的兒童獲得治癒', '我發現他們的旅程都差不多,', '這邊是辦公室,這邊事實上還在競標所以我們不用去設計', '但我們決定我們何不也來辦個我們的海報宣傳活動來講一些穆斯林的優良事蹟順便推廣電影', '但不幸的是這種模式要走到盡頭了。', '但面臨耗弱健康的疾病及衰老時,他們不會費盡心思延長壽命。', '這樣讓你有一些概念關於頂峰附近的情況有多麼惡劣', '我們的研究通常會以一個問題做為開場白,', '你們可能聽說過苯環,它的致癌性很高', '那些從天而降的靈感又是什麼?', '某一天,農民可以毫無危險地耕作;', '但,我們還是要奮力朝「現在」前進。', '我們認為,要在通氣孔旁寫上「禁止進入」是不可能的', '然後我們從這裡出發,再退回去', '」', '純淨、正統性、返回到真實的傳統、追尋這些,會讓一個完美的社會和人民受傷害。', '黃金!', '在生產界線的另一邊,在規則中,用到一個很特別的詞,所謂「非主要生產者」所做的工作,是「很少或無價值的」。', '現在我們來看更小的物體,這是人的毛髮', '那個組織裡的人被稱為\"反洗腦者\"', '同樣的問題是:「是誰讓我們的社區在911之後又重新恢復運作?', '書的作者是一個鋼琴家,他在書中詳細地記錄了自己職業生涯中所觀察到的事實,那就是音樂在非常狀態下的人身上,所能發生的不可思議的效應。', '它高度商業化。', '他們還會在婚禮那天一起發酒瘋然後用蛋糕砸對方的臉,', '這是我很景仰的一位朋友弗朗西斯.柯林斯美國國立衛生研究院的院長這是去年我們在tedmed聊天的照片', '2003年,我離開純資本主義部門到所謂的社會部門工作時,我完全沒有任何遠大的策略或計畫要追求和尋找可營利的方式來解決迫切的公共議題,', '日立現在以這項科技發展了一種顯像器,並用在光纖上以傳輸—珍妮‧班娜斯來談過很多次:就是仿生學。', '其中最顯著的是心理上的的益處對長期或短期而言都是如此', '於是我們開始懷疑:如果連受過高等教育的我們,都對月經一事誤解這麼大,一定有數百萬的女性也對月經不清不楚。', '這就是我們特別興奮的計劃它下個月就會開始', '對於腸道微生物群來說較少的纖維意味著較少的燃料本質上使微生物群挨餓直至他們相繼死亡', '在五十年前,這觀點被認為相當有道理', '一旦啟動模擬它就會像這樣跌倒,就像這樣', '它們只需要專心成長和分裂,成長和分裂。', '但,氣候危機已經被解決了。', '它們會有個小電梯和圍繞著電梯的樓梯,還有個採光天井。', '但是我仍然記得在我離家,橫跨美國大陸到微軟開始新工作時的一景。', '在你心臟病發之後會發生甚麼事,這個阻斷?']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  80%|████████  | 3200/4000 [50:27<12:32,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "122.5523681640625\n",
            ":aymad:::有了。好。。。。,。。,。。。。?。。,,。,,,。,,。。的。,?,。了的的。的的人了??\n",
            "['citizenkane,玫瑰--:玫瑰花蕾。', '」', '世上最有名的雕像', '我們會這麼做有很多原因', '這全都來自深思熟慮的權衡,在其他業者都有自己角色的更大生態系統中,它決定扮演協作者的角色,而不是扮演唯一的贏家、英雄,獲利並非它全拿,最終它只拿一點點。', '如果你想要看清楚一個人真正的樣子,或許你需要的是改變你的角度。', '我們做小型的學校,我們提供獎學金,我們幫忙修建圖書館。', '朱利安:嗯...', '我們不是被拋棄在路旁的車子然後就在高速公路上放空而如果某方面來說我們是如此的話,不要擔心', '二者透由交換光子來彼此互吸,而光子就是光的量子,帶著電磁力,那是標準模型基本力之一。', '我瞭解,我也很難啟齒', '在英國,自從1969年起,有1900間教堂被關閉,原因是集會縮減,而在非洲,每一天,就有一間教堂或清真寺被建立起來。', '也就是氦的英文名是\"helium\"', '2。', '他需要暫時做這個分界的保護者', '那是好事──他無須相信我。', '但jenniferlee開始質疑這是否合理。', '兩種指標成正比,出乎意外', '其次,呼氣分析為非侵入式,就像是對著酒精濃度探測機呼氣那麼簡單。', '我最終決定,這問題是錯誤的因為這問題並不重要', '難民有充分的時間來為回歸祖國做準備。', '布羅希:這裡的人認為,我當時的年紀,在村莊裡,應該是要當祖母了,', '他轉過身,對著她。', '巾幗之約光復領袖艾德拉為救世雙俠當明燈指引到第一枚瑰寶:力量之泉', '但是直到我們發揮技能,習慣,天賦以及道德上的勇氣去利用它事實才會讓我們自由。', '他們成功的程度到了他們已經開始拓展這個計畫到他們投資組合的其他部分。', '我想一個世紀前,許多人會說,累進式所得稅不可行,但後來卻實現了。', '我就不斷寄信問', '也許這些孩子的際遇讓我感到難過,但他們鼓舞了我。', '不過若你回顧更早些年,一切不言自明。', '她其實是個藝術家,', '在我們尋找下一個太陽系新家園時,我們不太可能把太多時間花在旅途上、太空中、在一艘像密封罐頭的太空船中,因為這可能會要好幾個世代的演化才行。', '在今天日本所在的地區人們用稻米製作清酒', '他們隨時穿著-他們穿著盔甲吃飯,他們穿著盔甲睡覺。', '首先,我們先簡單地回顧史塔西的歷史,因為這很重要,有助於我們了解它所代表的意義。', '比如,我們知道有五種基本味道,但我們強烈懷疑應該還有更多,事實上,用我們的eeg計畫,我們找到證據證明,除了能感受到脂肪的質地和氣味之外,也能嚐得出來。', '甚至可以作的更好一點,我們用影片紀錄填加水的過程,', '愛鸚斯坦:唔!', '女性佔人類人口的51%', '嚴格來說那裡存在著電磁場但就本質而言那裡是空的']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  85%|████████▌ | 3400/4000 [53:35<09:25,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "136.5943603515625\n",
            "是,,,在在,知,,的而發,,,,,其他,,類的,而會被把掘。。。。。。。。。。。。。。。。。。。。。。。。。。。。。的。。。。。。的。。。的。。。。。。。。。的。。的。。。。的。的。。。。。的的。。的。。。。。的。。。。。。。。的。的。。的的。。。的。。。的大。的。。了。的。。。。。的。。。。的。。了。。。的的的。的。。。。。。。。的的的的。的。的。的。。的。。。。的。。的的。的的。的的。的的的的的的的。的。的的的的的的。。。的的。的的大。了。的的。。的的的的。的。。的。的。。。。有的的了的的的。的的了的的的的的的的的的。的的的的的。。的的的的的的的的的的。的的的的的的的大的的的。的的的的\n",
            "['一個人造的、大家都看得見的月亮,激發了人們敬畏及崇敬之心,人類終於可以發射一個物體進入太空了。', '這裡有個哈佛大學開發的可愛的小伙子,由身體上施加的壓力波而行走;並且靈活到可以在低矮的橋下潛行,一直走,一直走,然後有些不同。', '要知道這些漁網裝滿魚的時候重量有上千斤啊!', '現在有尼安德塔人的基因組在手作為參照,還有先進的科技技術可檢測古代的殘骸和萃取dna,我們便應用這些技術資源在世界各地的研究。', '這麼個小問題花了研究團隊兩年才解決', '我們有催產素聯繫著我們和別人讓我們感受到他們的感受', '但無論採取何種方式,我最喜愛用的兩種素材就是歷史和對話。', '我一年裡拍攝約5000多張照片我想我可編輯一下這些照片從中找些可能適合而且感興趣的照片給大家看', '我們難道不能製造更好的烤爐嗎?', '這意味著我們要思考材料,在這些材料變成商品、被使用過後,以及在它們壽終正寢時:它們何時可再次被利用?', '」', '」61是個聰明的女孩,她沒有急著吃醋。', '讓我聼聼你的反應', '所以未来的实验还是很有意思的', 'rct的關鍵是,受試者將隨機地被分配到各研究小組。', '也有人認為姥鯊數量的減少是反映溫室效應的指標因為牠們最能反映浮游生物的狀況成天嘴巴開開游來游去的國際自然保護聯盟已將姥鯊列為「瀕危」狀態', '跟黑猩猩大腦容量比例一樣', '因此當時我們很小心。', '再往下去,你就會到前代數和早期代數', '轉動它時可以看到包含其中的很多錯綜複雜的圖案', '沒人會和流浪漢一起吃午餐的。', '我當時研究的是物理學,有天回到家裡時,我突然意識到,我家裡就有一台3d印表機。', '是你大腦的作業系統,', '事實上,各位聽我講話的時候這種現象也正在你的大腦裏發生;', '他有個比喻:「我們把開合橋向上拉或是向下放?', '這對我們非常重要。', '以我為例:「我一直在投資,我已經獲利數千萬美元,', '減肥佔用了意志力──這些原本可以用在其他地方──比如輔導自己的孩子做功課,或者完成重要的工作,又因為意志力是有限的,而任何減肥的策略都會持續地消耗意志力這基本上保證了,一旦注意力轉移到其他地方時飢餓就會趁虛而入。', '這麼做的唯一理由,就是想讓更多人從中受益。', '我要給你幾個例子。', '即使我們很忙,我們有時間做要緊的事,', '它們築在山丘上跟里約的沙灘比起來算是內陸你可以看到房子懸在天然障礙物上', '好吧,我把我的ipod,手機和電腦叫做是科技可是這和我的小提琴又沒有關係', '他們的金髮與希芙的頭結合之後,持續增長,讓她比以前更容光煥發。', '然而你們可能不知道的是,另一組名字也都是非裔美國人同樣在過去的兩年內被殺害。', '我們完全沒有做任何實驗。', '其實在某種程度上,這是一種挑戰:如何把一個好的想法付諸行動。', '我堅信當人們獲得這種自信正如我們一直以來在斯坦福設計學院和ideo公司看到的人們開始研究生命中真正重要的東西', '但是他們很願意我們將其他領域的技術已經經過安全試驗的裝置運用到這個專案中去。', '他們在推廣人口密度,新的人口密度,比地球上所有人做的更好。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  90%|█████████ | 3600/4000 [56:43<06:15,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107.54219055175781\n",
            "兩部分的是是,禁,,,倍人。。的。。。的,的的的的的的的的的的的的的的的的的的的的,的的的的的的人的的的的的的的的的的有的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的大的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "['小兒痲痹的監控系統是四百萬人挨家挨戶去尋找。', '而我認為,如果我們沒有什麼力量能阻止這類事情,那就太瘋狂了,因為我們其實是有可能做到的。', '」', '我那時規劃了四個步驟:', '很快的引發許多人批評此一工作小組而其中許多人甚至根本不熟悉乳房x光攝影術', '\"為什麼是現在?', '但最重要的是,現在我知道,若要教導人與人之間如何溝通,這件事應該要由人類來做。', '好,千禧世代,這是我所發現關於我們的資訊。', '為什麼?', '每一種分子只能與其相對受器結合,非常專一。', '現在我要播放一段影片給你們看一個出生就失去聽覺的女孩', '一個孩子,他的名字我忘記了,他大概有七到八歲確定被認定為弱智的不能讀,甚至不能在低年級讀虽然身在学校,心已经飞走了。', '你對貝多芬的一切所知基本上是錯誤的。', '此外,我的父母和朋友們的父母只靠開計程車和當清潔工好像也過得不錯', '我認為,如果你能想像這樣的辯論輸掉的一方能對贏的人觀眾以及陪審團說「對阿,這是一場很棒的辯論。', '他們不是等到死後才設立基金會,', '我不是歷史學家女士們先生們', '我們可以用現代的電腦術語來說就是一種「讀--寫」文化', '一片麵包能充飢,懷抱希望則能救命。', '這巫師說:「沒有,沒上過。', '弗拉季米爾:咱們等著看他會說什麼。', '看起來這樣的。', '「二十世紀的拳擊巨星」是的,', '如果沒有人要說我們的故事,讓我們來說', '查:我真希望那些音樂家現在就在這裡你就能親眼看到他們多麼絕頂出色', '我在澳洲社區長大,在那裡,人們變老或生病,然後過世,只有成人會出席葬禮。', '為甚麼不呢?', '當這個結果出來時,它只是一個令人非常興奮的事情,一個使盲人視網膜有回應的概念。', '取而代之的,我們可以利用它作為跳板並且將我們最好一面表現出來並過著更快樂的生活。', '我知道多數人不這麼認為', '\"', '如果我有孩子和孫子,也許他們會和我共度那一天。', '顯然,類似deankamen從事的這種非凡工作—但是你可以向很多慈善機構捐助電腦,幫助受傷的士兵.', '這是我的第四次聖母峰之旅這個是百武彗星,剛好畫過山際', '在印度,我發現情況也好不到哪裡去', '他認為道德是一個在此時此地用我們最好的判斷決策的問題,來找到正確的道路。', '我要做那個。', '沒錯,我們正嘗試解決這些問題,但解決了問題後是甚麼境況?', '1869年,格里戈里·葉菲莫維奇·拉斯普丁出生在西伯利亞的一個農家。', '這片段取自影片《在一起我們就能自由》,記錄了拯救活動以及我努力接觸歐普拉的嘗試。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  95%|█████████▌| 3800/4000 [59:50<03:07,  1.06 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.52608489990234\n",
            "」。。了了了了的了了的的的的的的的的的了的的的的的的的的了\"的的的的的的了的的的的的的的了的了的的的的了的的的了的的的的的的的了的的的的的的了的的了的了的的的的的了的的了的的的了的的了的的的的的的的的的的的的的的的的的的的的的的的了的的的的的的的的的的的的的的的的的的的的了的的的的的的的的的了的的的了的的的的的的的的的的的了的了的的的的的的的的的了的的的的的的的的的的了的的的的了的的的的的的的的的的的的的的的了的的的的的的的的的了的的了的的的的了的的的的的的的的的的的的了的的的的的的的的的了的的的的的的的的的的的的的的的的的的的的了的的的的的的的的了的的了的的的的的的的的的的的的了的的的的的的的了的的的的的的的的的的的的的了的的的的的的的的了的了的的的的的的的的的的的的了的的的的的了了了的的的了的的的的了的的的的了的的的的的的的的的的的的的的的的的的的的了的的的了的的的的的的的的的的的\n",
            "['」', '跟這肉相比,光散射到各處。', '還會有一條不可遺傳的染色體。', '需要多少的家畜才能產生這些呢?', '謝謝', '這正是我們10年前進行的研究', '你們又默認什麼呢?', '那你應該免疫啊。', '我們正是千里達共和國的產物,', '比利:不是的,如果我們想要探討的話—我正進行一個小規模調查', '我們是怎麼做到的?', '那是種經驗法則。', '我想這應該不是他想要的答案。', '曾獲勝的詞包括「recombobulationarea」指的是密爾沃基機場過安檢後旅客的重新整頓區', '我們治療的孩童比參與計畫的更多。', '當你想想背後的涵意,這是簡短的宇宙歷史', '但我對我自己的能力有了新的認識。', '在哪裡聽過它?', '到下一階段,接下來的四天裡,我們會探討更多這樣的想法。', '但是,還有一點讓我個人覺得特別受不了的我想先從\"窮人\"的定義談起', '而這個典範不一定是對我們健康最有益處的。', '癌症可能要長達20年才會出現症狀如果定期檢查我們可以發現子宮頸細胞異常在它們發展成癌症前就看出來', '但,我仍然相信這些荒唐、瘋狂的小型體驗,可以啟發大家對於別人呈現給我們不完整的實境事物時,能夠保持存疑的態度。', '」', '」', '當孩子來到這裡他們會接觸到很多東西如木頭、釘子、繩子、輪子等等。', '考慮微生物隨著人們四處傳播你或許預期相距不遠的房間存在十分相似的生物群落', '」', '我們花了五個星期去重建教會。', '你看,要有原創性並不簡單,但我對此深信不疑:這是我們改變世界最好的方法。', '在過去的三十年之中,我們發現許多活在各種極端環境的微生物。', '你覺得有在做事,你覺得很忙。', '第一個理由是:如果我們的心靈像一塊白板,根據定義,我們就是平等的,因為0等於0等於0等於0。', '我的意思是,當我自己一個人在電梯時,我會做很多奇怪的事,但當有其它人進到電梯時,我停止做這些事,因為我不想要打擾他們,或是說嚇壞他們。', '然後我問營區的管理員,33萬人中有多少人是在那裡出生的。', '各位可能都聽過哈柏望遠鏡以及天文台。', '現在再放更大些,你可以看見裂痕了', '女人說:\"也許一年、十年,也許我一年內就死了或什麼的\"', '但這説明了比喻如何誤導我們', '藍色與綠色的地方代表水溫非常冷。']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step: 100%|██████████| 4000/4000 [1:02:57<00:00,  1.06 step/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115.46831512451172\n",
            "當你時你的的斯坦時你,時東西限的一自己的你是什麼敢的的的的\n",
            "['如果你選擇把身體因壓力而產生的反應當作有益的那你自然而然會有勇氣去面對', '保時捷。', '在那邊有很多空曠的空間利於飛機的起降不用擔心製造噪音或是撞到高樓大廈', '它們會不會住在農作物中負責除去害蟲?', '此外,也讓他們知道,有他們所需的一切,在將來能夠靠自己來解決這些問題,或甚至避免這些問題,透過溝通來避免。', '卡車把他帶到了工廠在那裡他跟同伴們被壓平以及擠壓成塊', '基本上,它的一種作用在它所橫越過的組織上的力量。', '所得超過全國的8%', '而根除小兒麻痺症,在很多方面又更加困難有幾個原因', '另外,不願分享的情形到處可見。', '它們的比例可以讓我們知道海水的溫度。', '她在塔利班的襲擊名單裏。', '但後來某些人在對的時機,身處對的地方那些在八十年代中後期擔任幫派老大的人個個發了大財', '不論你是非營利、營利,或自付帳單,皆是如此。', '我問:「那你從事這行多久了?', '幾乎所有東西不會含多過一種的原料因為它們本身即為一種原料', '所以故事像是當我們在消化政治資訊時、當我們在閱讀小說時,餵給我們吃的糖果。', '你有兩樣東西可以利用', '他們獨來獨往,從無怨言,一心只專注於他們的計劃。', '這種未來的空氣有一些可感知的特性。', '所以,在亞馬遜,在一個平常陽光燦爛的日子,一棵大樹能透過它的蒸散作用,轉移一千公升的水——一千公升。', '在這個地球上,此刻我們面臨著蠻嚴苛的環境挑戰', '我想告訴各位網際網路和連結已經創造出新的心態', '沒有吸氣。', '這是很多人游泳的問題。', '我們兩邊都很吃驚因爲這些標簽跟我們認識的對方完全不符合。', '而且那是最初幾款你可以自主選擇音樂的視頻遊戲中的一款', '當然,他們不是經常吵鬧及哭叫但有著三個男孩,其中一個會不規矩的機率是很大的其實他是應該的', '而且他們做的第一項嘗試就是完全保留了漫畫的翻頁然後直接移植到螢幕上這是個典型的麥克盧恩式錯誤沿用舊科技採用的型式作為新科技的型式', '這完全取決於產生螺旋的旋轉角度。', '我們提供了二萬六千個小時的精神健康服務予一萬多名難民。', '綜合這些變化,會增加心臟病發作或中風的機會', '在大壺節的成功鼓舞了我,讓我想要協助其他可能受到蜂湧群眾所苦的人。', '」在接下來的十八個月,那些文字開花結果成了《百年孤寂》。', '生物列印機能讓我們發揮讀寫dna的能力,並讓我們所謂的生物電子傳送開始被重視。', '透過嚴密的過程我們給員工較少的控制權較少的選擇但能提供更多更豐富的人際互動', '一些tedsters也在這裡。', '他們的數量眾多,我只能挑其中一些。', '假設我要你回憶一件事,就像,那是什麼?', '這是怵目驚心的數字。']\n",
            "115.46831512451172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvalid_step:   0%|          | 0/39 [00:00<?, ? step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   2, 2174], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5],\n",
            "       device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175],\n",
            "       device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286],\n",
            "       device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,   26, 2183,  241, 2177],\n",
            "       device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,   26, 2183,  241, 2177,    3,    0,\n",
            "        2183,  241, 2177,    3,    0, 2177,    3,    0], device='cuda:0')\n",
            "tensor([   2, 2174,  360,    5, 2224, 2175,    5,    9, 2247,    5, 2220,    5,\n",
            "         126, 2175,    5, 2224, 2175,    5, 2220,    5,  126, 2175,    5,  126,\n",
            "        2175,    5, 2183,  241, 2175,    5, 2196, 2247,    5, 2196, 2247,    5,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,    5, 2286, 2196, 2247,    5, 2286,\n",
            "        2196, 2247,    5, 2286, 2196, 2247,   26, 2183,  241, 2177,    3,    0,\n",
            "        2183,  241, 2177,    3,    0, 2177,    3,    0, 2177,    3,    0,    3,\n",
            "           0,    3,    0, 2173, 2177,    3], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rvalid_step:   0%|          | 0/39 [02:50<?, ? step/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5cdf0a606eaf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_is_prepare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# gc.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-5a4a1fba6304>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(setting, dataset_is_prepare)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         avg_val_loss,avg_bleu_score = valid(\n\u001b[0m\u001b[1;32m    160\u001b[0m                         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-cceebb3f9676>\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(device, model, loss_calculator, batch_size_setting, valid_loader, beam_num, max_sentence_length, dictionary_length, bos_id, eos_id, pad_id, tgt_tokenizer)\u001b[0m\n\u001b[1;32m     34\u001b[0m                             dictionary_length,bos_id,pad_id)\n\u001b[1;32m     35\u001b[0m         \u001b[0mdecode_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs_in_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_last_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# outputs_in_word,outputs = decode_with_beam_search(device,is_last_batch,model,src,src_mask,beam_num,\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#       max_sentence_length,dictionary_length,bos_id,pad_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5ead7ee18a3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, is_last_batch, src, src_mask)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# decoder_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# decoder_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         new_decoder_beam_expand , new_decoder_probability = self.get_next_word(is_last_batch,memory_beam_expand,\n\u001b[0m\u001b[1;32m     66\u001b[0m         decoder_beam_expand,decoder_probability,id,batch,beam_num,padding,repeat,row)\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5ead7ee18a3e>\u001b[0m in \u001b[0;36mget_next_word\u001b[0;34m(self, is_last_batch, memory, out, out_probability, id, batch, beam_num, padding, repeat, row)\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0;31m# out_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0;31m# out_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mout_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeam_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_add\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5ead7ee18a3e>\u001b[0m in \u001b[0;36mbeam_search_one_step\u001b[0;34m(self, batch, beam_num, repeat, row, sentences, p_sentences, n_beam_output)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;31m# sentences_expand : {type : tensor , shape : batch X (beam_num X beam_num) X now_sentences_length ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0;31m# value : [[[A,B...] X beam_num times,[C,D...] X beam_num times}...] A,B,C,D...are int}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0msentences_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;31m# topk_prob : {type : tensor , shape : batch X beam_num X beam_num, value : log_softmax probability}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save({\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'loss': loss,\n",
        "#             ...\n",
        "#             }, PATH)\n",
        "# model = TheModelClass(*args, **kwargs)\n",
        "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "# checkpoint = torch.load(PATH)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# model.eval()\n",
        "# # - or -\n",
        "# model.train()"
      ],
      "metadata": {
        "id": "NAQywvDycPXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import datetime\n",
        "# from pathlib import Path\n",
        "\n",
        "# def set_logger(log_name : str):\n",
        "#     \"\"\"write log under given log_path\"\"\"\n",
        "#     log_dir = Path(\"./log\")\n",
        "#     log_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     log_path = log_dir / f\"{datetime.datetime.now().date()}.log\"\n",
        "\n",
        "#     logger = logging.getLogger(log_name)\n",
        "#     logger.setLevel(logging.INFO)\n",
        "#     formater_s = logging.Formatter(\"%(name)s [%(levelname)s] %(message)s\")\n",
        "#     #formater_f = logging.Formatter(\"%(asctime)s - %(name)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "#     if not logger.handlers:\n",
        "#         \"\"\"\n",
        "#         # logging to file\n",
        "#         file_handler = logging.FileHandler(log_path)\n",
        "#         file_handler.setFormatter(formater_f)\n",
        "#         logger.addHandler(file_handler)\n",
        "#         \"\"\"\n",
        "#         # logging to console\n",
        "#         stream_handler = logging.StreamHandler()\n",
        "#         stream_handler.setFormatter(formater_s)\n",
        "#         logger.addHandler(stream_handler)\n",
        "\n",
        "#     return logger\n",
        ""
      ],
      "metadata": {
        "id": "RaaYZopHC5c3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}