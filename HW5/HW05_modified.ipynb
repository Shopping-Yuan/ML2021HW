{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML2021HW/blob/Shopping_vscode_branch/HW5/HW05_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n",
        "###Part 0 setting and installing package\n",
        "------\n",
        "###Part 1 preparing data set\n",
        "------\n",
        "######load data file\n",
        "######clean data\n",
        "######pick up line pairs\n",
        "######tokenize : using sentencepiece\n",
        "######make data set\n",
        "------\n",
        "###Part 2 make model\n",
        "------\n",
        "######positional encoding layer\n",
        "######multihead attention layer\n",
        "######encoder layer(s)\n",
        "######decoder layer(s)\n",
        "######transformer layer\n",
        "------\n",
        "###Part 3 training and validation process\n",
        "------\n",
        "######Noam optimizer\n",
        "######label smoothing\n",
        "######beam search\n",
        "######bleu\n",
        "######training and validation function\n",
        "######main function\n",
        "------\n"
      ],
      "metadata": {
        "id": "WTv4XN2qB_fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting\n",
        "======\n",
        ">Here are all parameters using in this project."
      ],
      "metadata": {
        "id": "iVQ2D_mLcx4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setting = {\n",
        "# information of the path of dataset\n",
        "\"data_info\" : {\n",
        "    \"drive_path\":\"/content/drive\",\n",
        "    \"document\":\"/content/drive/MyDrive\",\n",
        "    \"raw_file_name\":\"/ted2020.tgz\",\n",
        "    \"unzip_path\":\"/train_dev/\",\n",
        "    \"source\":{\n",
        "        \"lang\":\"en\",\n",
        "        \"raw_data_path\":\"/train_dev/raw.en\",\n",
        "        \"clean_data_path\":\"/train_dev/clean_en.txt\",\n",
        "        \"tokenized_train_data\":\"/train_dev/tokenized_train_data_en.txt\",\n",
        "        \"tokenized_val_data\":\"/train_dev/tokenized_val_data_en.txt\"\n",
        "        },\n",
        "    \"target\":{\n",
        "        \"lang\":\"zh\",\n",
        "        \"raw_data_path\":\"/train_dev/raw.zh\",\n",
        "        \"clean_data_path\":\"/train_dev/clean_zh.txt\",\n",
        "        \"tokenized_train_data\":\"/train_dev/tokenized_train_data_zh.txt\",\n",
        "        \"tokenized_val_data\":\"/train_dev/tokenized_val_data_zh.txt\"\n",
        "        }\n",
        "},\n",
        "# tokenized setting for spm\n",
        "\"tokenized_setting\" : {\n",
        "    \"vocab_size\" : 8000,\n",
        "    \"character_coverage\" : 1,\n",
        "    \"model_type\" : \"bpe\", # \"unigram\",\n",
        "    \"input_sentence_size\" : 400000,\n",
        "    \"shuffle_input_sentence\" : True,\n",
        "    \"normalization_rule_name\" : \"nmt_nfkc_cf\",\n",
        "    \"pad_id\":0,\n",
        "    \"unk_id\":1,\n",
        "    \"bos_id\":2,\n",
        "    \"eos_id\":3,\n",
        "    \"max_l\":400\n",
        "},\n",
        "# model structure setting\n",
        "\"model\" : {\n",
        "      \"encoder_embedding_dimension\" : 256,\n",
        "      \"decoder_embedding_dimension\" : 256,\n",
        "      \"feedforward_dimension\" : 2048,\n",
        "      \"num_heads\" : 2,\n",
        "      \"dropout_p\" : 0.0,\n",
        "      \"layer_num\" : 6\n",
        "},\n",
        "\n",
        "# setting in training and validation process ,\n",
        "# including optimization setting.\n",
        "\"training_hparas\" : {\n",
        "    \"total_step\" : 200000,\n",
        "    \"do_valid_step\" : 40000,\n",
        "    \"early_stop_step\" : 2,\n",
        "    \"temp_save_step\" : 1000,\n",
        "    \"train_batch_size\" : 40,\n",
        "    \"valid_batch_size\" : 100,\n",
        "    \"workers\" : 0,\n",
        "    \"label_smoothing\" : 0.1,\n",
        "    \"beam_num\" : 2,\n",
        "    \"optimization\":{\n",
        "        \"factor\" : 2,\n",
        "        \"warmup\"  : 4000,\n",
        "        \"optimizer\" : {\n",
        "                \"lr\" : 0,\n",
        "                \"betas\" : (0.9, 0.98),\n",
        "                \"eps\" : 1e-9,\n",
        "                \"weight_decay\" : 0.0001\n",
        "                }\n",
        "            },\n",
        "    \"model_saving_path\" : \"/content/drive/MyDrive/model.pth\",\n",
        "    \"model_temporary_saving_path\" : \"/content/drive/MyDrive/temporary_model.pth\"\n",
        "}\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "id": "-WoR-01STMor"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing package\n",
        "------"
      ],
      "metadata": {
        "id": "cdURO12Sntrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used in part 1\n",
        "!pip install sentencepiece\n",
        "# used in part 1 and 3\n",
        "!pip install tqdm\n",
        "# used in part 2\n",
        "!pip install torchinfo\n",
        "# used in part 3\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7ti-UGuHNhh",
        "outputId": "13754d79-e12e-4c3d-eeeb-4563108999bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing data set\n",
        "=============\n",
        "\n",
        "load data file\n",
        "-------------\n",
        ">Here I load dataset from my drive,  \n",
        ">but it also can be download from the link below."
      ],
      "metadata": {
        "id": "mMkT3K4JXs60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1 : download dataset from drive to google colab\n",
        "# original dataset is in \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\"\n",
        "\n",
        "path_doc = setting[\"data_info\"][\"document\"]\n",
        "rawdata_file_name = setting[\"data_info\"][\"raw_file_name\"]\n",
        "rawdata_file_path = path_doc + rawdata_file_name\n",
        "unzip_path = path_doc + setting[\"data_info\"][\"unzip_path\"]\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive_path = setting[\"data_info\"][\"drive_path\"]\n",
        "drive.mount(drive_path)\n",
        "\n",
        "# copy file from drive\n",
        "# import shutil\n",
        "# shutil.copyfile(path_doc + rawdata_file_name, rawdata_file_path)\n",
        "\n",
        "# step 2 : unzip dataset\n",
        "import tarfile\n",
        "# open file\n",
        "file = tarfile.open(rawdata_file_path)\n",
        "# extracting file\n",
        "file.extractall(unzip_path)\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X23RaTWe9hoU",
        "outputId": "191a40c0-2d3e-45fb-e185-31b09476a359"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean data\n",
        "------\n",
        ">First each dataset (source or target) is clean  \n",
        ">seperately, change to halfwidth and remove/replace  \n",
        ">some kind of punctuations.\n",
        "\n",
        ">Also because the number of sentences in one line may be  \n",
        ">different in line pairs of source and target set (its an error),  \n",
        ">some special punctuations is add to the end of sentences  \n",
        ">for the next process dealing with these problem by  \n",
        ">using sentence pairs instead of lines pairs to form datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "-y54N2UNimor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "# convert fullwidth to halfwidth\n",
        "def to_halfwidth(string):\n",
        "  return \"\".join(unicodedata.normalize('NFKC',letter) for letter in string)\n",
        "def clean_s_zh(s):\n",
        "    s = to_halfwidth(s)\n",
        "    # step 1 : delete — _\n",
        "    delete = \" _()[]\"\n",
        "    delete_rules = s.maketrans(\"\",\"\",delete)\n",
        "    s = s.translate(delete_rules)\n",
        "\n",
        "    # step 2 : replace “” with \"\"\n",
        "    to_be_replace = '“”'\n",
        "    replace = '\"\"'\n",
        "    replace_dict = dict(zip(to_be_replace,replace))\n",
        "\n",
        "    # step 3 : add **END** before and after punctuation\n",
        "\n",
        "    \"\"\"\n",
        "    The number of sentences in one line may be different\n",
        "    in line pairs of source and target set.\n",
        "    \"**END**\" is add after \"。!?\" and \".!?\", which can be used\n",
        "    to check if the number of sentence in the pair are equal\n",
        "    in the next process.\n",
        "    also in english, \".\" may be use in abbreviation,\n",
        "    these different use must be identified.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    punctuation = \"。!?\"\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "\n",
        "    replace_rules = s.maketrans(replace_dict)\n",
        "    s = s.translate(replace_rules)\n",
        "\n",
        "    zh_list = s.strip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "    return zh_list\n",
        "\n",
        "def clean_s_en(s):\n",
        "    s = to_halfwidth(s)\n",
        "\n",
        "    replace_dict = {}\n",
        "\n",
        "    delete = \"-()[]\"\n",
        "    for char in delete:\n",
        "      replace_dict[char] = \"\"\n",
        "\n",
        "    punctuation = \"!?\"\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "    replace_rules = s.maketrans(replace_dict)\n",
        "    s = s.translate(replace_rules)\n",
        "\n",
        "    # Identify if \".\" is used in abbreviation,\n",
        "    # if not, add \"**END**\" after it.\n",
        "    pattern = re.compile(r\"(?<!([.\\s\\r\\n\\f][a-zA-Z]))[.]\")\n",
        "    s = pattern.sub(\"**END**\",s)\n",
        "\n",
        "    # test pattern\n",
        "    # pattern = re.compile(r\"(?<!([.\\s\\r\\n\\f][a-zA-Z]))[.]\")\n",
        "    # result = pattern.sub(\"**END**\",\"There are many people in U.S. w.r.t. in Taiwan.Thank you.\")\n",
        "\n",
        "    en_list = s.strip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "    return en_list"
      ],
      "metadata": {
        "id": "5dwWeVz-sPI2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pick up line pairs\n",
        "------\n",
        ">pick up line pairs has equal number of sentences and  \n",
        ">split them into sentences to form sourse/target dataset.  \n",
        ">Remove sentences with too many words for training and validation."
      ],
      "metadata": {
        "id": "M2EfnpIXV91l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using \"**END**\" to split line pairs to check if they have equal sentence\n",
        "def divide_by_END(s):\n",
        "    list_s = []\n",
        "    for line_string in s.strip(\"**END**\").split(\"**END**\"):\n",
        "      if line_string not in [\"\",\" \"]:\n",
        "         list_s.append(line_string)\n",
        "    return(list_s)\n",
        "'''\n",
        "warning : devide_en_again function is apply just beacause\n",
        "in \"this\" dataset english sentences end with \":\" or \";\"\n",
        "sometimes not splited well.\n",
        "If the dataset is change, this part may need to be\n",
        "eliminated or modified.\n",
        "'''\n",
        "def devide_en_again(s,punctuation = \":;\"):\n",
        "    replace_dict = {}\n",
        "    for char in punctuation:\n",
        "      replace_dict[char] = char + \"**END**\"\n",
        "\n",
        "    replace_rules_src = s.maketrans(replace_dict)\n",
        "    new_s = divide_by_END(s.translate(replace_rules_src))\n",
        "    return new_s\n",
        "\n",
        "# remove \"sentence\" if it is too long.\n",
        "def remove_too_long(src_list,tgt_list,threshold):\n",
        "    too_long_src = 0\n",
        "    too_long_tgt = 0\n",
        "    remove = False\n",
        "    new_s = []\n",
        "    new_t = []\n",
        "    for i in range(len(src_list)):\n",
        "      if ((len(src_list[i])>threshold)):\n",
        "        remove = True\n",
        "        too_long_src += 1\n",
        "      if (len(tgt_list[i])>threshold):\n",
        "        remove = True\n",
        "        too_long_tgt += 1\n",
        "      if remove == False:\n",
        "        new_s.append(src_list[i])\n",
        "        new_t.append(tgt_list[i])\n",
        "      else :\n",
        "        remove = False\n",
        "    return(new_s,new_t,too_long_src,too_long_tgt)\n",
        "\n",
        "# pick up good line pairs for traning and validation model\n",
        "def check_data_pairs(src_list,tgt_list,threshold):\n",
        "    index = 0\n",
        "    new_src_list = []\n",
        "    new_tgt_list = []\n",
        "\n",
        "    same = 0\n",
        "    add_next = 0\n",
        "    split_again = 0\n",
        "    not_use = 0\n",
        "\n",
        "    while(index < len(src_list)):\n",
        "\n",
        "      src = divide_by_END(src_list[index])\n",
        "      tgt = divide_by_END(tgt_list[index])\n",
        "\n",
        "      # case 1 : src is as long as tgt , finished.\n",
        "      if len(src) == len(tgt):\n",
        "        new_src_list += src\n",
        "        new_tgt_list += tgt\n",
        "        same += 1\n",
        "        index += 1\n",
        "\n",
        "      else :\n",
        "        # if it is not the last one : both src and tgt add next sentence\n",
        "        if index != len(src_list)-1:\n",
        "          src_add_next = divide_by_END(src_list[index] + src_list[index+1])\n",
        "          tgt_add_next = divide_by_END(tgt_list[index] + tgt_list[index+1])\n",
        "          # case 2 : src_add_next is as long as tgt_add_next , finished.\n",
        "          if len(src_add_next) == len(tgt_add_next):\n",
        "            new_src_list += src_add_next\n",
        "            new_tgt_list += tgt_add_next\n",
        "            add_next += 2\n",
        "            index += 2\n",
        "\n",
        "          # using new punctuation to divide tgt (english) sentence.\n",
        "          # note that this part could cause negative effects if the dataset is change.\n",
        "          else :\n",
        "            src_add_next = devide_en_again(src_list[index] + src_list[index+1])\n",
        "            # case 3 : src_add_next is as long as tgt_add_next , finished.\n",
        "            if len(src_add_next) == len(tgt_add_next):\n",
        "              new_src_list += src_add_next\n",
        "              new_tgt_list += tgt_add_next\n",
        "              split_again +=2\n",
        "              index += 2\n",
        "\n",
        "            # case 4 : sentence will not be used.\n",
        "            else :\n",
        "              not_use += 1\n",
        "              # if to_do == 1 :\n",
        "              #   print(index,src_add_next,tgt_add_next,len(src_add_next),len(tgt_add_next))\n",
        "              index += 1\n",
        "\n",
        "        # if it is the last one\n",
        "        else :\n",
        "          not_use += 1\n",
        "          index += 1\n",
        "    # print information\n",
        "    print(f\"The original total number of line is {index}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences is {same}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences after combine the next lines is {add_next}.\")\n",
        "    print(f\"The number of line pairs have the equal sentences after combine the next lines\"+\\\n",
        "       f\"and resplit english lines using :; is {split_again}.\")\n",
        "    print(f\"The number of line we don't use is {not_use}.\")\n",
        "    print(f\"Note that {index} = {same}+{add_next}+{split_again}+{not_use}.\")\n",
        "\n",
        "    # remove long lines\n",
        "    print(f\"The total number of sentence pairs before remove long sentences is {len(new_src_list)}.\")\n",
        "    new_src_list,new_tgt_list,too_long_src,too_long_tgt = remove_too_long(new_src_list,new_tgt_list,threshold)\n",
        "    print(f\"The finally total number of sentence pairs using is {len(new_src_list)}.\")\n",
        "    print(f\"Note that {len(new_src_list)} are the number of sentence pairs, not line pairs\")\n",
        "\n",
        "    return(new_src_list,new_tgt_list)"
      ],
      "metadata": {
        "id": "UVYvYCpuDQDa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load and clean data\n",
        "------"
      ],
      "metadata": {
        "id": "1KPMwJwck437"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and clean data\n",
        "def load_file(path,function):\n",
        "    with open(path, \"r\") as f:\n",
        "      data = f.read()\n",
        "      return function(data)\n",
        "# saving to new path\n",
        "def clean_data_and_save(\n",
        "    path_doc,raw_src_path,raw_tgt_path,\n",
        "    clean_src_path,clean_tgt_path,threshold\n",
        "    ):\n",
        "    raw_src_path = path_doc + raw_src_path\n",
        "    raw_tgt_path = path_doc + raw_tgt_path\n",
        "    src = load_file(raw_src_path,clean_s_en),\n",
        "    tgt = load_file(raw_tgt_path,clean_s_zh),\n",
        "    # src , tgt are tuples with only one term : src_list, tgt_list\n",
        "    src_list = src[0]\n",
        "    tgt_list = tgt[0]\n",
        "    clean_src_list, clean_tgt_list = check_data_pairs(src_list,tgt_list,threshold)\n",
        "    with open(path_doc + clean_src_path, \"w\") as f:\n",
        "      f.write(\"\\n\".join(clean_src_list))\n",
        "    with open(path_doc + clean_tgt_path, \"w\") as f:\n",
        "      f.write(\"\\n\".join(clean_tgt_list))\n",
        "# test clean_data_and_save\n",
        "# clean_data_and_save(\n",
        "#     path_doc = setting[\"data_info\"][\"document\"],\n",
        "#     raw_src_path = setting[\"data_info\"][\"source\"][\"raw_data_path\"],\n",
        "#     raw_tgt_path = setting[\"data_info\"][\"target\"][\"raw_data_path\"],\n",
        "#     clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "#     clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "#     threshold = setting[\"tokenized_setting\"][\"max_l\"]\n",
        "# )"
      ],
      "metadata": {
        "id": "DhVI2xylk1tr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize\n",
        "------\n",
        ">using sentencepiece to tokenize sentences,  \n",
        ">first make the english/chinese dictionary separately,  \n",
        ">then use these dict to encode sentence pair in dataset,  \n",
        ">including add bos/eos/padding to tokenized sentences.  \n",
        ">Finally split then into train/val set and save."
      ],
      "metadata": {
        "id": "S_-APGe5okQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.utils.data as data\n",
        "def tokenized(path_doc,\n",
        "       clean_data_path,\n",
        "       vocab_size,\n",
        "       lang,\n",
        "       tokenized_setting\n",
        "       ):\n",
        "  model_prefix = f\"spm_{vocab_size}_{lang}\"\n",
        "  spm.SentencePieceTrainer.train(\n",
        "      input= path_doc+clean_data_path,\n",
        "      **tokenized_setting,\n",
        "      model_prefix = path_doc +\"/\"+ model_prefix,\n",
        "  )\n",
        "  return(model_prefix)\n",
        "\n",
        "def get_tokenizers(path_doc,vocab_size,src_lang,tgt_lang):\n",
        "  src_tokenizer = spm.SentencePieceProcessor(model_file = path_doc + f\"/spm_{vocab_size}_{src_lang}\" +\".model\")\n",
        "  tgt_tokenizer = spm.SentencePieceProcessor(model_file = path_doc + f\"/spm_{vocab_size}_{tgt_lang}\" +\".model\")\n",
        "  return src_tokenizer,tgt_tokenizer\n",
        "\n",
        "def bos_eos_padding(dataset,\n",
        "          max_l,\n",
        "          src_tokenizer,\n",
        "          tgt_tokenizer\n",
        "          ):\n",
        "\n",
        "\n",
        "  padding_src = []\n",
        "  padding_tgt = []\n",
        "  len_s = 0\n",
        "  len_t = 0\n",
        "  for src,tgt in dataset:\n",
        "    s = src_tokenizer.encode(src, out_type=int)\n",
        "    s = np.append(s,[3])\n",
        "    s = np.append([2],np.pad(s,(0, max_l-len(s)-1), constant_values = 0))\n",
        "    padding_src.append(s)\n",
        "\n",
        "    t = tgt_tokenizer.encode(tgt, out_type=int)\n",
        "    t = np.append(t,[3])\n",
        "    t = np.append([2],np.pad(t,(0, max_l-len(t)-1), constant_values = 0))\n",
        "    padding_tgt.append(t)\n",
        "\n",
        "  return(list(zip(padding_src,padding_tgt)))\n",
        "# test SentencePieceProcessor and bos_eos_padding\n",
        "# s_src = spm.SentencePieceProcessor(model_file=\"/content/spm8000_en.model\")\n",
        "# s_src.encode(\"hello world!\", out_type=int)\n",
        "# bos_eos_padding([(\"hello world\",\"_哈囉\")],5,10)\n",
        "\n",
        "def data_set_preparing(path_doc,\n",
        "            clean_src_path,\n",
        "            clean_tgt_path,\n",
        "            max_l,\n",
        "            src_tokenizer,\n",
        "            tgt_tokenizer,\n",
        "            st_train_path,\n",
        "            st_val_path,\n",
        "            tt_train_path,\n",
        "            tt_val_path,\n",
        "            ):\n",
        "    src_set = []\n",
        "    tgt_set = []\n",
        "\n",
        "    with open(path_doc+clean_src_path,\"r\") as in_f :\n",
        "      for line in tqdm(in_f):\n",
        "        src_set.append(line)\n",
        "    with open(path_doc+clean_tgt_path,\"r\") as in_f :\n",
        "      for line in tqdm(in_f):\n",
        "        tgt_set.append(line)\n",
        "\n",
        "    dataset = list(zip(src_set,tgt_set))\n",
        "    dataset = bos_eos_padding(dataset,max_l,src_tokenizer,tgt_tokenizer)\n",
        "    train_set, valid_set = data.random_split(dataset,[0.99,0.01])\n",
        "    # print(train_set[0][0])\n",
        "\n",
        "    with open(path_doc + st_train_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(train_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[0])+\"\\n\")\n",
        "    with open(path_doc + st_val_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(valid_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[0])+\"\\n\")\n",
        "    with open(path_doc + tt_train_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(train_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[1])+\"\\n\")\n",
        "    with open(path_doc + tt_val_path, 'w') as out_f:\n",
        "      for line_pair in tqdm(valid_set):\n",
        "        out_f.write(\" \".join(str(x) for x in line_pair[1])+\"\\n\")"
      ],
      "metadata": {
        "id": "ByrUmAvFkKk9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized_data(vocab_size,tokenized_setting,max_l,path_doc,clean_src_path,\n",
        "          clean_tgt_path,src_lang,tgt_lang,st_train_path,st_val_path,\n",
        "          tt_train_path,tt_val_path,):\n",
        "  tokenized(path_doc,clean_src_path,vocab_size,src_lang,tokenized_setting)\n",
        "  tokenized(path_doc,clean_tgt_path,vocab_size,tgt_lang,tokenized_setting)\n",
        "  src_tokenizer,tgt_tokenizer = get_tokenizers(path_doc,vocab_size,src_lang,tgt_lang)\n",
        "  data_set_preparing(path_doc,clean_src_path,clean_tgt_path,max_l,src_tokenizer,\n",
        "           tgt_tokenizer,st_train_path,st_val_path,tt_train_path,tt_val_path)\n",
        "  return src_tokenizer,tgt_tokenizer\n",
        "\n",
        "# test tokenized_data()\n",
        "# src_tokenizer,tgt_tokenizer = tokenized_data(\n",
        "#     vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "#     tokenized_setting = {k:setting[\"tokenized_setting\"][k] for k in \\\n",
        "#               set(list(setting[\"tokenized_setting\"].keys()))-{\"vocab_size\",\"max_l\"}},\n",
        "#     max_l = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "#     path_doc = setting[\"data_info\"][\"document\"],\n",
        "#     clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "#     clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "#     src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "#     tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],\n",
        "#     st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "#     st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "#     tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "#     tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"])"
      ],
      "metadata": {
        "id": "RkIHpc6qkRqh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make data set\n",
        "------\n",
        "> Using tokenized data to make dataset.  \n",
        "> Classmethod : padding_mask_batch which  \n",
        "> where the key padding mask is constucted  \n",
        "> also defined here."
      ],
      "metadata": {
        "id": "FV3kHGqlggdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class myDataset(Dataset):\n",
        "  def __init__(self,src_path,tgt_path):\n",
        "\n",
        "    self.src_path = src_path\n",
        "    self.tgt_path = tgt_path\n",
        "\n",
        "    src_list = []\n",
        "    with open(self.src_path,\"r\") as f :\n",
        "      d_l = f.readlines()\n",
        "      for line in tqdm(d_l):\n",
        "        int_list = [int(i) for i in line.split()]\n",
        "        src_list.append(int_list)\n",
        "    self.src = torch.LongTensor(src_list)\n",
        "\n",
        "    tgt_list = []\n",
        "    with open(self.tgt_path,\"r\") as f :\n",
        "      l_l = f.readlines()\n",
        "      for line in tqdm(l_l):\n",
        "        int_list = [int(i) for i in line.split()]\n",
        "        tgt_list.append(int_list)\n",
        "    self.tgt = torch.LongTensor(tgt_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.src[index], self.tgt[index]\n",
        "\n",
        "  # make key padding mask\n",
        "  @classmethod\n",
        "  def padding_mask_batch(cls,batch,pad_id):\n",
        "    \"\"\"Collate a batch of data.\"\"\"\n",
        "    src, tgt = zip(*batch)\n",
        "    src = torch.stack(src)\n",
        "    tgt = torch.stack(tgt)\n",
        "    src_padding = (src == pad_id)\n",
        "    tgt_padding = (tgt == pad_id)\n",
        "\n",
        "    return src, tgt , src_padding, tgt_padding\n",
        "# test myDataset\n",
        "# data = []\n",
        "# with open(\"/content/train_dev/tokenized_train_data_en.txt\",\"r\") as f :\n",
        "#   d_l = f.readlines()\n",
        "#   for line in tqdm(d_l):\n",
        "#     int_list = [int(i) for i in line.split()]\n",
        "#     data.append(int_list)\n",
        "# print(data[0])"
      ],
      "metadata": {
        "id": "dbfi-DvrlDhI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "def get_data_set(train_batch_size,valid_batch_size,num_workers,path_doc,\n",
        "         st_train_path,st_val_path,tt_train_path,tt_val_path,pad_id):\n",
        "\n",
        "  train_set = myDataset(src_path = path_doc + st_train_path,\n",
        "              tgt_path = path_doc + tt_train_path,\n",
        "              )\n",
        "  valid_set = myDataset(src_path = path_doc + st_val_path,\n",
        "              tgt_path = path_doc + tt_val_path,\n",
        "              )\n",
        "  train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size = train_batch_size,\n",
        "    shuffle = True,\n",
        "    num_workers = num_workers,\n",
        "    pin_memory = True,\n",
        "    collate_fn = lambda x : myDataset.padding_mask_batch(x,\n",
        "                   pad_id = pad_id)\n",
        "  )\n",
        "  valid_loader = DataLoader(\n",
        "    valid_set,\n",
        "    batch_size = valid_batch_size,\n",
        "    num_workers = num_workers,\n",
        "    pin_memory = True,\n",
        "    collate_fn = lambda x : myDataset.padding_mask_batch(x,\n",
        "                   pad_id = pad_id)\n",
        "  )\n",
        "  del train_set,valid_set\n",
        "  gc.collect()\n",
        "  return train_loader,valid_loader\n",
        "# test get_data_set()\n",
        "# train_set,valid_set = get_data_set()\n",
        "# batch = next(iter(valid_set))\n",
        "# src,tgt,src_mask,tgt_mask = batch\n",
        "# print(src.shape)"
      ],
      "metadata": {
        "id": "YBFKMSM45ppM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make model\n",
        "======\n",
        "positional encoding layer\n",
        "------\n",
        ">The first layer is embedding layer, where each integers  \n",
        ">in encoder sentence will be represent by a vector.   \n",
        ">I use build-in class in pytorch to finish these part,    \n",
        ">and combine it with encoder layers to form my encoder.\n",
        "\n",
        ">The layer below is the second layer :positional encoding layer  \n",
        ">in this layer the position infomation is add to each \"word\"  \n",
        ">in the sentence.\n",
        ">Here I use parameters instead of constant as  \n",
        ">position infomation so they will change during training process."
      ],
      "metadata": {
        "id": "RZAzqY3bwds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Positional_Encoding(nn.Module):\n",
        "    def __init__(self,max_sentence_length,embedding_dimension):\n",
        "      super().__init__()\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      self.encoding_values = nn.Parameter(nn.init.normal_(torch.empty(max_sentence_length,1, embedding_dimension)))\n",
        "    def forward(self, x):\n",
        "        # the shape of x : [batch,length,e_dim]\n",
        "        # the shape of self.encoding_values : [batch,length,e_dim]\n",
        "        x = x + self.encoding_values.unsqueeze(0)\n",
        "        x = x.squeeze(-2)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "EoKH9m1LznWO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "multihead attention layer\n",
        "------\n"
      ],
      "metadata": {
        "id": "OURB2Fg-4lE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import math\n",
        "from torchinfo import summary\n",
        "# This part is modify from pytorch : torch.nn.functional.scaled_dot_product_attention\n",
        "# Efficient implementation equivalent to the following:\n",
        "class Scaled_Dot_Product_Attention(nn.Module):\n",
        "    def __init__(self,max_sentence_length,dropout_p):\n",
        "      super().__init__()\n",
        "      self.dropout_p = dropout_p\n",
        "      self.max_l = max_sentence_length\n",
        "      attn_bias = torch.zeros(self.max_l, self.max_l)\n",
        "      temp_mask = torch.ones(self.max_l, self.max_l, dtype=torch.bool).tril(diagonal=0)\n",
        "      attn_bias = attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
        "      self.register_buffer(\"attn_bias\",attn_bias)\n",
        "\n",
        "    def forward(self, is_last_batch, query, key, value, padding_mask=None, is_causal=False, scale=None) -> torch.Tensor:\n",
        "      # Efficient implementation equivalent to the following:\n",
        "\n",
        "      scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
        "      attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
        "\n",
        "      if is_causal:\n",
        "        if is_last_batch:\n",
        "          self.attn_bias = self.attn_bias[:query.size(-2),:query.size(-2)]\n",
        "        self.attn_bias.to(query.dtype)\n",
        "        attn_weight += self.attn_bias\n",
        "\n",
        "      if padding_mask is not None:\n",
        "          if padding_mask.dtype == torch.bool:\n",
        "            padding_mask = torch.zeros_like(padding_mask,dtype = float).masked_fill_(padding_mask, (float(\"-inf\")))\n",
        "\n",
        "          padding_mask = padding_mask.unsqueeze(0).unsqueeze(0)\n",
        "          padding_mask.to(query.dtype)\n",
        "\n",
        "          attn_weight = attn_weight.transpose(-4,-2)\n",
        "          attn_weight += padding_mask\n",
        "          attn_weight = attn_weight.transpose(-4,-2)\n",
        "\n",
        "      attn_weight = torch.softmax(attn_weight, dim=-1)\n",
        "      attn_weight = torch.dropout(attn_weight, self.dropout_p, train=True)\n",
        "      return attn_weight @ value\n",
        "# test scaled_dot_product_attention\n",
        "# t = torch.rand([2,3,4,5])\n",
        "# mask = torch.tensor([[False,False,True,True],[False,True,False,True]],dtype = torch.bool)\n",
        "# print(scaled_dot_product_attention(\"cpu\",t,t,t,padding_mask= mask, is_causal=True))\n",
        "# from torch.nn.functional import scaled_dot_product_attention\n",
        "class My_MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, max_sentence_length, kv_input_dimension, embedding_dimension, num_heads, dropout_p, if_decoder = False):\n",
        "        '''\n",
        "        embedding_dimension = input dimension\n",
        "        note that there are residual sublayers in MultiHeadedAttention\n",
        "        '''\n",
        "        super().__init__()\n",
        "        assert embedding_dimension % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
        "        self.max_l = max_sentence_length\n",
        "        self.kv_d = kv_input_dimension\n",
        "        self.d = embedding_dimension\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout_p = dropout_p\n",
        "        self.is_causal = if_decoder\n",
        "        self.sdpa = Scaled_Dot_Product_Attention(self.max_l,self.dropout_p)\n",
        "        self.linear_for_q = nn.Linear(self.d, self.d)\n",
        "        self.linear_for_kv = nn.Linear(self.kv_d, 2 * self.d)\n",
        "        self.linear_out_project = nn.Linear(self.d, self.d)\n",
        "\n",
        "    def forward(self, is_last_batch, q_input_data, kv_input_data , padding_mask = None):\n",
        "\n",
        "        query = self.linear_for_q(q_input_data)\n",
        "        key, value = self.linear_for_kv(kv_input_data).split(self.d,dim = -1)\n",
        "\n",
        "        query,key,value = \\\n",
        "          map(lambda x : x.view(x.size(0),x.size(1),self.num_heads,self.d//self.num_heads),[query,key,value])\n",
        "        query,key,value = \\\n",
        "          map(lambda x : x.transpose(-2,-3),[query,key,value])\n",
        "\n",
        "        x = self.sdpa(is_last_batch,query,key,value,padding_mask = padding_mask,is_causal = self.is_causal)\n",
        "        x = x.transpose(-2,-3).contiguous()\n",
        "        x = x.view(x.size(0),x.size(1),self.d)\n",
        "        x = self.linear_out_project(x)\n",
        "\n",
        "        return x\n",
        "# test My_MultiHeadedAttention\n",
        "# model = My_MultiHeadedAttention(64,128,2,0.0)\n",
        "# q_input = torch.rand(32,400,128)\n",
        "# kv_input = torch.rand(32,400,64)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(q_input,kv_input,mask).size())\n",
        "# print(summary(model,device = \"cpu\",q_input_data = q_input, kv_input_data = kv_input,padding_mask = mask))"
      ],
      "metadata": {
        "id": "PLWLkr9UaKFD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoder layer(s)\n",
        "------"
      ],
      "metadata": {
        "id": "T0IjI-zC5fqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class My_Encoder_Layer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,embedding_dimension,feedforward_dimension,num_heads,dropout_p):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "\n",
        "    self.attention = My_MultiHeadedAttention(self.max_l, self.emb_dim, self.emb_dim, self.num_heads, self.dropout_p)\n",
        "    self.layer_norm_attn = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_attn_layernorm = nn.Dropout(self.dropout_p)\n",
        "\n",
        "    self.feedforward = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_feedforward = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_feedforward_layernorm = nn.Dropout(self.dropout_p)\n",
        "\n",
        "\n",
        "  def forward(self,is_last_batch,x,padding_mask):\n",
        "    x = x + self.attention(is_last_batch,x,x,padding_mask)\n",
        "    x = self.layer_norm_attn(x)\n",
        "\n",
        "    x = self.drop_out_attn_layernorm(x)\n",
        "\n",
        "    x = x + self.feedforward(x)\n",
        "    x = self.layer_norm_feedforward(x)\n",
        "    x = self.drop_out_feedforward_layernorm(x)\n",
        "\n",
        "    return x\n",
        "# test My_Encoder_Layer\n",
        "# model = My_Encoder_Layer(\"cpu\",128,256,2,0.0)\n",
        "# input = torch.rand((32,400,128))\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(input,mask).size())\n",
        "# print(summary(model,input_data = input,padding_mask = mask))\n",
        "# print(model.state_dict().keys())\n",
        "class My_Encoder(nn.Module):\n",
        "  def __init__(self,max_sentence_length,dictionary_length,embedding_dimension,feedforward_dimension,\n",
        "         padding_idx, num_heads, dropout_p, layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.padding_idx = padding_idx\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "\n",
        "    self.encoder_embedding = nn.Embedding(self.dict_l,self.emb_dim,self.padding_idx)\n",
        "    self.positional_encoding = Positional_Encoding(self.max_l,self.emb_dim)\n",
        "    self.encoder = nn.ModuleList([My_Encoder_Layer(self.max_l,self.emb_dim,self.fwd_dim,\\\n",
        "                    self.num_heads,self.dropout_p) for i in range(layer_num)])\n",
        "\n",
        "  def forward(self,is_last_batch,input,padding_mask):\n",
        "    x = self.encoder_embedding(input.unsqueeze(-1))* math.sqrt(self.emb_dim)\n",
        "    x = self.positional_encoding(x)\n",
        "\n",
        "    for index,module in enumerate(self.encoder):\n",
        "      if index == 0:\n",
        "        x = module(is_last_batch,x,padding_mask)\n",
        "      else:\n",
        "        x = module(is_last_batch,x,None)\n",
        "    return x\n",
        "# test My_Encoder\n",
        "# model = My_Encoder(\"cpu\",400,8000,128,256,0,2,0.0,2)\n",
        "# input = torch.randint(0,7999,(32,400),dtype = torch.long)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(input,mask).size())\n",
        "# print(summary(model,input_data = input,padding_mask = mask))\n",
        "# print(model.state_dict().keys())"
      ],
      "metadata": {
        "id": "PYhd7muASnrY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "decoder layer(s)\n",
        "------"
      ],
      "metadata": {
        "id": "4O_rI3QV55Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class My_Decoder_Layer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,encoder_embedding_dimension,embedding_dimension,feedforward_dimension,num_heads,dropout_p):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.encoder_dim = encoder_embedding_dimension\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "\n",
        "    self.self_attention = My_MultiHeadedAttention \\\n",
        "     (self.max_l,self.emb_dim,self.emb_dim, num_heads = self.num_heads,\\\n",
        "     dropout_p = self.dropout_p, if_decoder = True)\n",
        "    self.layer_norm_sa = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_sa = nn.Dropout(0)\n",
        "\n",
        "    self.feedforward_sa = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_sa_fw = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_sa_fw = nn.Dropout(0)\n",
        "\n",
        "    self.cross_attention = My_MultiHeadedAttention \\\n",
        "    (self.max_l,self.encoder_dim, self.emb_dim, num_heads = self.num_heads,\n",
        "    dropout_p = self.dropout_p, if_decoder = True)\n",
        "    self.layer_norm_ca = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_ca = nn.Dropout(0)\n",
        "\n",
        "    self.feedforward_ca = nn.Sequential(\n",
        "    nn.Linear(self.emb_dim,self.fwd_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(self.fwd_dim,self.emb_dim)\n",
        "    )\n",
        "    self.layer_norm_ca_fw = nn.LayerNorm(self.emb_dim)\n",
        "    self.drop_out_ca_fw = nn.Dropout(0)\n",
        "\n",
        "  def forward(self,is_last_batch,encoder_input,input,padding_mask):\n",
        "\n",
        "    x = input + self.self_attention(is_last_batch,input,input,padding_mask)\n",
        "    x = self.layer_norm_sa(x)\n",
        "    x = self.drop_out_sa(x)\n",
        "\n",
        "    x = x + self.feedforward_sa(x)\n",
        "    x = self.layer_norm_sa_fw(x)\n",
        "    x = self.drop_out_sa_fw(x)\n",
        "\n",
        "    x = x + self.cross_attention(is_last_batch,x,encoder_input,padding_mask)\n",
        "    x = self.layer_norm_ca(x)\n",
        "    x = self.drop_out_ca(x)\n",
        "\n",
        "    x = x + self.feedforward_ca(x)\n",
        "    x = self.layer_norm_ca_fw(x)\n",
        "    x = self.drop_out_ca_fw(x)\n",
        "\n",
        "    return x\n",
        "class My_Decoder(nn.Module):\n",
        "  def __init__(self,max_sentence_length, dictionary_length, encoder_embedding_dimension,\n",
        "         embedding_dimension, feedforward_dimension, padding_idx, num_heads, dropout_p, layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.encoder_dim = encoder_embedding_dimension\n",
        "    self.emb_dim = embedding_dimension\n",
        "    self.fwd_dim = feedforward_dimension\n",
        "    self.padding_idx = padding_idx\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "\n",
        "    self.decoder_embedding = nn.Embedding(self.dict_l,self.emb_dim,padding_idx=self.padding_idx)\n",
        "    self.positional_encoding = Positional_Encoding(self.max_l,self.emb_dim)\n",
        "    self.decoder = nn.ModuleList([My_Decoder_Layer(self.max_l,self.encoder_dim,self.emb_dim,\\\n",
        "                    self.fwd_dim,self.num_heads,self.dropout_p) for i in range(self.layer_num)])\n",
        "    # self.encoder = My_Encoder_Layer(self.emb_dim,self.fwd_dim)\n",
        "\n",
        "    self.generator = nn.Linear(self.emb_dim,self.dict_l)\n",
        "\n",
        "  def forward(self,is_last_batch,encoder_input,input,padding_mask):\n",
        "    x = self.decoder_embedding(input.unsqueeze(-1))* math.sqrt(self.emb_dim)\n",
        "    x = self.positional_encoding(x)\n",
        "    # x = self.encoder(x,padding_mask)\n",
        "    for index,module in enumerate(self.decoder):\n",
        "      if index == 0:\n",
        "        x = module(is_last_batch,encoder_input,x,padding_mask)\n",
        "      else:\n",
        "        x = module(is_last_batch,encoder_input,x,None)\n",
        "    x = self.generator(x)\n",
        "    x = F.log_softmax(x,dim = -1)\n",
        "    return x\n",
        "# test My_Decoder\n",
        "# model = My_Decoder(\"cpu\",400,8000,128,64,256,0,2,0.0,2)\n",
        "# encoder_input = torch.rand(32,400,128)\n",
        "# input = torch.randint(0,7999,(32,400),dtype = torch.long)\n",
        "# mask = (torch.FloatTensor(32,400).uniform_() > 0.8)\n",
        "# print(model(encoder_input = encoder_input,input = input, padding_mask = mask).size())\n",
        "# print(summary(model,encoder_input = encoder_input,input = input, padding_mask = mask))\n",
        "# print(model.state_dict().keys())"
      ],
      "metadata": {
        "id": "rEjaTbhyBmEV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformer layer\n",
        "------"
      ],
      "metadata": {
        "id": "1gcz18nz6QTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Transformer(nn.Module):\n",
        "  def __init__(self,max_sentence_length,dictionary_length,padding_idx,\n",
        "         encoder_embedding_dimension,decoder_embedding_dimension,\n",
        "         feedforward_dimension,num_heads,dropout_p,layer_num):\n",
        "    super().__init__()\n",
        "    self.max_l = max_sentence_length\n",
        "    self.dict_l = dictionary_length\n",
        "    self.padding_idx = padding_idx\n",
        "    self.en_dim = encoder_embedding_dimension\n",
        "    self.de_dim = decoder_embedding_dimension\n",
        "    self.fw_dim = feedforward_dimension\n",
        "    self.num_heads = num_heads\n",
        "    self.dropout_p = dropout_p\n",
        "    self.layer_num = layer_num\n",
        "    self.encoder = My_Encoder \\\n",
        "     (self.max_l,self.dict_l,self.en_dim,self.fw_dim,\n",
        "      self.padding_idx,self.num_heads,self.dropout_p,self.layer_num)\n",
        "    self.decoder = My_Decoder \\\n",
        "     (self.max_l,self.dict_l,self.en_dim,self.de_dim,self.fw_dim,\n",
        "      self.padding_idx,self.num_heads,self.dropout_p,self.layer_num)\n",
        "\n",
        "  def forward(self,is_last_batch,src,tgt,src_mask,tgt_mask):\n",
        "    memory = self.encoder(is_last_batch,src,src_mask)\n",
        "    outputs = self.decoder(is_last_batch,memory,tgt,tgt_mask)\n",
        "    return outputs\n",
        "\n",
        "def build_model(max_sentence_length,dictionary_length,padding_idx,encoder_embedding_dimension,\n",
        "         decoder_embedding_dimension,feedforward_dimension,num_heads,dropout_p,layer_num):\n",
        "  return My_Transformer(max_sentence_length,dictionary_length,padding_idx,\n",
        "              encoder_embedding_dimension,decoder_embedding_dimension,\n",
        "              feedforward_dimension,num_heads,dropout_p,layer_num)\n",
        "# test My_Transformer\n",
        "# model = My_Transformer(\"cpu\",400,8000,0,128,64,256,2,0,2)\n",
        "# src = torch.randint(0,8000,(32,400),dtype = torch.long)\n",
        "# tgt = torch.randint(0,8000,(32,400),dtype = torch.long)\n",
        "# src_mask = torch.cat(((torch.FloatTensor(32,200).uniform_() > 1),(torch.FloatTensor(32,200).uniform_() > 0.15)),dim =1)\n",
        "# tgt_mask = torch.cat(((torch.FloatTensor(32,100).uniform_() > 1),(torch.FloatTensor(32,300).uniform_() > 0.15)),dim =1)\n",
        "# out = model(src,tgt,src_mask,tgt_mask)\n",
        "# print(out.size(),out.dim(),out[0][0])\n",
        "# print(summary(model,src = src,tgt = tgt,src_mask = src_mask,tgt_mask = tgt_mask))\n",
        "# print(model.state_dict().keys())\n",
        "\n",
        "# test build_model\n",
        "# model = build_model()\n",
        "# batch = next(iter(train_set))\n",
        "# src, tgt, src_mask, tgt_mask = batch\n",
        "# print(type(src),src.shape)\n",
        "# print(summary(model,src = src,tgt = tgt,src_mask = src_mask,tgt_mask = tgt_mask))\n",
        "# outputs = model(src,tgt,src_mask,tgt_mask)\n",
        "# print(outputs.shape)"
      ],
      "metadata": {
        "id": "PBDq_h1jKCo7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training and validation process\n",
        "======\n",
        "Noam optimizer\n",
        "------"
      ],
      "metadata": {
        "id": "sPbMfCre6cSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reference : https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
        "class NoamOpt:\n",
        "    def __init__(self,dictionary_length,factor,warmup,optimizer):\n",
        "        self.dict_len = dictionary_length\n",
        "        self.factor = factor\n",
        "        self.warmup = warmup\n",
        "        self.optimizer = optimizer\n",
        "        self._step = 0\n",
        "        self._rate = 0\n",
        "    def step(self):\n",
        "        self._step += 1\n",
        "        self._rate = self.factor *(self.dict_len ** (-0.5) * \\\n",
        "        min(self._step ** (-0.5), self._step * self.warmup ** (-1.5)))\n",
        "\n",
        "        self.optimizer.param_groups[0][\"lr\"] = self._rate\n",
        "        self.optimizer.step()\n",
        "    def zero_grad(self):\n",
        "        return self.optimizer.zero_grad()\n",
        "\n",
        "    def state_dict(self):\n",
        "        return self.optimizer.state_dict()\n",
        "\n",
        "    def load_state_dict(self,state_dict):\n",
        "        return self.optimizer.load_state_dict(state_dict)\n",
        "\n",
        "    def set_step(self,step):\n",
        "        self._step = step\n",
        "# test NoamOpt:\n",
        "# x = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
        "# x.param_groups[0][\"lr\"]"
      ],
      "metadata": {
        "id": "Lb8BnuysNCOQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "label smoothing\n",
        "------"
      ],
      "metadata": {
        "id": "3TyyebUNOeI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "  def __init__(self,batch_size,dictionary_length,padding_id,smoothing):\n",
        "        super().__init__()\n",
        "        self.dict_len = dictionary_length\n",
        "        self.smoothing = smoothing\n",
        "        self.padding_id = padding_id\n",
        "        shift = torch.full(size = (batch_size,1), dtype = torch.long, fill_value = self.padding_id)\n",
        "        self.register_buffer(\"shift\",shift)\n",
        "  def forward(self, is_last_batch, outputs , label):\n",
        "\n",
        "    # step1 : when using label in validation, shift is needed.\n",
        "    # label_shift : {type : tensor , shape : batch  X (max_sentence_length-1)\n",
        "    # value : int}\n",
        "    label_shift = label[:,1:]\n",
        "    # shift : {type : tensor , shape : batch  X 1 ,value : self.padding_id}\n",
        "\n",
        "    # label_shift : {type : tensor , shape : batch  X max_sentence_length\n",
        "    # value : int}\n",
        "    if is_last_batch:\n",
        "      label_shift = torch.cat((label_shift,self.shift[:label.size(0),:]),dim = 1)\n",
        "\n",
        "    else:\n",
        "      label_shift = torch.cat((label_shift,self.shift),dim = 1)\n",
        "\n",
        "    # step2 : convert label to onehot tensor, then apply label smoothing\n",
        "    # label_onehot : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : 0 or 1}\n",
        "    label_onehot = F.one_hot(label_shift,self.dict_len).float()\n",
        "    # add : {type : float}\n",
        "    add = self.smoothing / (self.dict_len)\n",
        "    # label_onehot : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : add or 1+add}\n",
        "    label_onehot += add\n",
        "    # label_smoothed : {type : tensor , shape : batch  X max_sentence_length X dictionary_length\n",
        "    # value : add or 1+add-self.smoothing}\n",
        "    label_smoothed = label_onehot.masked_fill_((label_onehot > 1),float(1-self.smoothing+add))\n",
        "\n",
        "    '''\n",
        "    Question : Is padding really needed?\n",
        "    '''\n",
        "    # step3 : use padding mask to ignore to loss from padding id, then calculate loss.\n",
        "    # loss : {type : tensor , shape : batch  X max_sentence_length X 1, value : float}\n",
        "    loss = -1*torch.sum((outputs*label_smoothed),dim = -1)\n",
        "    # label_padding_mask {type : tensor , shape : batch  X max_sentence_length, value : bool}\n",
        "    label_padding_mask = (label == self.padding_id)\n",
        "    # mask_loss : {type : tensor , shape : batch  X max_sentence_length,\n",
        "    # value : 0 or add or 1+add-self.smoothing}\n",
        "    mask_loss = loss.masked_fill_(label_padding_mask,0)\n",
        "    # # ignore_index_number : {type : int}\n",
        "    # ignore_index_number = (mask_loss == 0).sum().item()\n",
        "    # avg_loss : {type : int}\n",
        "    # avg_loss = mask_loss.sum()/(mask_loss.size(0)*mask_loss.size(1)-ignore_index_number)\n",
        "    avg_loss = mask_loss.sum()/mask_loss.size(0)\n",
        "    return(avg_loss)\n",
        "\n",
        "# test LabelSmoothedCrossEntropyCriterion\n",
        "# cal1 = LabelSmoothedCrossEntropyCriterion()\n",
        "# print(cal1(outputs,tgt))\n",
        "\n",
        "# ignore_index not work correctly\n",
        "# def LabelSmoothedCrossEntropy(outputs , label,dictionary_length,smooth,padding_id):\n",
        "#   print(outputs.shape)\n",
        "#   print(label.shape)\n",
        "#   label_onehot = label.transpose(-1,-2).squeeze()\n",
        "#   outputs = outputs.transpose(-1,-2)\n",
        "#   cal_loss = nn.CrossEntropyLoss(ignore_index = padding_idx,reduction = \"mean\", label_smoothing=smooth)\n",
        "#   return cal_loss(outputs,label_onehot)"
      ],
      "metadata": {
        "id": "8JltOQM_wq4m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see https://arxiv.org/pdf/1512.00567.pdf page 7\n",
        "\n",
        "#Ref 1 : Hong-Yi Li ML2021 HW5\n",
        "\n",
        "# class LabelSmoothedCrossEntropyCriterion(nn.Module):\n",
        "#     def __init__(self, smoothing, ignore_index=None, reduce=True):\n",
        "#         super().__init__()\n",
        "#         self.smoothing = smoothing\n",
        "#         self.ignore_index = ignore_index\n",
        "#         self.reduce = reduce\n",
        "\n",
        "#     def forward(self, lprobs, target):\n",
        "#         if target.dim() == lprobs.dim() - 1:\n",
        "#             target = target.unsqueeze(-1)\n",
        "#         # nll: Negative log likelihood，the cross-entropy when target is one-hot. following line is same as F.nll_loss\n",
        "#         nll_loss = -lprobs.gather(dim=-1, index=target)\n",
        "#         #  reserve some probability for other labels. thus when calculating cross-entropy,\n",
        "#         # equivalent to summing the log probs of all labels\n",
        "#         smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n",
        "#         if self.ignore_index is not None:\n",
        "#             pad_mask = target.eq(self.ignore_index)\n",
        "#             nll_loss.masked_fill_(pad_mask, 0.0)\n",
        "#             smooth_loss.masked_fill_(pad_mask, 0.0)\n",
        "#         else:\n",
        "#             nll_loss = nll_loss.squeeze(-1)\n",
        "#             smooth_loss = smooth_loss.squeeze(-1)\n",
        "#         if self.reduce:\n",
        "#             nll_loss = nll_loss.sum()\n",
        "#             smooth_loss = smooth_loss.sum()\n",
        "#         # when calculating cross-entropy, add the loss of other labels\n",
        "#         eps_i = self.smoothing / lprobs.size(-1)\n",
        "#         loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n",
        "#         return loss\n",
        "\n",
        "#Ref 2 : By hemingkx : https://github.com/hemingkx/ChineseNMT\n",
        "\n",
        "# class LabelSmoothing(nn.Module):\n",
        "#     \"\"\"Implement label smoothing.\"\"\"\n",
        "\n",
        "#     def __init__(self, size, padding_idx, smoothing=0.0):\n",
        "#         super(LabelSmoothing, self).__init__()\n",
        "#         self.criterion = nn.KLDivLoss(size_average=False)\n",
        "#         self.padding_idx = padding_idx\n",
        "#         self.confidence = 1.0 - smoothing\n",
        "#         self.smoothing = smoothing\n",
        "#         self.size = size\n",
        "#         self.true_dist = None\n",
        "\n",
        "\n",
        "#     def forward(self, x, target):\n",
        "#         assert x.size(1) == self.size\n",
        "#         true_dist = x.data.clone()\n",
        "#         true_dist.fill_(self.smoothing / (self.size - 2))\n",
        "#         true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "#         true_dist[:, self.padding_idx] = 0\n",
        "#         mask = torch.nonzero(target.data == self.padding_idx)\n",
        "#         if mask.dim() > 0:\n",
        "#             true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "#         self.true_dist = true_dist\n",
        "#         return self.criterion(x, Variable(true_dist, requires_grad=False))"
      ],
      "metadata": {
        "id": "uaE0-tA9Q9cq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "beam search\n",
        "------"
      ],
      "metadata": {
        "id": "33m5daxZ7Cpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "class Decode_With_Beam_Search(nn.Module):\n",
        "    def __init__(self,batch_size,model,beam_num,max_sentence_length,\n",
        "           dictionary_length,bos_id,padding_id):\n",
        "      super().__init__()\n",
        "      self.batch_size = batch_size\n",
        "      self.model = model\n",
        "      self.beam_num = beam_num\n",
        "      self.max_sentence_length = max_sentence_length\n",
        "      self.dictionary_length = dictionary_length\n",
        "      self.bos_id = bos_id\n",
        "      self.padding_id = padding_id\n",
        "      # decoder_input : {type : tensor , shape : Batch X 1 , value : bos_id}\n",
        "      decoder_input = torch.full(size = (self.batch_size,1),fill_value = self.bos_id)\n",
        "      self.register_buffer(\"decoder_input\",decoder_input)\n",
        "      # repeat : {type : tensor , shape : Batch ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = torch.full([self.batch_size],fill_value = self.beam_num)\n",
        "      self.register_buffer(\"repeat\",repeat)\n",
        "      # decoder_probability {type : tensor , shape : Batch X beam_num X 1, value : 0.1}\n",
        "      decoder_probability = torch.full(size = (self.batch_size,self.beam_num,1),fill_value = 0.0)\n",
        "      self.register_buffer(\"decoder_probability\",decoder_probability)\n",
        "\n",
        "      # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "      padding = torch.full(size = (batch_size*self.beam_num,self.max_sentence_length),fill_value = self.padding_id)\n",
        "      self.register_buffer(\"padding\",padding)\n",
        "\n",
        "      # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "      row = torch.tensor(range(self.batch_size)).unsqueeze(1)\n",
        "      self.register_buffer(\"row\",row)\n",
        "\n",
        "    def forward(self,is_last_batch,src,src_mask):\n",
        "\n",
        "      if is_last_batch:\n",
        "        batch = src.size(0)\n",
        "      else :\n",
        "        batch = self.batch_size\n",
        "\n",
        "      if self.beam_num > batch:\n",
        "        beam_num = batch\n",
        "      else :\n",
        "        beam_num = self.beam_num\n",
        "\n",
        "      decoder_input = self.decoder_input[:batch,:]\n",
        "      repeat = self.repeat[:batch]\n",
        "      decoder_probability = self.decoder_probability[:batch,:,]\n",
        "      padding = self.padding[:batch*beam_num,:]\n",
        "      row = self.row[:batch,:]\n",
        "\n",
        "      # decoder_beam_expand : {type : tensor , shape : (Batch X beam_num) X 1 ,value : bos_id}\n",
        "      # decoder_beam_expand = torch.repeat_interleave(decoder_input,repeat,dim=0)\n",
        "      decoder_beam_expand = torch.repeat(beam_num,1)\n",
        "\n",
        "      # memory : {type : tensor , shape : Batch X max_sentence_length X encoder_output_dim ,value : arbitary float}\n",
        "      memory = self.model.encoder(is_last_batch,src,src_mask)\n",
        "      # memory_beam_expand : {type : tensor ,\n",
        "      # shape : (Batch X n_beam) X max_sentence_length X encoder_output_dim ,value : float}\n",
        "      memory_beam_expand = torch.repeat_interleave(memory,repeat,dim=0)\n",
        "\n",
        "      gc.collect()\n",
        "\n",
        "      for id in range(self.max_sentence_length-1):\n",
        "\n",
        "        # decoder_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "        # decoder_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "        new_decoder_beam_expand , new_decoder_probability = self.get_next_word(is_last_batch,memory_beam_expand,\n",
        "        decoder_beam_expand,decoder_probability,id,batch,beam_num,padding,repeat,row)\n",
        "\n",
        "        decoder_beam_expand,decoder_probability = new_decoder_beam_expand , new_decoder_probability\n",
        "        if id%10 ==0:\n",
        "          print(new_decoder_beam_expand[0])\n",
        "        gc.collect()\n",
        "\n",
        "      # out_beam_expand : {type : tensor , shape : Batch X beam_num X (max_sentence_length) ,value : 0 or 1}\n",
        "      decoder_beam_expand = decoder_beam_expand.view(batch,beam_num,self.max_sentence_length)\n",
        "      # max_probability : {type : tensor , shape :  Batch  X 1 ,value : int(max prob index)}\n",
        "      max_probability = torch.argmax(input = decoder_probability,dim = 1)\n",
        "      # max_probability_expand : {type : tensor , shape :  Batch  X 1 X max_sentence_length ,\n",
        "      # value : [[A,A,A....],[B,B,B...],...](A,B are int)}\n",
        "      max_probability_expand = max_probability.expand(batch, self.max_sentence_length).unsqueeze(1)\n",
        "      # decoder_out : {type : tensor , shape :  Batch X max_sentence_length ,\n",
        "      # value : [[int,int,...],[int,int...],...]}\n",
        "      decoder_out =  torch.gather(input = decoder_beam_expand ,dim = 1, index = max_probability_expand).squeeze(1)\n",
        "\n",
        "      print(decoder_out[0])\n",
        "      return decoder_out,F.one_hot(decoder_out,self.dictionary_length).float()\n",
        "\n",
        "    def get_next_word(self,is_last_batch,memory,out,out_probability,id,batch,beam_num,padding,repeat,row):\n",
        "      # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "      padding = padding[:,:self.max_sentence_length-(id+1)]\n",
        "      # out_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length,\n",
        "      # value : [[bos_id],[any_id],...[padding_id],....] X Batch}\n",
        "      out_padding = torch.cat((out,padding),dim = 1)\n",
        "      # tgt_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length ,value: bool}\n",
        "      tgt_padding = (out_padding == self.padding_id).squeeze(-1)\n",
        "      # out_add : {type : tensor , shape : Batch X beam_num X dictionary_length ,value : int}\n",
        "      out_add = self.model.decoder(is_last_batch,memory,out_padding,tgt_padding)[:,id,:]\\\n",
        "            .view(batch,beam_num,self.dictionary_length)\n",
        "      # out_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "      # out_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "      out , out_probability = self.beam_search_one_step(batch,beam_num,repeat,row,out,out_probability,out_add)\n",
        "\n",
        "      gc.collect()\n",
        "      return(out , out_probability)\n",
        "\n",
        "    def beam_search_one_step(self,batch,beam_num,repeat,row,sentences,p_sentences,n_beam_output):\n",
        "    # sentences : {type : tensor , shape : (batch X beam_num) X now_sentences_length X 1 value : int}\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num X 1 value : log_softmax probability}\n",
        "    # n_beam_output : {type : tensor , shape : batch X beam_num X dictionary_length,\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk in [0,1])}\n",
        "\n",
        "      '''\n",
        "      TO DO : (set beam num = K)\n",
        "      for every batch:\n",
        "      expand sentences(total number = K) K times (so there are K-square sentences),then concat with\n",
        "      the index of top K consequence of each beam(total K beams) in n_beam_output (so there are also K-square values).\n",
        "      '''\n",
        "      # sentences : {type : tensor , shape : batch X beam_num X now_sentences_length value : int}\n",
        "      sentences = sentences.view(batch,beam_num,-1)\n",
        "      # repeat : {type : tensor , shape : beam_num ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = repeat[:beam_num]\n",
        "      # sentences_expand : {type : tensor , shape : batch X (beam_num X beam_num) X now_sentences_length ,\n",
        "      # value : [[[A,B...] X beam_num times,[C,D...] X beam_num times}...] A,B,C,D...are int}\n",
        "      # sentences_expand = torch.repeat_interleave(sentences,repeat,dim=1)\n",
        "      sentences_expand = torch.repeat(1,beam_num,1)\n",
        "\n",
        "      # topk_prob : {type : tensor , shape : batch X beam_num X beam_num, value : log_softmax probability}\n",
        "      # topk_index : {type : tensor , shape : batch X beam_num X beam_num, value : int}\n",
        "      topk_prob, topk_index = torch.topk(n_beam_output,dim = -1,k = beam_num)\n",
        "\n",
        "      # topk_index : {type : tensor , shape : batch X (beam_num X beam_num) X 1, value : int}\n",
        "      topk_index = topk_index.view(batch,-1,1)\n",
        "      # sentences : {type : tensor , shape : batch X (beam_num X beam_num) X (now_sentences_length+1), value : int}\n",
        "      sentences_expand = torch.cat((sentences_expand,topk_index),dim = -1)\n",
        "      '''\n",
        "      TO DO :\n",
        "      multipies p_sentences with the probability of top K consequence of each beam(total K beams) in n_beam_output\n",
        "      (so there are also K-square values).\n",
        "\n",
        "      The final step is to choose Top K consequence from K-square sentences by using p_sentences.\n",
        "      '''\n",
        "\n",
        "      # p_sentences : {type : tensor , shape : batch X (beam_num X beam_num),\n",
        "      # value : [P1,P2,P3...] X beam_num times (Pk is log_softmax probability)}\n",
        "      p_sentences = (p_sentences+topk_prob).view(batch,-1)\n",
        "      # p_sentences : {type : tensor , shape : batch X beam_num, value : log_softmax probability}\n",
        "      # p_index : {type : tensor , shape : batch X beam_num, value : int}\n",
        "      p_sentences, p_index = torch.topk(p_sentences, dim = 1, k = beam_num)\n",
        "      p_sentences = p_sentences.unsqueeze(-1)\n",
        "      # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "      # sentences : {type : tensor , shape : batch X beam_num X (now_sentences_length+1), value : log_softmax probability}\n",
        "      new_sentences = sentences_expand[row, p_index].view(batch*beam_num,-1)\n",
        "      sentences.data = new_sentences.data\n",
        "      gc.collect()\n",
        "      return sentences,p_sentences\n",
        "# test repeat and sentence select\n",
        "\n",
        "# x = torch.randint(0,10,(2,5))\n",
        "# print(x)\n",
        "# r1 = x.repeat(3,1).view(3,2,-1)\n",
        "# print(r1)\n",
        "# r2 = x.repeat_interleave(torch.tensor([3,3]),dim=0).view(3,2,-1)\n",
        "# print(r2)\n",
        "# row = torch.tensor(range(3)).unsqueeze(1)\n",
        "# p_index = torch.tensor([[1,0],[0,1],[0,1]])\n",
        "# new_sentences = r1[row, p_index].view(6,-1)\n",
        "# print(new_sentences)\n",
        "\n",
        "# test decode_with_beam_search\n",
        "\n",
        "# batch = 3\n",
        "# beam_num = 2\n",
        "# sentences = torch.randint(0,8000,(batch*beam_num,5))\n",
        "# p_sentences = torch.log(torch.rand((batch , beam_num , 1)))\n",
        "# n_beam_output = torch.rand((batch , beam_num , 8000))\n",
        "# print(sentences,p_sentences,n_beam_output)\n",
        "# print(beam_search_one_step(sentences,p_sentences,n_beam_output))\n",
        "# repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "# sentences_expand = torch.repeat_interleave(sentences.view(batch,beam_num,-1),repeat,dim=1)\n",
        "# print(sentences_expand,sentences_expand.shape)\n",
        "# decode_model = Decode_With_Beam_Search(32,model,2,400,8000,2,0)\n",
        "# outputs_in_word,outputs = decode_model(False,src,src_mask)\n",
        "# print(output[0])\n"
      ],
      "metadata": {
        "id": "6hrE6wYFxTIs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def beam_search_one_step(device,sentences,p_sentences,n_beam_output):\n",
        "    # sentences : {type : tensor , shape : (batch X beam_num) X now_sentences_length X 1 value : int}\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num X 1 value : log_softmax probability}\n",
        "    # n_beam_output : {type : tensor , shape : batch X beam_num X dictionary_length,\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk in [0,1])}\n",
        "\n",
        "    '''\n",
        "    TO DO : (set beam num = K)\n",
        "    for every batch:\n",
        "    expand sentences(total number = K) K times (so there are K-square sentences),then concat with\n",
        "    the index of top K consequence of each beam(total K beams) in n_beam_output (so there are also K-square values).\n",
        "    '''\n",
        "    batch = n_beam_output.size(0)\n",
        "    beam_num = n_beam_output.size(1)\n",
        "    # sentences : {type : tensor , shape : batch X beam_num X now_sentences_length value : int}\n",
        "    sentences = sentences.view(batch,beam_num,-1)\n",
        "    # repeat : {type : tensor , shape : beam_num ,value : beam_num}\n",
        "    # each row repeat beam_num times before concatenate\n",
        "    repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "    repeat = repeat.to(device)\n",
        "    # sentences_expand : {type : tensor , shape : batch X (beam_num X beam_num) X now_sentences_length ,\n",
        "    # value : [[[A,B...] X beam_num times,[C,D...] X beam_num times}...] A,B,C,D...are int}\n",
        "    sentences_expand = torch.repeat_interleave(sentences,repeat,dim=1)\n",
        "\n",
        "    # topk_prob : {type : tensor , shape : batch X beam_num X beam_num, value : log_softmax probability}\n",
        "    # topk_index : {type : tensor , shape : batch X beam_num X beam_num, value : int}\n",
        "    topk_prob, topk_index = torch.topk(n_beam_output,dim = -1,k = beam_num)\n",
        "\n",
        "    # topk_index : {type : tensor , shape : batch X (beam_num X beam_num) X 1, value : int}\n",
        "    topk_index = topk_index.view(batch,-1,1)\n",
        "    # sentences : {type : tensor , shape : batch X (beam_num X beam_num) X (now_sentences_length+1), value : int}\n",
        "    sentences_expand = torch.cat((sentences_expand,topk_index),dim = -1)\n",
        "    '''\n",
        "    TO DO :\n",
        "    multipies p_sentences with the probability of top K consequence of each beam(total K beams) in n_beam_output\n",
        "    (so there are also K-square values).\n",
        "\n",
        "    The final step is to choose Top K consequence from K-square sentences by using p_sentences.\n",
        "    '''\n",
        "\n",
        "    # p_sentences : {type : tensor , shape : batch X (beam_num X beam_num),\n",
        "    # value : [P1,P2,P3...] X beam_num times (Pk is log_softmax probability)}\n",
        "    p_sentences = (p_sentences+topk_prob).view(batch,-1)\n",
        "    # p_sentences : {type : tensor , shape : batch X beam_num, value : log_softmax probability}\n",
        "    # p_index : {type : tensor , shape : batch X beam_num, value : int}\n",
        "    p_sentences, p_index = torch.topk(p_sentences, dim = 1, k = beam_num)\n",
        "    p_sentences = p_sentences.unsqueeze(-1)\n",
        "    # row : {type : tensor , shape : batch X 1, value : [[0],[1],[2],...]}\n",
        "    row = torch.tensor(range(batch)).unsqueeze(1)\n",
        "    row = row.to(device)\n",
        "    # sentences : {type : tensor , shape : batch X beam_num X (now_sentences_length+1), value : log_softmax probability}\n",
        "    new_sentences = sentences_expand[row, p_index].view(batch*beam_num,-1)\n",
        "    sentences.data = new_sentences.data\n",
        "    gc.collect()\n",
        "    return sentences,p_sentences\n",
        "\n",
        "def get_next_word(model,is_last_batch,device,memory,out,out_probability,id,batch,beam_num,max_sentence_length,dictionary_length,padding_id):\n",
        "    # padding : {type : tensor , shape : (Batch X beam_num) X (max_sentence_length-(id+1)) ,value : int}\n",
        "    padding = torch.full(size = (batch*beam_num,max_sentence_length-(id+1)),fill_value = padding_id)\n",
        "    padding = padding.to(device)\n",
        "    # out_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length,\n",
        "    # value : [[bos_id],[any_id],...[padding_id],....] X Batch}\n",
        "    out_padding = torch.cat((out,padding),dim = 1)\n",
        "    # tgt_padding : {type : tensor , shape : (Batch X beam_num) X max_sentence_length ,value: bool}\n",
        "    tgt_padding = (out_padding == padding_id).squeeze(-1)\n",
        "    # out_add : {type : tensor , shape : Batch X beam_num X dictionary_length ,value : int}\n",
        "    out_add = model.decoder(is_last_batch,memory,out_padding,tgt_padding)[:,id,:].view(batch,beam_num,dictionary_length)\n",
        "    # out_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "    # out_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "    out , out_probability = beam_search_one_step(device,out,out_probability,out_add)\n",
        "\n",
        "    gc.collect()\n",
        "    return(out , out_probability)\n",
        "\n",
        "def decode_with_beam_search(device,is_last_batch,model,src,src_mask,beam_num,max_sentence_length,\n",
        "               dictionary_length,bos_id,padding_id):\n",
        "    with torch.no_grad():\n",
        "      batch = src.size(0)\n",
        "      # decoder_input : {type : tensor , shape : Batch X 1 , value : bos_id}\n",
        "      decoder_input = torch.full(size = (batch,1),fill_value = bos_id)\n",
        "      decoder_input = decoder_input.to(device)\n",
        "      # repeat : {type : tensor , shape : Batch ,value : beam_num}\n",
        "      # each row repeat beam_num times before concatenate\n",
        "      repeat = torch.full([batch],fill_value = beam_num)\n",
        "      repeat = repeat.to(device)\n",
        "      # decoder_beam_expand : {type : tensor , shape : (Batch X beam_num) X 1 ,value : bos_id}\n",
        "      decoder_beam_expand = torch.repeat_interleave(decoder_input,repeat,dim=0)\n",
        "\n",
        "      # decoder_probability {type : tensor , shape : Batch X beam_num X 1, value : 0.1}\n",
        "      decoder_probability = torch.full(size = (batch,beam_num,1),fill_value = 0.0)\n",
        "      decoder_probability = decoder_probability.to(device)\n",
        "\n",
        "      # memory : {type : tensor , shape : Batch X max_sentence_length X encoder_output_dim ,value : arbitary float}\n",
        "      memory = model.encoder(is_last_batch,src,src_mask)\n",
        "      # memory_beam_expand : {type : tensor ,\n",
        "      # shape : (Batch X n_beam) X max_sentence_length X encoder_output_dim ,value : float}\n",
        "      memory_beam_expand = torch.repeat_interleave(memory,repeat,dim=0)\n",
        "\n",
        "      gc.collect()\n",
        "\n",
        "      for id in range(max_sentence_length-1):\n",
        "\n",
        "        # decoder_n_beam : {type : tensor , shape : (Batch X beam_num) X (id+1) ,value : int}\n",
        "        # decoder_probability {type : tensor , shape : Batch X beam_num X 1 , value : log_softmax probability}\n",
        "        new_decoder_beam_expand , new_decoder_probability = \\\n",
        "        get_next_word(model,is_last_batch,device,memory_beam_expand,decoder_beam_expand,\n",
        "               decoder_probability,id,batch,beam_num,max_sentence_length,dictionary_length,padding_id)\n",
        "\n",
        "        decoder_beam_expand,decoder_probability = new_decoder_beam_expand , new_decoder_probability\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "      # out_beam_expand : {type : tensor , shape : Batch X beam_num X (max_sentence_length) ,value : 0 or 1}\n",
        "      decoder_beam_expand = decoder_beam_expand.view(batch,beam_num,max_sentence_length)\n",
        "      # max_probability : {type : tensor , shape :  Batch  X 1 ,value : int(max prob index)}\n",
        "      max_probability = torch.argmax(input = decoder_probability,dim = 1)\n",
        "      # max_probability_expand : {type : tensor , shape :  Batch  X 1 X max_sentence_length ,\n",
        "      # value : [[A,A,A....],[B,B,B...],...](A,B are int)}\n",
        "      max_probability_expand = max_probability.expand(batch, max_sentence_length).unsqueeze(1)\n",
        "      # decoder_out : {type : tensor , shape :  Batch X max_sentence_length ,\n",
        "      # value : [[int,int,...],[int,int...],...]}\n",
        "      decoder_out =  torch.gather(input = decoder_beam_expand ,dim = 1, index = max_probability_expand).squeeze(1)\n",
        "    print(decoder_out[0])\n",
        "    return decoder_out,F.one_hot(decoder_out,dictionary_length).float()\n",
        "\n",
        "# test decode_with_beam_search\n",
        "# batch = 3\n",
        "# beam_num = 2\n",
        "# sentences = torch.randint(0,8000,(batch*beam_num,5))\n",
        "# p_sentences = torch.log(torch.rand((batch , beam_num , 1)))\n",
        "# n_beam_output = torch.rand((batch , beam_num , 8000))\n",
        "# print(sentences,p_sentences,n_beam_output)\n",
        "# print(beam_search_one_step(sentences,p_sentences,n_beam_output))\n",
        "# repeat = torch.full([beam_num],fill_value = beam_num)\n",
        "# sentences_expand = torch.repeat_interleave(sentences.view(batch,beam_num,-1),repeat,dim=1)\n",
        "# print(sentences_expand,sentences_expand.shape)\n",
        "# output = decode_with_beam_search(model,src,src_mask,2,400,8000,)\n",
        "# print(output[0])"
      ],
      "metadata": {
        "id": "sz_zI5fDh9UU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bleu\n",
        "------"
      ],
      "metadata": {
        "id": "Pt1o-F1Ik8cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torcheval.metrics.functional.text import bleu\n",
        "def get_bleu_score(outputs,tgt,tgt_tokenizer,eos_id):\n",
        "    outputs = np.array(outputs.detach().tolist())\n",
        "    outputs = [x[:np.nonzero(x == eos_id)[0][0]].tolist() if len(np.nonzero(x == eos_id)[0])>0 \\\n",
        "              else x.tolist() for x in outputs ]\n",
        "\n",
        "    outputs_decode = tgt_tokenizer.decode(outputs)\n",
        "    out = [outputs_decode[i] for i in range(len(outputs_decode)) if len(outputs_decode[i])>= 4]\n",
        "    print(out)\n",
        "    out = [\" \".join(list(x)) for x in out]\n",
        "    print(out)\n",
        "    tgt_decode = tgt_tokenizer.decode(tgt.detach().tolist())\n",
        "    tgt = [tgt_decode[i] for i in range(len(outputs_decode)) if len(outputs_decode[i])>= 4]\n",
        "    print(tgt)\n",
        "    tgt = [\" \".join(list(x)) for x in tgt]\n",
        "    print(tgt)\n",
        "    return bleu.bleu_score(out, tgt, n_gram=4).detach().item()\n",
        "# test bleu\n",
        "# test_tokenizer = spm.SentencePieceProcessor(model_file = \"/content/spm_8000_zh.model\")\n",
        "# candidates = torch.tensor([[21,3,9,99,42],[5,78,89,3,31]])\n",
        "# references = torch.tensor([[18,5,9,3,42],[3,5,78,89,50]])\n",
        "# get_bleu_score(candidates,references,test_tokenizer,3)"
      ],
      "metadata": {
        "id": "ISpHxGVQk7dh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train and validation function\n",
        "------"
      ],
      "metadata": {
        "id": "GF4GshwGjz-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "def train_one_batch(device,model,loss_calculator,is_last_batch,\n",
        "          src,tgt,src_mask,tgt_mask,dictionary_length,\n",
        "          optimizer):\n",
        "\n",
        "    outputs = model(is_last_batch,src,tgt,src_mask,tgt_mask)\n",
        "\n",
        "    loss = loss_calculator(is_last_batch,outputs,tgt)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return loss.detach().item(),outputs[0].detach()\n",
        "\n",
        "def valid(device,model,loss_calculator,batch_size_setting,valid_loader,beam_num,max_sentence_length,\n",
        "      dictionary_length,bos_id,eos_id,pad_id,tgt_tokenizer):\n",
        "    batch_loss = []\n",
        "    batch_bleu_score = []\n",
        "    with torch.no_grad():\n",
        "      for val_batch in tqdm(valid_loader,desc=\"valid_step\", unit=\" step\"):\n",
        "        src,tgt,src_mask,tgt_mask = val_batch\n",
        "        src,tgt,src_mask = src.to(device),tgt.to(device),src_mask.to(device)\n",
        "\n",
        "        batch_size = src.size(0)\n",
        "\n",
        "        is_last_batch = False\n",
        "        if batch_size != batch_size_setting:\n",
        "          is_last_batch = True\n",
        "        decode_model = Decode_With_Beam_Search(batch_size,model,beam_num,max_sentence_length,\n",
        "                            dictionary_length,bos_id,pad_id)\n",
        "        decode_model.to(device)\n",
        "        outputs_in_word,outputs = decode_model(is_last_batch,src,src_mask)\n",
        "        # outputs_in_word,outputs = decode_with_beam_search(device,is_last_batch,model,src,src_mask,beam_num,\\\n",
        "        #       max_sentence_length,dictionary_length,bos_id,pad_id)\n",
        "\n",
        "\n",
        "        loss = loss_calculator(is_last_batch,outputs,tgt)\n",
        "\n",
        "        bleu_score = get_bleu_score(outputs_in_word,tgt,tgt_tokenizer,eos_id)\n",
        "\n",
        "        batch_loss.append(loss)\n",
        "        batch_bleu_score.append(bleu_score)\n",
        "\n",
        "      avg_valid_loss = batch_loss.sum()/len(batch_loss).detach().item()\n",
        "      avg_bleu_score = batch_bleu_score.sum()/len(batch_bleu_score).detach().item()\n",
        "\n",
        "    return avg_valid_loss,avg_bleu_score"
      ],
      "metadata": {
        "id": "bwXkljhMFqKV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main function\n",
        "------"
      ],
      "metadata": {
        "id": "R7I8W9cQj7ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def main(setting,dataset_is_prepare = False,load_model = False):\n",
        "\n",
        "    # set random seed\n",
        "    myseed = 1\n",
        "    np.random.seed(myseed)\n",
        "    torch.manual_seed(myseed)\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "    # data set & tokenizer\n",
        "    if not dataset_is_prepare:\n",
        "        clean_data_and_save(\n",
        "        path_doc = setting[\"data_info\"][\"document\"],\n",
        "        raw_src_path = setting[\"data_info\"][\"source\"][\"raw_data_path\"],\n",
        "        raw_tgt_path = setting[\"data_info\"][\"target\"][\"raw_data_path\"],\n",
        "        clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "        clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "        threshold = setting[\"tokenized_setting\"][\"max_l\"])\n",
        "\n",
        "        src_tokenizer,tgt_tokenizer = tokenized_data(\n",
        "            vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            tokenized_setting = {k:setting[\"tokenized_setting\"][k] for k in \\\n",
        "                      set(list(setting[\"tokenized_setting\"].keys()))-{\"vocab_size\",\"max_l\"}},\n",
        "            max_l = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "            path_doc = setting[\"data_info\"][\"document\"],\n",
        "            clean_src_path = setting[\"data_info\"][\"source\"][\"clean_data_path\"],\n",
        "            clean_tgt_path = setting[\"data_info\"][\"target\"][\"clean_data_path\"],\n",
        "            src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "            tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],\n",
        "            st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "            st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "            tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "            tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"])\n",
        "    else:\n",
        "        src_tokenizer,tgt_tokenizer = get_tokenizers(\n",
        "            path_doc = setting[\"data_info\"][\"document\"],\n",
        "            vocab_size = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            src_lang = setting[\"data_info\"][\"source\"][\"lang\"],\n",
        "            tgt_lang = setting[\"data_info\"][\"target\"][\"lang\"],)\n",
        "\n",
        "    # data loader\n",
        "    train_batch_size_setting = setting[\"training_hparas\"][\"train_batch_size\"]\n",
        "    valid_batch_size_setting = setting[\"training_hparas\"][\"valid_batch_size\"]\n",
        "    train_loader,valid_loader = get_data_set(\n",
        "        train_batch_size = train_batch_size_setting,\n",
        "        valid_batch_size = valid_batch_size_setting,\n",
        "        num_workers = setting[\"training_hparas\"][\"workers\"],\n",
        "        path_doc = setting[\"data_info\"][\"document\"],\n",
        "        st_train_path = setting[\"data_info\"][\"source\"][\"tokenized_train_data\"],\n",
        "        st_val_path = setting[\"data_info\"][\"source\"][\"tokenized_val_data\"],\n",
        "        tt_train_path = setting[\"data_info\"][\"target\"][\"tokenized_train_data\"],\n",
        "        tt_val_path = setting[\"data_info\"][\"target\"][\"tokenized_val_data\"],\n",
        "        pad_id = setting[\"tokenized_setting\"][\"pad_id\"])\n",
        "    train_iter = iter(train_loader)\n",
        "    valid_iter = iter(valid_loader)\n",
        "\n",
        "    # model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model =  build_model(\n",
        "          max_sentence_length = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "          dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "          padding_idx = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "          encoder_embedding_dimension = setting[\"model\"][\"encoder_embedding_dimension\"],\n",
        "          decoder_embedding_dimension = setting[\"model\"][\"decoder_embedding_dimension\"],\n",
        "          feedforward_dimension = setting[\"model\"][\"feedforward_dimension\"],\n",
        "          num_heads = setting[\"model\"][\"num_heads\"],\n",
        "          dropout_p = setting[\"model\"][\"dropout_p\"],\n",
        "          layer_num = setting[\"model\"][\"layer_num\"])\n",
        "\n",
        "    if load_model:\n",
        "      checkpoint = torch.load(setting[\"training_hparas\"][\"model_temporary_saving_path\"])\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    train_loss_calculator = LabelSmoothedCrossEntropyCriterion(\n",
        "                batch_size = train_batch_size_setting,\n",
        "                dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "                padding_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "                smoothing = setting[\"training_hparas\"][\"label_smoothing\"])\n",
        "\n",
        "    valid_loss_calculator = LabelSmoothedCrossEntropyCriterion(\n",
        "            batch_size = valid_batch_size_setting,\n",
        "            dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "            padding_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "            smoothing = 0)\n",
        "\n",
        "    train_loss_calculator,valid_loss_calculator = \\\n",
        "    train_loss_calculator.to(device),valid_loss_calculator.to(device)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), **(setting[\"training_hparas\"][\"optimization\"][\"optimizer\"]))\n",
        "\n",
        "    Noam_optimizer = NoamOpt(\n",
        "             dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "             factor = setting[\"training_hparas\"][\"optimization\"][\"factor\"],\n",
        "             warmup = setting[\"training_hparas\"][\"optimization\"][\"warmup\"],\n",
        "             optimizer = optimizer)\n",
        "    if load_model:\n",
        "      Noam_optimizer.set_step(checkpoint['step'])\n",
        "      Noam_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    # step\n",
        "    total_step = setting[\"training_hparas\"][\"total_step\"]\n",
        "    early_stop_epoch = setting[\"training_hparas\"][\"early_stop_step\"]\n",
        "    do_valid_steps = setting[\"training_hparas\"][\"do_valid_step\"]\n",
        "    early_stop_count = 0\n",
        "    progress_bar = tqdm(total = do_valid_steps, desc=\"train_step\", unit=\" step\")\n",
        "\n",
        "    # output datas\n",
        "    train_loss_every_batchs = []\n",
        "    valid_loss = []\n",
        "    bleu_score = []\n",
        "    best_bleu_score = 0\n",
        "\n",
        "    step = 0\n",
        "    if load_model:\n",
        "      step = checkpoint['step']\n",
        "\n",
        "    while step <= total_step:\n",
        "\n",
        "      # training\n",
        "      # iter batch\n",
        "      try:\n",
        "        train_batch = next(train_iter)\n",
        "      except StopIteration:\n",
        "        train_iter = iter(train_loader)\n",
        "        train_batch = next(train_iter)\n",
        "\n",
        "      # compute batch loss and update parameters in model\n",
        "      model.train()\n",
        "\n",
        "      src,tgt,src_mask,tgt_mask = train_batch\n",
        "      src,tgt,src_mask,tgt_mask = src.to(device),tgt.to(device),\\\n",
        "                     src_mask.to(device),tgt_mask.to(device)\n",
        "      batch_size = src.size(0)\n",
        "\n",
        "      is_last_batch = False\n",
        "      if batch_size != train_batch_size_setting:\n",
        "        is_last_batch = True\n",
        "\n",
        "      train_loss, test_sentence = train_one_batch(\n",
        "              device = device,\n",
        "              model = model,\n",
        "              loss_calculator = train_loss_calculator,\n",
        "              is_last_batch = is_last_batch,\n",
        "              src = src,\n",
        "              tgt = tgt,\n",
        "              src_mask = src_mask,\n",
        "              tgt_mask = tgt_mask,\n",
        "              dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "              optimizer = Noam_optimizer)\n",
        "\n",
        "      train_loss_every_batchs.append(train_loss)\n",
        "      temp_save_and_print = setting[\"training_hparas\"][\"temp_save_step\"]\n",
        "      if (step+1) % (temp_save_and_print) == 0:\n",
        "        loss_list = train_loss_every_batchs[int(-1*(temp_save_and_print)):-1]\n",
        "        print(sum(loss_list) / len(loss_list))\n",
        "        print(tgt_tokenizer.decode(torch.argmax(test_sentence,dim = -1).tolist()))\n",
        "        print(tgt_tokenizer.decode(tgt[0].detach().tolist()))\n",
        "        torch.save({'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': Noam_optimizer.state_dict(),\n",
        "            'step': step},\n",
        "            setting[\"training_hparas\"][\"model_temporary_saving_path\"])\n",
        "\n",
        "      progress_bar.update()\n",
        "      if (step+1) % do_valid_steps == 0:\n",
        "\n",
        "        print(train_loss_every_batchs[-1])\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "        model.eval()\n",
        "        avg_val_loss,avg_bleu_score = valid(\n",
        "                        device = device,\n",
        "                        model = model,\n",
        "                        loss_calculator = valid_loss_calculator,\n",
        "                        batch_size_setting = valid_batch_size_setting,\n",
        "                        valid_loader = valid_loader,\n",
        "                        beam_num = setting[\"training_hparas\"][\"beam_num\"],\n",
        "                        max_sentence_length = setting[\"tokenized_setting\"][\"max_l\"],\n",
        "                        dictionary_length = setting[\"tokenized_setting\"][\"vocab_size\"],\n",
        "                        bos_id = setting[\"tokenized_setting\"][\"bos_id\"],\n",
        "                        eos_id = setting[\"tokenized_setting\"][\"eos_id\"],\n",
        "                        pad_id = setting[\"tokenized_setting\"][\"pad_id\"],\n",
        "                        tgt_tokenizer = tgt_tokenizer)\n",
        "        valid_loss.append(avg_val_loss)\n",
        "        bleu_score.append(avg_bleu_score)\n",
        "\n",
        "        # print avg loss\n",
        "        print(f\"average train loss = {sum(train_loss_every_batchs[-1*do_valid_steps:-1])/len(do_valid_steps):.4f}\")\n",
        "        print(f\"average valid loss = {valid_loss[-1]:.4f}\")\n",
        "        print(f\"average valid loss = {bleu_score[-1]:.4f}\")\n",
        "\n",
        "        # saving model and check early stop criterion\n",
        "        if bleu_score[-1] > best_bleu_score:\n",
        "          torch.save(model.state_dict(), setting[\"training_hparas\"][\"model_saving_path\"])\n",
        "        else :\n",
        "          early_stop_count += 1\n",
        "\n",
        "        if early_stop_count == early_stop_epoch:\n",
        "          break\n",
        "\n",
        "        progress_bar = tqdm(total = do_valid_steps, desc=\"train_step\", unit=\" step\")\n",
        "\n",
        "        step += 1\n",
        "    progress_bar.close()\n",
        "\n",
        "    return train_loss_every_batchs,valid_loss,bleu_score"
      ],
      "metadata": {
        "id": "e7hn-NAjHSQ5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(setting, dataset_is_prepare = True, load_model = True)\n",
        "# gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGUYF3WnrI9F",
        "outputId": "33b93aaf-61b3-4bdd-8c76-e271297b6066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 384064/384064 [00:41<00:00, 9266.99it/s] \n",
            "100%|██████████| 384064/384064 [00:33<00:00, 11374.97it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 15657.24it/s]\n",
            "100%|██████████| 3879/3879 [00:00<00:00, 14680.64it/s]\n",
            "train_step:   2%|▏         | 999/40000 [14:36<9:32:14,  1.14 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98.77808591672728\n",
            "在197年,七,,日人父母個孩子款開始被被單,我的tua這的字p了\"母本\"\"\"的\"的\"的的的的的\n",
            "2005年十月的時候第一批的七個貸款都還清後我和matt將網站的\"試用版\"字樣移除\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:   5%|▍         | 1999/40000 [29:21<9:17:30,  1.14 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.50696465966699\n",
            "同樣的是,覆,,池,姊叫做「小的,一。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "情況類似重一點的電子的兄弟,叫做渺子和濤子。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:   7%|▋         | 2999/40000 [44:06<9:02:00,  1.14 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98.86063651542167\n",
            "細菌菌體會會有效長。細菌。。。。。。。。,。。。,,的的的,的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的\n",
            "而噬菌體則很擅長感染細菌。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  10%|▉         | 3999/40000 [58:52<8:48:20,  1.14 step/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97.61387832076461\n",
            "大約就像基因法的,我們我們年代起,我們一直以來在基因的法的的基因金法。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。。\n",
            "看起來就像是魔法一樣,從那個時候起,我們一直生活在擁有魔法藥物的黃金時代裡。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train_step:  11%|█         | 4390/40000 [1:04:42<8:41:47,  1.14 step/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save({\n",
        "#             'epoch': epoch,\n",
        "#             'model_state_dict': model.state_dict(),\n",
        "#             'optimizer_state_dict': optimizer.state_dict(),\n",
        "#             'loss': loss,\n",
        "#             ...\n",
        "#             }, PATH)\n",
        "# model = TheModelClass(*args, **kwargs)\n",
        "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "# checkpoint = torch.load(PATH)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# model.eval()\n",
        "# # - or -\n",
        "# model.train()"
      ],
      "metadata": {
        "id": "NAQywvDycPXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import logging\n",
        "# import datetime\n",
        "# from pathlib import Path\n",
        "\n",
        "# def set_logger(log_name : str):\n",
        "#     \"\"\"write log under given log_path\"\"\"\n",
        "#     log_dir = Path(\"./log\")\n",
        "#     log_dir.mkdir(parents=True, exist_ok=True)\n",
        "#     log_path = log_dir / f\"{datetime.datetime.now().date()}.log\"\n",
        "\n",
        "#     logger = logging.getLogger(log_name)\n",
        "#     logger.setLevel(logging.INFO)\n",
        "#     formater_s = logging.Formatter(\"%(name)s [%(levelname)s] %(message)s\")\n",
        "#     #formater_f = logging.Formatter(\"%(asctime)s - %(name)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "#     if not logger.handlers:\n",
        "#         \"\"\"\n",
        "#         # logging to file\n",
        "#         file_handler = logging.FileHandler(log_path)\n",
        "#         file_handler.setFormatter(formater_f)\n",
        "#         logger.addHandler(file_handler)\n",
        "#         \"\"\"\n",
        "#         # logging to console\n",
        "#         stream_handler = logging.StreamHandler()\n",
        "#         stream_handler.setFormatter(formater_s)\n",
        "#         logger.addHandler(stream_handler)\n",
        "\n",
        "#     return logger\n"
      ],
      "metadata": {
        "id": "RaaYZopHC5c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt\n",
        "class get_plot():\n",
        "    def __init__(self,train_loss_every_batchs,valid_loss,bleu_score,\n",
        "           step = setting[\"training_hparas\"][\"do_valid_step\"]):\n",
        "      self.train = train_loss_every_batchs\n",
        "      self.val = valid_loss\n",
        "      self.score = bleu_score\n",
        "      self.step = step\n",
        "    def plot_train_loss(self,figsize = [6,12],ylims = [0,10]):\n",
        "      index = [i for i in range(len(self.train))]\n",
        "      plt.figure(figsize = figsize, layout='constrained')\n",
        "      plt.plot(data = [index, self.train],\n",
        "           color = \"ted:blue\", label = \"train loss\")\n",
        "      plt.ylim(ylims)\n",
        "      plt.xlabel(\"step\")\n",
        "      plt.ylabel(\"loss\")\n",
        "      plt.legend()\n",
        "      plt.show()\n",
        "    def plot_loss(self,figsize = [6,12],ylims = [0,10]):\n",
        "      avg_step = self.step//10+1\n",
        "      train_index = list(range(0,len(self.train),self.step))\n",
        "      if train_index[-1] != self.train[-1]:\n",
        "        train_index[-1] += [self.train[-1]]\n",
        "\n",
        "      train_avg = [self.train[:avg_step].mean()] + \\\n",
        "             [self.train[i-avg_step:i+avg_step].mean() for i in train_index[1:-1]] + \\\n",
        "             [self.train[-avg_step:].mean()]\n",
        "\n",
        "      plt.figure(figsize = figsize, layout='constrained')\n",
        "      plt.plot(data = [train_index, train_avg],\n",
        "          color = \"ted:blue\", label = \"train loss\")\n",
        "      plt.plot(data = [train_index, self.val],\n",
        "          color = \"ted:red\", label = \"val loss\")\n",
        "      plt.ylim(ylims)\n",
        "      plt.xlabel(\"step\")\n",
        "      plt.ylabel(\"loss\")\n",
        "      plt.legend()\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "WHjjzhzIIXl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Records:\n",
        "  def __init__(self):\n",
        "    self.train_losses = []\n",
        "    self.valid_score = []\n",
        "\n",
        "  def record_train(self, loss):\n",
        "    self.train_losses.append(loss)\n",
        "\n",
        "  def record_valid(self, score):\n",
        "    self.valid_score.append(score)\n",
        "\n",
        "  def pop_train_record(self, idx):\n",
        "    \"\"\"Pop specified train record at position 'idx', and returns popped value.\"\"\"\n",
        "    return self.train_losses.pop(idx)\n",
        "\n",
        "  def get_mean_train_records(self, length=1000):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      length (:obj:`int`):\n",
        "        length of records to mean\n",
        "    Return:\n",
        "      mean loss\n",
        "    \"\"\"\n",
        "    train_losses = np.array(self.train_losses)\n",
        "    if len(train_losses) > length:\n",
        "      return train_losses[-length : -1].mean()\n",
        "    else:\n",
        "      return train_losses[:-1].mean()\n",
        "\n",
        "  def get_best_score(self):\n",
        "    \"\"\"Get the best bleu score.\"\"\"\n",
        "    return max(self.valid_score)\n",
        "\n",
        "  def get_records_for_plot(self):\n",
        "    \"\"\"\n",
        "    Get records for plotting.\n",
        "\n",
        "    Return:\n",
        "      gap between consecutive records, records of train (:obj:`dict`), records of validation (:obj:`dict`)\n",
        "    \"\"\"\n",
        "    train_losses = np.array(self.train_losses)\n",
        "    valid_score = np.array(self.valid_score)\n",
        "    # The length of training-losses to mean so that the output lengths of train-losses\n",
        "    #   and valid-score be the same.\n",
        "    gap = (train_losses.size // valid_score.size) + 1\n",
        "\n",
        "    out_train = {\"loss\": []}\n",
        "    out_valid = {\"score\": valid_score}\n",
        "\n",
        "    for i in range(valid_score.size - 1):\n",
        "      out_train[\"loss\"].append(train_losses[i * gap : (i + 1) * gap].mean())\n",
        "    out_train[\"loss\"].append(train_losses[(valid_score.size - 1) * gap :].mean())\n",
        "\n",
        "    return gap, out_train, out_valid\n",
        "\n",
        "records = Records()"
      ],
      "metadata": {
        "id": "sKpZBzViNF_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "# pop the fake big train loss\n",
        "records.pop_train_record(0)\n",
        "# get records\n",
        "gap, records_train, records_valid = records.get_records_for_plot()\n",
        "last_train_loss = records_train[\"loss\"][-1]\n",
        "last_valid_score = records_valid[\"score\"][-1]\n",
        "print(f\"training loss: {last_train_loss:.3f} | valid score: {last_valid_score:.3f}\")\n",
        "\n",
        "# Base figure\n",
        "figure = plt.figure(figsize=(6, 12))\n",
        "x = [gap * (i+1) for i in range(len(records_valid[\"score\"]))]\n",
        "\n",
        "# loss\n",
        "figure.add_subplot(2, 1, 1)\n",
        "plt.plot(x, records_train[\"loss\"], c=\"tab:red\", label=\"train\")\n",
        "plt.ylim(0.0, 10.0)\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "\n",
        "# score\n",
        "figure.add_subplot(2, 1, 2)\n",
        "plt.plot(x, records_valid[\"score\"], c=\"tab:cyan\", label=\"valid\")\n",
        "plt.ylim(0.0, 1.0)\n",
        "plt.xlabel(\"steps\")\n",
        "plt.ylabel(\"score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qmu9OHdCNERP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}