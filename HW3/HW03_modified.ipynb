{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# You may choose where to download the data.\n",
    "\n",
    "# Google Drive\n",
    "#!gdown --id '1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy' --output food-11.zip\n",
    "\n",
    "# Dropbox\n",
    "# !wget https://www.dropbox.com/s/m9q6273jl3djall/food-11.zip -O food-11.zip\n",
    "\n",
    "# MEGA\n",
    "# !sudo apt install megatools\n",
    "# !megadl \"https://mega.nz/#!zt1TTIhK!ZuMbg5ZjGWzWX1I6nEUbfjMZgCmAgeqJlwDkqdIryfg\"\n",
    "\n",
    "# Unzip the dataset.\n",
    "# This may take some time.\n",
    "#!unzip -q food-11.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#import pytorch\n",
    "import torch\n",
    "\n",
    "# torch.backends.cudnn: set CNN algorithmtorch.backends.cudnn\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# get the current available device ('cpu' or 'cuda')\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(torch.cuda.is_available())\n",
    "#set random variable\n",
    "import numpy as np\n",
    "myseed = 1\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# m = nn.Conv2d(1, 1, 2 , stride=2, padding=(9,9),bias = False)\n",
    "# test = torch.tensor([[[1.0,2.0,3.0],[4.0,5.0,6.0],[7.0,8.0,9.0]]])\n",
    "# print(test)\n",
    "# print(m(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# with Image.open(\"C:/Users/user/Pictures\\Screenshots/資格證.jpg\") as im:\n",
    "#     im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# x = torch.FloatTensor([[2,7,1],[3,4,9],[5,6,8]])\n",
    "# y = x[x> 2]\n",
    "# print(x,y)\n",
    "# print(x.argmax(dim = 0))\n",
    "# print(x.argmax(dim = 1))\n",
    "# print(x.argmax(dim = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from PIL import Image\n",
    "def get_tfm(mode):\n",
    "    if mode in [\"val\",\"test\"]:\n",
    "      tfm = transforms.Compose([\n",
    "      transforms.Resize((128, 128)),\n",
    "      transforms.ToTensor(),\n",
    "      ])\n",
    "    elif mode in [\"train_unlabeled\",\"train\"]:\n",
    "       tfm = transforms.Compose([\n",
    "      transforms.Resize((128, 128)),\n",
    "      transforms.ToTensor(),\n",
    "      ])\n",
    "    return tfm\n",
    "def food_f(mode):\n",
    "    dataset = DatasetFolder(data_info[mode][\"path\"], loader=lambda x: Image.open(x), extensions=\"jpg\", transform=get_tfm(mode))\n",
    "    print('Size of {} data: {}'.format(mode,len(list(dataset))))\n",
    "    return dataset\n",
    "\n",
    "#create a dict of functions and path w.r.t. different mode\n",
    "data_info = {\n",
    "    \"train_origin\":{\"path\":\"./food-11/training/labeled\"},\n",
    "    \"train\":{\"path\":\"./food-11/training/unlabeled\"},\n",
    "    \"val\":{\"path\":\"./food-11/validation\"},\n",
    "    \"test\":{\"path\":\"./food-11/testing\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.transforms.transforms.Compose'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfm = transforms.Compose([\n",
    "      transforms.Resize((128, 128)),\n",
    "      transforms.ToTensor(),\n",
    "      ])\n",
    "print(type(tfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of val data: 660\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "x = 500# x = int(max(prep))\n",
    "print(list(food_f(\"val\"))[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_paras = {\n",
    "    # maximum number of epochs\n",
    "    'n_epochs': 200,\n",
    "    # mini-batch size for dataloader\n",
    "    'batch_size': 128,\n",
    "    # optimization algorithm (optimizer in torch.optim)\n",
    "    'optimizer': 'Adam',\n",
    "    # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "    'optim_hparas': {\n",
    "        # learning rate of Adam\n",
    "        'lr': 0.001,\n",
    "    },\n",
    "    'early_stop': 5,\n",
    "    # your model will be saved here\n",
    "    'save_path': './model.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML2021_python_3_11_5\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of val data: 660\n",
      "Size of test data: 3347\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Construct data loaders.\n",
    "train_loader = DataLoader(food_f(\"train\"), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_loader = DataLoader(food_f(\"val\"), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(food_f(\"test\"), batch_size=h_paras[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # The arguments for commonly used modules:\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "        # input image size: [3, 128, 128]\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(4, 4, 0),\n",
    "        )\n",
    "        self.flat_layer = nn.Flatten()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(256 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 11)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 128, 128]\n",
    "        # output: [batch_size, 11]\n",
    "\n",
    "        # Extract features by convolutional layers.\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = self.flat_layer(x)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_set,model_d,device):\n",
    "    # set model to evalutation mode\n",
    "    model_d.eval()\n",
    "    total_correct_number = 0\n",
    "    total_loss = 0\n",
    "    # iterate through the dataloader\n",
    "    for data , label in val_set:\n",
    "    # move data to device (cpu/cuda)\n",
    "      data_d, label_d = data.to(device), label.to(device)\n",
    "      # disable gradient calculation\n",
    "      with torch.no_grad():\n",
    "        # forward pass (compute output)\n",
    "        pred = model_d(data_d)\n",
    "        # get the index of the class with the highest probability\n",
    "        max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
    "        total_correct_number += (max_prob_indexs.cpu() == label_d.cpu()).sum().item()\n",
    "        # compute loss\n",
    "        mse_loss = model_d.cal_loss(pred, label_d)\n",
    "      # accumulate loss\n",
    "      batch_size = len(data_d)\n",
    "      total_loss += mse_loss.detach().cpu().item() * batch_size\n",
    "\n",
    "    # compute averaged loss\n",
    "    totol_size = len(val_set.dataset)\n",
    "    acc = total_correct_number/totol_size\n",
    "    avg_loss =  total_loss/totol_size\n",
    "    return acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\ML2021_python_3_11_5\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "def get_pseudo_labels(dataset, model, threshold=0.65):\n",
    "    # This functions generates pseudo-labels of a dataset using given model.\n",
    "    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n",
    "    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n",
    "\n",
    "    # Construct a data loader.\n",
    "    train_unlabeled_loader = \\\n",
    "    DataLoader(food_f(\"train_unlabeled\"), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # Make sure the model is in eval mode.\n",
    "    model.eval()\n",
    "    # Define softmax function.\n",
    "    softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    # Iterate over the dataset by batches.\n",
    "    for batch in tqdm(train_unlabeled_loader):\n",
    "        img, label = batch\n",
    "\n",
    "        # Forward the data\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(img.to(device))\n",
    "\n",
    "        # Obtain the probability distributions by applying softmax on logits.\n",
    "        predicts = softmax(logits)\n",
    "        for  index , probs in enumerate(predicts):\n",
    "            max_index , max_prob = probs.max()\n",
    "            if max_prob > threshold:\n",
    "                (logits[index],max_index)\n",
    "\n",
    "\n",
    "        # Filter the data and construct a new dataset.\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # # Turn off the eval mode.\n",
    "    model.train()\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2021_python_3_11_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
