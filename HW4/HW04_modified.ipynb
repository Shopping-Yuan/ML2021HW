{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79aa8f0935d243baafdcec9f8932450f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9497e561bb944165b4ed43c2a9cfa458",
              "IPY_MODEL_b3db996193f345c9be0866a7db385c88",
              "IPY_MODEL_1ad97658267f44b38dbc1ddae5c2ff27"
            ],
            "layout": "IPY_MODEL_80d2e5d7ec80460abb1106fca1841a4f"
          }
        },
        "9497e561bb944165b4ed43c2a9cfa458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9936d3fed14a47bf4c8f7d0f42db4c",
            "placeholder": "​",
            "style": "IPY_MODEL_2ac8e17deb7640d190c899e2f2105deb",
            "value": "100%"
          }
        },
        "b3db996193f345c9be0866a7db385c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_258088fb0946452ca9a78e95eab628bd",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_581e8a1272ac481989f463d1ee900cb0",
            "value": 6000
          }
        },
        "1ad97658267f44b38dbc1ddae5c2ff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8138daa92bf48268e92d995b458d884",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1066343ffd4d6e8c8cb924672fc8df",
            "value": " 6000/6000 [00:28&lt;00:00, 259.88it/s]"
          }
        },
        "80d2e5d7ec80460abb1106fca1841a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9936d3fed14a47bf4c8f7d0f42db4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac8e17deb7640d190c899e2f2105deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "258088fb0946452ca9a78e95eab628bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581e8a1272ac481989f463d1ee900cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8138daa92bf48268e92d995b458d884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1066343ffd4d6e8c8cb924672fc8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML2021HW/blob/Shopping_vscode_branch/HW4/HW04_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1cauo_ypX7F",
        "outputId": "2dbe3cb0-169f-49e9-dda5-18838d680b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copyfile('/content/drive/MyDrive/Dataset.zip','/content/Dataset.zip')\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/Dataset.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "rEgX4ezzB7SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"/content/Dataset\",\n",
        "    \"save_path\": \"model.ckpt\",\n",
        "    \"batch_size\": 32,\n",
        "    \"n_workers\": 8,\n",
        "    \"valid_steps\": 2000,\n",
        "    \"warmup_steps\": 1000,\n",
        "    \"save_steps\": 10000,\n",
        "    \"total_steps\": 70000,\n",
        "  }\n",
        "\n",
        "  return config"
      ],
      "metadata": {
        "id": "mfFqQ-KmrJGy"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "zWDKfQCSrx2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "33lkzQf43DNb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class myDataset(Dataset):\n",
        "  def __init__(self, data_dir, segment_len=128):\n",
        "    self.data_dir = data_dir\n",
        "    self.segment_len = segment_len\n",
        "\n",
        "    # Load the mapping from speaker neme to their corresponding id.\n",
        "    # Path package can use / to join path\n",
        "    #part 1-1\n",
        "    mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "    mapping = json.load(mapping_path.open())\n",
        "    self.speaker2id = mapping[\"speaker2id\"]\n",
        "    #self.speaker2id = {'id10001': 0, 'id10005': 1, ...... 'id11247': 598, 'id11251': 599}\n",
        "\n",
        "    #part 1-2\n",
        "    # Load metadata of training data.\n",
        "    metadata_path = Path(data_dir) / \"metadata.json\"\n",
        "    metadata = json.load(open(metadata_path))[\"speakers\"]\n",
        "\n",
        "    # Get the total number of speaker.\n",
        "    self.speaker_num = len(metadata.keys())\n",
        "    self.data = []\n",
        "    for speaker in metadata.keys():\n",
        "    #['id10473', 'id10328', 'id10382',......'id10864']\n",
        "      for utterances in metadata[speaker]:\n",
        "      # for example : metadata[speaker] = 'id10473'\n",
        "      # utterances = {'feature_path': 'uttr-5c88b2f1803449789c36f14fb4d3c1eb.pt', 'mel_len': 652}......\n",
        "        self.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
        "        # for example : ['uttr-5c88b2f1803449789c36f14fb4d3c1eb.pt',217]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    feat_path, speaker = self.data[index]\n",
        "    #[utterances[\"feature_path\"], self.speaker2id[speaker]\n",
        "\n",
        "    # Load preprocessed mel-spectrogram.\n",
        "    # https://pytorch.org/docs/stable/generated/torch.load.html\n",
        "    # using torch.load to open pt file . By default , tensors are loaded to GPU if they are GPU tensor.\n",
        "    # part 2\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "    # Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "    if len(mel) > self.segment_len:\n",
        "      # Randomly get the starting point of the segment.\n",
        "      start = random.randint(0, len(mel) - self.segment_len)\n",
        "      # Get a segment with \"segment_len\" frames.\n",
        "      mel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "    else:\n",
        "      mel = torch.FloatTensor(mel)\n",
        "    # Turn the speaker id into long for computing loss later.\n",
        "    speaker = torch.FloatTensor([speaker]).long()\n",
        "    return mel, speaker\n",
        "\n",
        "  def get_speaker_number(self):\n",
        "    return self.speaker_num"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_dir = parse_args()[\"data_dir\"]\n",
        "#part 1-1\n",
        "#mapping.json checcking\n",
        "#mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "#mapping = json.load(mapping_path.open())\n",
        "#speaker2id = mapping[\"speaker2id\"]\n",
        "#print(type(mapping)) #<class 'dict'>\n",
        "#print(mapping.keys()) #dict_keys(['speaker2id', 'id2speaker'])\n",
        "#print(mapping.values()) #dict_values([{'id10001': 0, 'id10005': 1, ...... 'id11247': 598, 'id11251': 599},\n",
        "             #{\"0\": \"id10001\", ......'599':  'id11251'}])\n",
        "#print(mapping['speaker2id']['id10473']) #217\n",
        "\n",
        "#part 1-2\n",
        "#metadata.json checcking\n",
        "#metadata_path = Path(data_dir) / \"metadata.json\"\n",
        "#metadata = json.load(open(metadata_path))[\"speakers\"]\n",
        "#print(type(metadata)) #<class 'dict'>\n",
        "#print(len(metadata.keys()),metadata.keys()) #600 dict_keys(['id10473', 'id10328', 'id10382',......'id10864'])\n",
        "#print(len(metadata.values()),len(list(metadata.values())[0]),list(metadata.values())[0])\n",
        "#600 176 [{'feature_path': 'uttr-5c88b2f1803449789c36f14fb4d3c1eb.pt', 'mel_len': 652},......\n",
        "#{'feature_path': 'uttr-caf385f0032140e0add0bbde9a6595cd.pt', 'mel_len': 414}]\n",
        "#print(len(metadata.values()),len(list(metadata.values())[1])) #600 101\n",
        "\n",
        "#part 2\n",
        "#mel = torch.load(os.path.join(data_dir, 'uttr-5c88b2f1803449789c36f14fb4d3c1eb.pt'))\n",
        "#print(type(mel)) #<class 'torch.Tensor'>\n",
        "#print(mel.size()) #torch.Size([652, 40])\n",
        "#print(mel[0])\n",
        "# tensor([\n",
        "# 2.0060,  1.9015,  1.3473,  1.5711,  1.5569,  2.3200,  3.0064,  3.3848,\n",
        "# 0.5376,  0.8397,  1.5710, -0.5662, -2.1262, -1.1271, -1.4272, -3.6233,\n",
        "# -1.0765, -1.8453, -3.2415, -2.3427, -1.5888, -0.4692, -0.4291, -0.4722,\n",
        "# -1.8450, -1.0638, -3.2177, -3.4006, -3.2176, -3.3409, -3.1142, -4.0395,\n",
        "# -3.6502, -4.2407, -4.9656, -5.1238, -5.0620, -5.4308, -6.0757, -6.6186])"
      ],
      "metadata": {
        "id": "qNWZbKmRrZUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "#part 1 check collate_batch\n",
        "def collate_batch(batch):\n",
        "  # Process features within a batch.\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  #part 1-1 , 1-2\n",
        "  mel, speaker = zip(*batch)\n",
        "  # Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
        "  mel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n",
        "  # mel: (batch size, length, 40)\n",
        "  #part 1-3\n",
        "  return mel, torch.FloatTensor(speaker).long()\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size, n_workers):\n",
        "  \"\"\"Generate dataloader\"\"\"\n",
        "  dataset = myDataset(data_dir)\n",
        "  speaker_num = dataset.get_speaker_number()\n",
        "  # Split dataset into training dataset and validation dataset\n",
        "  trainlen = int(0.9 * len(dataset))\n",
        "  lengths = [trainlen, len(dataset) - trainlen]\n",
        "  trainset, validset = random_split(dataset, lengths)\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=n_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "  valid_loader = DataLoader(\n",
        "    validset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=n_workers,\n",
        "    drop_last=True,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch,\n",
        "  )\n",
        "\n",
        "  return train_loader, valid_loader, speaker_num"
      ],
      "metadata": {
        "id": "MNfZK8vyq0rD"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = [[\"a\",1],[\"b\",2],[\"c\",3]]\n",
        "# print(list(zip(*x)))\n",
        "# print(list(zip((\"a\",1),(\"b\",2),(\"c\",3))))"
      ],
      "metadata": {
        "id": "75rCGxDvkX0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "#check collate_batch\n",
        "#part 1-1\n",
        "# * collect \"sequence\"function input to a tuple :\n",
        "#def f(*paras):\n",
        "#  print(paras)\n",
        "#f(1,2,3) #(1, 2, 3)\n",
        "# or collect a tuple to a \"sequence\"\n",
        "#print(*(1,2,3)) #1 2 3\n",
        "\n",
        "#part 1-2\n",
        "#test_data = np.random.rand(2,3,4)\n",
        "#test_label = np.random.rand(2,1)\n",
        "#samples = (test_data,test_label)\n",
        "#print(samples)\n",
        "#x , y = zip((1,2),(3,4),(5,6),(7,8))\n",
        "#print(x,y)\n",
        "\n",
        "#part 1-3\n",
        "#print(torch.FloatTensor([[1.],[1.]]))#tensor([[1.],[1.]])\n",
        "#print(torch.FloatTensor([[1.],[1.]]).long())#tensor([[1],[1]]) implies the numbers are integer now\n",
        "#print(torch.IntTensor([[1.],[1.]]))#tensor([[1],[1]], dtype=torch.int32)"
      ],
      "metadata": {
        "id": "vA6cTPqryJXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "3Yk6oGGdQD9G",
        "outputId": "fe89c7d4-a390-41df-a93e-feeb8df473a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = [True,True,False,True,False,False,False,True,False,True,True,False]\n",
        "\n",
        "# true_index_list = []\n",
        "\n",
        "# false_index_list = []\n",
        "\n",
        "# for i,b in enumerate(x):\n",
        "#   if b == True:\n",
        "#     true_index_list += [i]\n",
        "#   else :\n",
        "#     false_index_list += [i]\n",
        "# print(true_index_list,false_index_list)\n",
        "\n",
        "# new_list = []\n",
        "# t_max = len(true_index_list)\n",
        "# f_max = len(false_index_list)\n",
        "# true_index = 0\n",
        "# false_index = 0\n",
        "# t_or_f = 0\n",
        "# while (t_max * f_max)>0:\n",
        "#   if t_or_f % 2 ==0:\n",
        "#     new_list += true_index_list[true_index:true_index+3]\n",
        "#     true_index += 3\n",
        "#     t_or_f += 1\n",
        "#     t_max -= 3\n",
        "#   else :\n",
        "#     new_list += false_index_list[false_index:false_index+3]\n",
        "#     false_index += 3\n",
        "#     t_or_f += 1\n",
        "#     f_max -= 3\n",
        "# if t_max > 0:\n",
        "#   new_list += true_index_list[true_index:]\n",
        "# elif f_max > 0:\n",
        "#   new_list += false_index_list[false_index:]\n",
        "\n",
        "# print(new_list)\n"
      ],
      "metadata": {
        "id": "aBXbvqTlTSyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchinfo import summary\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, d_model=128, n_spks=600, dropout=0.1):\n",
        "    super().__init__()\n",
        "    # Project the dimension of features from that of input into d_model.\n",
        "    self.prenet = nn.Linear(40, d_model)\n",
        "    # TODO:\n",
        "    #   Change Transformer to Conformer.\n",
        "    #   https://arxiv.org/abs/2005.08100\n",
        "    # embed_dim must be divisible by num_heads\n",
        "    self.encoder_layer = nn.TransformerEncoderLayer(\n",
        "      d_model=d_model, dim_feedforward=256, nhead=1\n",
        "    )\n",
        "    # batch_first = True\n",
        "    # norm_first = True\n",
        "    self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "\n",
        "    # Project the the dimension of features from d_model into speaker nums.\n",
        "    self.pred_layer = nn.Sequential(\n",
        "      nn.Linear(d_model, d_model),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(d_model, n_spks),\n",
        "    )\n",
        "\n",
        "  def forward(self, mels):\n",
        "    \"\"\"\n",
        "    args:\n",
        "      mels: (batch size, length, 40)\n",
        "    return:\n",
        "      out: (batch size, n_spks)\n",
        "    \"\"\"\n",
        "    # out: (batch size, length, d_model)\n",
        "    out = self.prenet(mels)\n",
        "    # out: (length, batch size, d_model)\n",
        "    out = out.permute(1, 0, 2)\n",
        "    # The encoder layer expect features in the shape of (length, batch size, d_model).\n",
        "    #out = self.encoder_layer(out)\n",
        "    out = self.encoder(out)\n",
        "    # out: (batch size, length, d_model)\n",
        "    out = out.transpose(0, 1)\n",
        "    # mean pooling\n",
        "    stats = out.mean(dim=1)\n",
        "\n",
        "    # out: (batch, n_spks)\n",
        "    out = self.pred_layer(stats)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "zlXaMSlWMU__"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier()\n",
        "print(summary(model,(32,128,40)))\n",
        "#print(model.state_dict().keys())\n",
        "#print(model.state_dict()[\"encoder_layer.self_attn.in_proj_weight\"].size())#torch.Size([240, 80]) (80+80+80)*80\n",
        "#print(model.state_dict()[\"encoder_layer.self_attn.out_proj.weight\"].size())#torch.Size([80, 80])"
      ],
      "metadata": {
        "id": "vXLlPNAI9N9F",
        "outputId": "eb63690f-dcf8-4858-f690-99ac3a0e7a56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "Classifier                               [32, 600]                 529,920\n",
            "├─Linear: 1-1                            [32, 128, 128]            5,248\n",
            "├─TransformerEncoderLayer: 1-2           [128, 32, 128]            --\n",
            "│    └─MultiheadAttention: 2-1           [128, 32, 128]            66,048\n",
            "│    └─Dropout: 2-2                      [128, 32, 128]            --\n",
            "│    └─LayerNorm: 2-3                    [128, 32, 128]            256\n",
            "│    └─Linear: 2-4                       [128, 32, 256]            33,024\n",
            "│    └─Dropout: 2-5                      [128, 32, 256]            --\n",
            "│    └─Linear: 2-6                       [128, 32, 128]            32,896\n",
            "│    └─Dropout: 2-7                      [128, 32, 128]            --\n",
            "│    └─LayerNorm: 2-8                    [128, 32, 128]            256\n",
            "├─Sequential: 1-3                        [32, 600]                 --\n",
            "│    └─Linear: 2-9                       [32, 128]                 16,512\n",
            "│    └─ReLU: 2-10                        [32, 128]                 --\n",
            "│    └─Linear: 2-11                      [32, 600]                 77,400\n",
            "==========================================================================================\n",
            "Total params: 761,560\n",
            "Trainable params: 761,560\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 11.68\n",
            "==========================================================================================\n",
            "Input size (MB): 0.66\n",
            "Forward/backward pass size (MB): 25.35\n",
            "Params size (MB): 0.66\n",
            "Estimated Total Size (MB): 26.67\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "original\n",
        "parameter number :\n",
        "1.MultiheadAttention : =\n",
        "d_model+1(bias) * d_query +\n",
        "d_model+1(bias) * d_key  +\n",
        "d_model+1(bias) * d_v   +\n",
        "d_v + 1(bias) * output_dim( = dmodel)\n",
        "= (80+1)80 + (80+1)80 + (80+1)80 + (80+1)80 = 25920\n",
        "2.layer_norm : =input + input = 80*80 = 160\n",
        "\n",
        "first change\n",
        "parameter number :\n",
        "1.MultiheadAttention : =\n",
        "d_model+1(bias) * d_query +\n",
        "d_model+1(bias) * d_key  +\n",
        "d_model+1(bias) * d_v   +\n",
        "d_v + 1(bias) * output_dim( = dmodel)\n",
        "= (128+1)128(3+1)= 16512\n",
        "\n",
        "second change\n",
        "parameter number :\n",
        "1.MultiheadAttention : =\n",
        "d_model+1(bias) * d_query +\n",
        "d_model+1(bias) * d_key  +\n",
        "d_model+1(bias) * d_v   +\n",
        "d_v + 1(bias) * output_dim( = dmodel)\n",
        "= (128+1)128(3+1)= 16512\n",
        "two layers : 33024\n",
        "\n",
        "2.layer_norm : =input + input = 80*80 = 160\n",
        "\n",
        "3rd change\n",
        "parameter number :\n",
        "1.MultiheadAttention : =\n",
        "d_model+1(bias) * d_query +\n",
        "d_model+1(bias) * d_key  +\n",
        "d_model+1(bias) * d_v   +\n",
        "d_v + 1(bias) * output_dim( = dmodel)\n",
        "= (128+1)128(3+1)= 16512\n",
        "four layers : 66048\n",
        "\n",
        "2.layer_norm : =input + input = 80*80 = 160\n"
      ],
      "metadata": {
        "id": "5EhBDpSpznKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "  optimizer: Optimizer,\n",
        "  num_warmup_steps: int,\n",
        "  num_training_steps: int,\n",
        "  num_cycles: float = 0.5,\n",
        "  last_epoch: int = -1,\n",
        "):\n",
        "  \"\"\"\n",
        "  Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "  initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "  initial lr set in the optimizer.\n",
        "\n",
        "  Args:\n",
        "    optimizer (:class:`~torch.optim.Optimizer`):\n",
        "      The optimizer for which to schedule the learning rate.\n",
        "    num_warmup_steps (:obj:`int`):\n",
        "      The number of steps for the warmup phase.\n",
        "    num_training_steps (:obj:`int`):\n",
        "      The total number of training steps.\n",
        "    num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "      The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "      following a half-cosine).\n",
        "    last_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "      The index of the last epoch when resuming training.\n",
        "\n",
        "  Return:\n",
        "    :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "  \"\"\"\n",
        "\n",
        "  def lr_lambda(current_step):\n",
        "    # Warmup\n",
        "    if current_step < num_warmup_steps:\n",
        "      return float(current_step) / float(max(1, num_warmup_steps))\n",
        "    # decadence\n",
        "    # cosine angle\n",
        "    progress = float(current_step - num_warmup_steps) / float(\n",
        "      max(1, num_training_steps - num_warmup_steps)\n",
        "    )\n",
        "    return max(\n",
        "      0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "    )\n",
        "\n",
        "  return LambdaLR(optimizer, lr_lambda, last_epoch)"
      ],
      "metadata": {
        "id": "tUSxoANBMchs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, 1000, 70000)\n",
        "\n",
        "#print(type(scheduler.optimizer.param_groups)) #<class 'list'>\n",
        "#print(len(scheduler.optimizer.param_groups))  #1\n",
        "#print(type(scheduler.optimizer.param_groups[0])) #<class 'dict'>\n",
        "#print(scheduler.optimizer.param_groups[0].keys())\n",
        "#['params', 'lr', 'betas', 'eps', 'weight_decay', 'amsgrad', 'foreach',\n",
        "#'maximize', 'capturable', 'differentiable', 'fused', 'initial_lr']\n",
        "#print(scheduler.optimizer.param_groups[0]['params'])\n",
        "#[Parameter containing: tensor([[......],requires_grad=True)]\n",
        "#print(scheduler.optimizer.param_groups[0]['lr'])# 0.0\n",
        "#print(scheduler.optimizer.param_groups[0]['betas'])# (0.9, 0.999)\n",
        "#print(scheduler.optimizer.param_groups[0]['eps']) # 1e-08\n",
        "#print(scheduler.optimizer.param_groups[0]['weight_decay']) #0.01\n",
        "#print(scheduler.optimizer.param_groups[0]['amsgrad']) # False\n",
        "#print(scheduler.optimizer.param_groups[0]['foreach']) # None"
      ],
      "metadata": {
        "id": "9o3hw_GcF1Jb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "  \"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "  mels, labels = batch\n",
        "  mels = mels.to(device)\n",
        "  labels = labels.to(device)\n",
        "\n",
        "  outs = model(mels)\n",
        "\n",
        "  loss = criterion(outs, labels)\n",
        "\n",
        "  # Get the speaker id with highest probability.\n",
        "  preds = outs.argmax(1)\n",
        "  # Compute accuracy.\n",
        "  accuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "  return loss, accuracy"
      ],
      "metadata": {
        "id": "yfDXw13q1ssm"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "def valid(dataloader, model, criterion, device):\n",
        "  \"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "  # Manually update the progress bar : step 1\n",
        "  # total length\n",
        "  pbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
        "  for i, batch in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "      loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "      running_loss += loss.item()\n",
        "      running_accuracy += accuracy.item()\n",
        "    # Manually update the progress bar : step 2\n",
        "    # update each batch\n",
        "    pbar.update(dataloader.batch_size)\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{running_loss / (i+1):.2f}\",\n",
        "      accuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "    )\n",
        "  # Manually update the progress bar : step 3\n",
        "  pbar.close()\n",
        "  model.train()\n",
        "\n",
        "  return running_accuracy / len(dataloader)\n"
      ],
      "metadata": {
        "id": "959wMzs21wbz"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "# def parse_args():\n",
        "#   \"\"\"arguments\"\"\"\n",
        "#   config = {\n",
        "#     \"data_dir\": \"/content/Dataset\",\n",
        "#     \"save_path\": \"model.ckpt\",\n",
        "#     \"batch_size\": 32,\n",
        "#     \"n_workers\": 8,\n",
        "#     \"valid_steps\": 2000,\n",
        "#     \"warmup_steps\": 1000,\n",
        "#     \"save_steps\": 10000,\n",
        "#     \"total_steps\": 70000,\n",
        "#   }\n",
        "\n",
        "#   return config\n",
        "\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  save_path,\n",
        "  batch_size,\n",
        "  n_workers,\n",
        "  valid_steps,\n",
        "  warmup_steps,\n",
        "  total_steps,\n",
        "  save_steps,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "  train_iterator = iter(train_loader)\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "  scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  best_accuracy = -1.0\n",
        "  best_state_dict = None\n",
        "  # pbar has total 2000 step\n",
        "  pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "  # print train loss and accuracy every 1000 step\n",
        "\n",
        "  loss_acc_list = []\n",
        "\n",
        "  for step in range(total_steps):\n",
        "    # Get data\n",
        "    try:\n",
        "      batch = next(train_iterator)\n",
        "    except StopIteration:\n",
        "      train_iterator = iter(train_loader)\n",
        "      batch = next(train_iterator)\n",
        "\n",
        "    loss, accuracy = model_fn(batch, model, criterion, device)\n",
        "    batch_loss = loss.item()\n",
        "    batch_accuracy = accuracy.item()\n",
        "\n",
        "    # Updata model\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "    # print train loss acc\n",
        "    loss_acc_list.append((loss, accuracy))\n",
        "    print_loss , print_acc = list(zip(*loss_acc_list))\n",
        "    if step % 1000 == 0:\n",
        "      print(f\"average loss = {sum(print_loss)/len(print_loss):.4f} \\\n",
        "      average accuracy = {sum(print_acc)/len(print_acc):.4f})\")\n",
        "      loss_acc_list = []\n",
        "\n",
        "    # Log\n",
        "    # update each step (as total)\n",
        "    pbar.update()\n",
        "    pbar.set_postfix(\n",
        "      loss=f\"{batch_loss:.2f}\",\n",
        "      accuracy=f\"{batch_accuracy:.2f}\",\n",
        "      step=step + 1,\n",
        "    )\n",
        "\n",
        "    # Do validation\n",
        "    # valid each 2000 step\n",
        "    if (step + 1) % valid_steps == 0:\n",
        "      #close above pbar\n",
        "      pbar.close()\n",
        "\n",
        "      valid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "\n",
        "      # keep the best model\n",
        "      if valid_accuracy > best_accuracy:\n",
        "        best_accuracy = valid_accuracy\n",
        "        best_state_dict = model.state_dict()\n",
        "      # new pbar has total 2000 step\n",
        "      pbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "    # Save the best model so far.\n",
        "    if (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "      torch.save(best_state_dict, save_path)\n",
        "      pbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "  pbar.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())"
      ],
      "metadata": {
        "id": "m7ckdrpl6_YW",
        "outputId": "162897de-c061-4b64-9457-98843c0430d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info]: Use cuda now!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Train:   0% 5/2000 [00:00<04:37,  7.18 step/s, accuracy=0.00, loss=6.40, step=5]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 6.3969       average accuracy = 0.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1003/2000 [00:51<01:13, 13.59 step/s, accuracy=0.00, loss=4.58, step=1003]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 5.5162       average accuracy = 0.0504)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:54<00:00, 17.47 step/s, accuracy=0.19, loss=3.76, step=2000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 478.83 uttr/s, accuracy=0.22, loss=3.74]\n",
            "Train:   0% 1/2000 [00:00<02:54, 11.49 step/s, accuracy=0.12, loss=3.51, step=2001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 4.0222       average accuracy = 0.1832)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [00:56<01:00, 16.55 step/s, accuracy=0.31, loss=3.45, step=3001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 3.3836       average accuracy = 0.2764)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:57<00:00, 17.01 step/s, accuracy=0.41, loss=2.95, step=4000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 484.83 uttr/s, accuracy=0.32, loss=3.12]\n",
            "Train:   0% 1/2000 [00:00<03:35,  9.30 step/s, accuracy=0.38, loss=2.67, step=4001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 3.0726       average accuracy = 0.3255)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [00:53<01:10, 14.24 step/s, accuracy=0.34, loss=2.90, step=5001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.8353       average accuracy = 0.3650)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:51<00:00, 17.95 step/s, accuracy=0.44, loss=2.74, step=6000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 511.57 uttr/s, accuracy=0.41, loss=2.64]\n",
            "Train:   0% 2/2000 [00:00<04:44,  7.03 step/s, accuracy=0.44, loss=2.79, step=6001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.6738       average accuracy = 0.3959)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [00:53<01:06, 15.02 step/s, accuracy=0.28, loss=3.12, step=7004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.4979       average accuracy = 0.4301)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.14 step/s, accuracy=0.41, loss=2.28, step=8000]\n",
            "Valid: 100% 6944/6944 [00:13<00:00, 503.74 uttr/s, accuracy=0.45, loss=2.49]\n",
            "Train:   0% 4/2000 [00:00<03:24,  9.74 step/s, accuracy=0.41, loss=2.14, step=8004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.3930       average accuracy = 0.4523)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1003/2000 [00:54<01:18, 12.75 step/s, accuracy=0.38, loss=2.70, step=9003]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.2727       average accuracy = 0.4729)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.04 step/s, accuracy=0.41, loss=2.14, step=1e+4]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 492.07 uttr/s, accuracy=0.47, loss=2.34]\n",
            "\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n",
            "Train:   0% 1/2000 [00:00<05:51,  5.69 step/s, accuracy=0.59, loss=2.27, step=1e+4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10000, best model saved. (accuracy=0.4715)\n",
            "average loss = 2.2022       average accuracy = 0.4851)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [00:55<01:00, 16.42 step/s, accuracy=0.47, loss=2.45, step=11001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.0898       average accuracy = 0.5071)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:50<00:00, 18.17 step/s, accuracy=0.53, loss=1.89, step=12000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 464.89 uttr/s, accuracy=0.51, loss=2.15]\n",
            "Train:   0% 1/2000 [00:00<02:28, 13.42 step/s, accuracy=0.47, loss=2.09, step=12001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 2.0656       average accuracy = 0.5147)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [00:59<01:17, 12.91 step/s, accuracy=0.62, loss=1.46, step=13004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.9458       average accuracy = 0.5352)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:56<00:00, 17.10 step/s, accuracy=0.56, loss=2.11, step=14000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 453.04 uttr/s, accuracy=0.53, loss=2.07]\n",
            "Train:   0% 2/2000 [00:00<04:33,  7.32 step/s, accuracy=0.50, loss=1.81, step=14002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.9438       average accuracy = 0.5396)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1005/2000 [01:04<01:13, 13.48 step/s, accuracy=0.44, loss=1.95, step=15005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.8389       average accuracy = 0.5590)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.47 step/s, accuracy=0.59, loss=1.46, step=16000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 480.43 uttr/s, accuracy=0.55, loss=1.97]\n",
            "Train:   0% 5/2000 [00:00<02:51, 11.62 step/s, accuracy=0.44, loss=1.85, step=16005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.8114       average accuracy = 0.5632)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1005/2000 [01:00<01:06, 14.95 step/s, accuracy=0.72, loss=1.32, step=17005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.7493       average accuracy = 0.5772)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:51<00:00, 17.98 step/s, accuracy=0.44, loss=2.17, step=18000]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 472.51 uttr/s, accuracy=0.56, loss=1.90]\n",
            "Train:   0% 2/2000 [00:00<03:56,  8.44 step/s, accuracy=0.59, loss=1.59, step=18002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.6928       average accuracy = 0.5908)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1002/2000 [01:01<01:14, 13.41 step/s, accuracy=0.62, loss=1.76, step=19002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.6556       average accuracy = 0.5973)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:55<00:00, 17.30 step/s, accuracy=0.59, loss=1.85, step=2e+4]\n",
            "Valid: 100% 6944/6944 [00:14<00:00, 474.23 uttr/s, accuracy=0.58, loss=1.82]\n",
            "\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n",
            "Train:   0% 1/2000 [00:00<04:44,  7.04 step/s, accuracy=0.66, loss=1.23, step=2e+4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20000, best model saved. (accuracy=0.5772)\n",
            "average loss = 1.6182       average accuracy = 0.6057)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1003/2000 [01:07<01:26, 11.52 step/s, accuracy=0.56, loss=1.88, step=21003]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.5722       average accuracy = 0.6189)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [02:01<00:00, 16.41 step/s, accuracy=0.66, loss=1.66, step=22000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 444.67 uttr/s, accuracy=0.59, loss=1.80]\n",
            "Train:   0% 5/2000 [00:00<03:13, 10.31 step/s, accuracy=0.53, loss=1.92, step=22005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.5243       average accuracy = 0.6291)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [01:04<01:12, 13.82 step/s, accuracy=0.69, loss=1.68, step=23001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.4949       average accuracy = 0.6326)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:58<00:00, 16.89 step/s, accuracy=0.56, loss=1.94, step=24000]\n",
            "Valid: 100% 6944/6944 [00:16<00:00, 431.95 uttr/s, accuracy=0.61, loss=1.70]\n",
            "Train:   0% 5/2000 [00:00<03:08, 10.60 step/s, accuracy=0.62, loss=1.68, step=24005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.4284       average accuracy = 0.6473)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1002/2000 [01:03<01:23, 11.93 step/s, accuracy=0.69, loss=1.06, step=25002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.4474       average accuracy = 0.6433)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:57<00:00, 17.04 step/s, accuracy=0.69, loss=1.12, step=26000]\n",
            "Valid: 100% 6944/6944 [00:17<00:00, 395.46 uttr/s, accuracy=0.63, loss=1.63]\n",
            "Train:   0% 6/2000 [00:00<03:06, 10.70 step/s, accuracy=0.59, loss=1.94, step=26006]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.3741       average accuracy = 0.6598)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [01:07<00:50, 19.96 step/s, accuracy=0.69, loss=1.52, step=27001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.3686       average accuracy = 0.6595)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [02:02<00:00, 16.27 step/s, accuracy=0.81, loss=0.80, step=28000]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 435.71 uttr/s, accuracy=0.64, loss=1.59]\n",
            "Train:   0% 2/2000 [00:00<03:51,  8.63 step/s, accuracy=0.56, loss=1.16, step=28002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.3087       average accuracy = 0.6759)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [01:05<01:05, 15.30 step/s, accuracy=0.66, loss=1.19, step=29004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.3021       average accuracy = 0.6762)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:55<00:00, 17.29 step/s, accuracy=0.69, loss=1.07, step=3e+4]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 442.58 uttr/s, accuracy=0.64, loss=1.55]\n",
            "\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n",
            "Train:   0% 1/2000 [00:00<05:56,  5.60 step/s, accuracy=0.81, loss=0.77, step=3e+4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 30000, best model saved. (accuracy=0.6420)\n",
            "average loss = 1.2462       average accuracy = 0.6882)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [01:07<01:08, 14.48 step/s, accuracy=0.72, loss=1.50, step=31004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.2418       average accuracy = 0.6903)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [02:04<00:00, 16.01 step/s, accuracy=0.72, loss=1.18, step=32000]\n",
            "Valid: 100% 6944/6944 [00:17<00:00, 398.53 uttr/s, accuracy=0.64, loss=1.56]\n",
            "Train:   0% 2/2000 [00:00<03:41,  9.02 step/s, accuracy=0.78, loss=1.27, step=32002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.1880       average accuracy = 0.7006)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1007/2000 [01:09<01:17, 12.79 step/s, accuracy=0.59, loss=1.66, step=33007]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.1789       average accuracy = 0.7042)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [02:02<00:00, 16.29 step/s, accuracy=0.78, loss=0.74, step=34000]\n",
            "Valid: 100% 6944/6944 [00:16<00:00, 408.91 uttr/s, accuracy=0.67, loss=1.44]\n",
            "Train:   0% 3/2000 [00:00<02:55, 11.37 step/s, accuracy=0.78, loss=0.87, step=34003]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.1394       average accuracy = 0.7132)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1005/2000 [01:05<01:04, 15.54 step/s, accuracy=0.62, loss=1.77, step=35005]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.1277       average accuracy = 0.7172)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:57<00:00, 17.02 step/s, accuracy=0.59, loss=1.42, step=36000]\n",
            "Valid: 100% 6944/6944 [00:16<00:00, 433.24 uttr/s, accuracy=0.68, loss=1.38]\n",
            "Train:   0% 4/2000 [00:00<03:50,  8.67 step/s, accuracy=0.69, loss=1.29, step=36004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.0850       average accuracy = 0.7288)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [01:06<01:11, 14.01 step/s, accuracy=0.69, loss=0.94, step=37004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.0858       average accuracy = 0.7280)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:56<00:00, 17.15 step/s, accuracy=0.75, loss=1.16, step=38000]\n",
            "Valid: 100% 6944/6944 [00:16<00:00, 431.24 uttr/s, accuracy=0.69, loss=1.37]\n",
            "Train:   0% 3/2000 [00:00<03:57,  8.41 step/s, accuracy=0.81, loss=0.69, step=38003]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.0307       average accuracy = 0.7377)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1001/2000 [01:03<01:16, 13.12 step/s, accuracy=0.53, loss=1.55, step=39001]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 1.0448       average accuracy = 0.7350)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:54<00:00, 17.54 step/s, accuracy=0.75, loss=0.96, step=4e+4]\n",
            "Valid: 100% 6944/6944 [00:15<00:00, 439.01 uttr/s, accuracy=0.70, loss=1.31]\n",
            "\n",
            "Train:   0% 0/2000 [00:00<?, ? step/s]\n",
            "Train:   0% 1/2000 [00:00<05:42,  5.84 step/s, accuracy=0.78, loss=0.82, step=4e+4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 40000, best model saved. (accuracy=0.7039)\n",
            "average loss = 0.9587       average accuracy = 0.7532)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  50% 1004/2000 [01:05<01:41,  9.86 step/s, accuracy=0.84, loss=0.64, step=41004]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss = 0.9990       average accuracy = 0.7493)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100% 2000/2000 [01:52<00:00, 17.71 step/s, accuracy=0.72, loss=0.95, step=42000]\n",
            "Valid:  45% 3104/6944 [00:07<00:07, 531.03 uttr/s, accuracy=0.70, loss=1.31]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######original : val acc = 68%\n",
        "######d_model 80->128 , multihead 2->1\n",
        "###### train acc = 80% , val acc = 73%\n",
        "\n",
        "######TransformerEncoder layer : 1 -> 2 :"
      ],
      "metadata": {
        "id": "0ZnUtE246AXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "  def __init__(self, data_dir):\n",
        "    # using / to merge path\n",
        "    testdata_path = Path(data_dir) / \"testdata.json\"\n",
        "    metadata = json.load(testdata_path.open())\n",
        "    self.data_dir = data_dir\n",
        "    #\n",
        "    self.data = metadata[\"utterances\"]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    utterance = self.data[index]\n",
        "    feat_path = utterance[\"feature_path\"]\n",
        "    mel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "    # compare : when we load training set, we use append to concate datas\n",
        "    return feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "  \"\"\"Collate a batch of data.\"\"\"\n",
        "  feat_paths, mels = zip(*batch)\n",
        "\n",
        "  return feat_paths, torch.stack(mels)"
      ],
      "metadata": {
        "id": "ED3v3VUxUHDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "  \"\"\"arguments\"\"\"\n",
        "  config = {\n",
        "    \"data_dir\": \"./Dataset\",\n",
        "    \"model_path\": \"./model.ckpt\",\n",
        "    \"output_path\": \"./output.csv\",\n",
        "  }\n",
        "\n",
        "  return config\n",
        "\n",
        "\n",
        "def main(\n",
        "  data_dir,\n",
        "  model_path,\n",
        "  output_path,\n",
        "):\n",
        "  \"\"\"Main function.\"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "  mapping_path = Path(data_dir) / \"mapping.json\"\n",
        "  mapping = json.load(mapping_path.open())\n",
        "\n",
        "  dataset = InferenceDataset(data_dir)\n",
        "  dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        "    collate_fn=inference_collate_batch,\n",
        "  )\n",
        "  print(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "  speaker_num = len(mapping[\"id2speaker\"])\n",
        "  model = Classifier(n_spks=speaker_num).to(device)\n",
        "  model.load_state_dict(torch.load(model_path))\n",
        "  model.eval()\n",
        "  print(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "  results = [[\"Id\", \"Category\"]]\n",
        "  for feat_paths, mels in tqdm(dataloader):\n",
        "    with torch.no_grad():\n",
        "      mels = mels.to(device)\n",
        "      outs = model(mels)\n",
        "      preds = outs.argmax(1).cpu().numpy()\n",
        "      # zip from two list to a sequence of tuples\n",
        "      # preds is a numpy array whose elements are int numbers\n",
        "      for feat_path, pred in zip(feat_paths, preds):\n",
        "        # mapping[\"id2speaker\"] = {\"0\": \"id10001\", ......'599':  'id11251'}])\n",
        "        results.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "\n",
        "  with open(output_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(**parse_args())\n"
      ],
      "metadata": {
        "id": "WGfTSJDtUYPB",
        "outputId": "56ab7d4a-a324-4bb0-c201-1cd4c043edfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "79aa8f0935d243baafdcec9f8932450f",
            "9497e561bb944165b4ed43c2a9cfa458",
            "b3db996193f345c9be0866a7db385c88",
            "1ad97658267f44b38dbc1ddae5c2ff27",
            "80d2e5d7ec80460abb1106fca1841a4f",
            "0f9936d3fed14a47bf4c8f7d0f42db4c",
            "2ac8e17deb7640d190c899e2f2105deb",
            "258088fb0946452ca9a78e95eab628bd",
            "581e8a1272ac481989f463d1ee900cb0",
            "e8138daa92bf48268e92d995b458d884",
            "fc1066343ffd4d6e8c8cb924672fc8df"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info]: Use cuda now!\n",
            "[Info]: Finish loading data!\n",
            "[Info]: Finish creating model!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79aa8f0935d243baafdcec9f8932450f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinearLayer(nn.Module):\n",
        "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
        "    def __init__(self, size_in, size_out):\n",
        "        super().__init__()\n",
        "        self.size_in, self.size_out = size_in, size_out\n",
        "        weights = torch.Tensor(size_out, size_in)\n",
        "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
        "        bias = torch.Tensor(size_out)\n",
        "        self.bias = nn.Parameter(bias)\n",
        "\n",
        "        # initialize weights and biases\n",
        "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
        "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
        "        bound = 1 / math.sqrt(fan_in)\n",
        "        nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
        "\n",
        "    def forward(self, x):\n",
        "        w_times_x= torch.mm(x, self.weights.t())\n",
        "        return torch.add(w_times_x, self.bias)  # w times x + b\n",
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)\n",
        "class NoisyLinear(T.nn.Module):\n",
        "  def __init__(self, n_in, n_out):\n",
        "    super().__init__()\n",
        "    self.n_in, self.n_out = n_in, n_out\n",
        "\n",
        "    self.weights = T.nn.Parameter(T.zeros((n_out, n_in),\n",
        "      dtype=T.float32))\n",
        "    self.bias = T.nn.Parameter(T.tensor(n_out,\n",
        "      dtype=T.float32))\n",
        "    self.lo = 0.90; self.hi = 0.98  # noise\n",
        "\n",
        "    lim = 0.01  # initialize weights and bias\n",
        "    T.nn.init.uniform_(self.weights, -lim, +lim)\n",
        "    T.nn.init.uniform_(self.bias, -lim, +lim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    wx= T.mm(x, self.weights.t())\n",
        "    rnd = (self.hi - self.lo) * T.rand(1) + self.lo\n",
        "    return rnd * T.add(wx, self.bias)  # wts * x + bias\n",
        "class PrintLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintLayer, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Do your print / debug stuff here\n",
        "        print(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nuDMfXVo9mD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PermuteLayer(nn.Module):\n",
        "  def __init__(self, input, output):\n",
        "    super().__init__()\n",
        "  def forward(self , x):\n",
        "    return(x.permute(1,0))\n",
        "\n",
        "class SelfAttentionPollingLayer(nn.Module):\n",
        "  def __init__(self,d_ap):\n",
        "    super().__init__()\n",
        "    self.attention_layer =\n",
        "\n",
        "    nn.Sequential(\n",
        "        PermuteLayer(),\n",
        "        nn.Linear(input, d_ap),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(d_ap, 1 ),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "  def forward(self ,x ):\n",
        "    return torch.mm(x, self.attention_layer(x))"
      ],
      "metadata": {
        "id": "CxnOhUSa9wLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}