{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML_Project/blob/Shopping_vscode_branch/CNN_Classification/CNN_Classification_fruit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Data"
      ],
      "metadata": {
        "id": "I_7n-RiO2czn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDo4n9HGqTbH",
        "outputId": "2136f1ed-f0c4-4845-bd37-75fd025c91b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  megatools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 207 kB of archives.\n",
            "After this operation, 898 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 megatools amd64 1.10.3-1build1 [207 kB]\n",
            "Fetched 207 kB in 0s (1,304 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package megatools.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../megatools_1.10.3-1build1_amd64.deb ...\n",
            "Unpacking megatools (1.10.3-1build1) ...\n",
            "Setting up megatools (1.10.3-1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[0KDownloaded food-11.zip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install megatools\n",
        "!megadl \"https://mega.nz/#!zt1TTIhK!ZuMbg5ZjGWzWX1I6nEUbfjMZgCmAgeqJlwDkqdIryfg\"\n",
        "# Unzip the dataset.\n",
        "# This may take some time.\n",
        "!unzip -q /content/food-11.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare Dataset"
      ],
      "metadata": {
        "id": "kza4JCYB4DDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6RhmTvYcqTbL"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from torch.utils.data import ConcatDataset\n",
        "from PIL import Image\n",
        "def get_tfm(data_info):\n",
        "    tfm = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(data_info[\"size\"]),\n",
        "    ])\n",
        "    return tfm\n",
        "def get_tfm_flip(data_info):\n",
        "    tfm_flip = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(data_info[\"size\"]),\n",
        "    v2.RandomHorizontalFlip(p=1),\n",
        "    ])\n",
        "    return tfm_flip\n",
        "def food_f(mode,data_info):\n",
        "    dataset = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm(data_info))\n",
        "    if mode in [\"train_origin\"]:\n",
        "      dataset_flip = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm_flip(data_info))\n",
        "      dataset = ConcatDataset([dataset,dataset_flip])\n",
        "    print('Size of {} data: {}'.format(mode,len(list(dataset))))\n",
        "    return dataset\n",
        "\n",
        "# This part is for semi- supervised learning\n",
        "class Label_Changable_dsf(DatasetFolder):\n",
        "    def __init__(self,root,loader,extensions,transform):\n",
        "            super().__init__(root, loader, extensions , transform,)\n",
        "    def change_targets(self ,correct_target):\n",
        "      for i , t in enumerate(correct_target):\n",
        "        self.targets[i] = t\n",
        "\n",
        "def food_semi_f(mode,data_info,DatasetFolder):\n",
        "    dataset = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm(data_info))\n",
        "\n",
        "    print('Size of data for semi-supervised-learning: {}'.format(len(list(dataset))))\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x_uSxJ1bqTbO"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # The arguments for commonly used modules:\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "\n",
        "        # input image size: [3, 32, 32]\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(4, 4, 0),\n",
        "        )\n",
        "        self.flat_layer = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(int(256 * data_info[\"size\"][0]/16 * data_info[\"size\"][1]/16), 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, 11)\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "    def forward(self, x):\n",
        "        # input (x): [batch_size, 3, 128, 128]\n",
        "        # output: [batch_size, 11]\n",
        "\n",
        "        # Extract features by convolutional layers.\n",
        "        x = self.cnn_layers(x)\n",
        "\n",
        "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
        "        x = self.flat_layer(x)\n",
        "\n",
        "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "    def cal_loss(self, pred, target):\n",
        "        return self.criterion(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QOWwbIscgbm7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset , Subset\n",
        "def get_pseudo_labels(model, training_loader ,h_paras):\n",
        "\n",
        "    softmax = nn.Softmax(dim=-1)\n",
        "    model.eval()\n",
        "    # Construct a data loader.\n",
        "    semi_datasetfolder = food_semi_f(\"train\",data_info,Label_Changable_dsf)\n",
        "    semi_dataset_loader = \\\n",
        "    DataLoader(semi_datasetfolder, \\\n",
        "               batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "    correct_label = []\n",
        "    correct_index = []\n",
        "\n",
        "    for batch_num , batch in enumerate(tqdm(semi_dataset_loader)):\n",
        "        img = batch[0]\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img_d = img.to(device)\n",
        "            prep = model(img_d)\n",
        "        predicts = softmax(prep)\n",
        "        max_prob , max_column_index = predicts.max(dim = -1)\n",
        "\n",
        "        max_prob_list = max_prob.tolist()\n",
        "        max_column_index_list = max_column_index.tolist()\n",
        "        correct_label += [max_column_index_list[i]  \\\n",
        "                          for i in range(len(max_column_index_list)) if max_prob_list[i] > h_paras[\"threshold\"]]\n",
        "        correct_index += [(i + batch_num * h_paras[\"batch_size\"]) \\\n",
        "                          for i in range(len(max_column_index_list)) if max_prob_list[i] > h_paras[\"threshold\"]]\n",
        "\n",
        "    if len(correct_index)>0:\n",
        "      semi_datasetfolder.change_targets(correct_label)\n",
        "      add_train_set = Subset(semi_datasetfolder,correct_index)\n",
        "\n",
        "      new_train_set = ConcatDataset([food_f(\"train_origin\",data_info),add_train_set])\n",
        "      training_loader = DataLoader(new_train_set, batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "      #build a dic to print the number of label of each class added to add_train_set\n",
        "      label_dict = {}\n",
        "      label_set = set(correct_label)\n",
        "      for i in label_set:\n",
        "        label_dict[i] = correct_label.count(i)\n",
        "      print(\"add total {} datas to training dataset, each label numbers as follow {}\".format(len(correct_index),label_dict))\n",
        "\n",
        "    return training_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QgdT2JdtqTbP"
      },
      "outputs": [],
      "source": [
        "def train(train_loader,model_d,optimizer,device):\n",
        "    # set model to training mode\n",
        "    model_d.train()\n",
        "    total_correct_number = 0\n",
        "    train_loss_list = []\n",
        "#    print(type(train_loader))\n",
        "    # iterate through the dataloader\n",
        "    for data , label in tqdm(train_loader):\n",
        "      # move data to device (cpu/cuda)\n",
        "      data_d , label_d = data.to(device), label.to(device)\n",
        "      # forward pass (compute output tensor)\n",
        "      pred = (model_d(data_d))\n",
        "      # get the index of the class with the highest probability\n",
        "      max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "      correct_number = (max_prob_indexs.cpu() == label_d.cpu()).sum().item()\n",
        "#      print(correct_number)\n",
        "      total_correct_number += correct_number\n",
        "      # compute loss\n",
        "      loss = model_d.cal_loss(pred , label_d)\n",
        "      # compute gradient (backpropagation)\n",
        "      loss.backward()\n",
        "      # Clip the gradient norms for stable training.\n",
        "      nn.utils.clip_grad_norm_(model_d.parameters(), max_norm=10)\n",
        "      # update model with optimizer\n",
        "      optimizer.step()\n",
        "      # set optimizer gradient to zero\n",
        "      optimizer.zero_grad()\n",
        "      train_loss_list.append(loss.detach().cpu().item())\n",
        "    acc = total_correct_number/len(train_loader.dataset)\n",
        "#    print(acc , train_loss_list)\n",
        "    return acc , train_loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NEn8YBfVqTbP"
      },
      "outputs": [],
      "source": [
        "def val(val_loader,model_d,device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "    total_correct_number = 0\n",
        "    total_loss = 0\n",
        "    # iterate through the dataloader\n",
        "    for data , label in tqdm(val_loader):\n",
        "    # move data to device (cpu/cuda)\n",
        "      data_d, label_d = data.to(device), label.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = model_d(data_d)\n",
        "        # get the index of the class with the highest probability\n",
        "        max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "        total_correct_number += (max_prob_indexs.cpu() == label_d.cpu()).sum().item()\n",
        "        # compute loss\n",
        "        mse_loss = model_d.cal_loss(pred, label_d)\n",
        "      # accumulate loss\n",
        "      batch_size = len(data_d)\n",
        "      total_loss += mse_loss.detach().cpu().item() * batch_size\n",
        "\n",
        "    # compute averaged loss\n",
        "    totol_size = len(val_loader.dataset)\n",
        "    acc = total_correct_number/totol_size\n",
        "    avg_loss =  total_loss/totol_size\n",
        "    return acc, avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E5PRQVp6qTbP"
      },
      "outputs": [],
      "source": [
        "def train_val_process(training_loader, validation_loader, model, h_paras, device , do_semi = False):\n",
        "    # Initialize a model, and put it on the device specified.\n",
        "    model_d = model.to(device)\n",
        "    model_d.device = device\n",
        "    optimizer = torch.optim.Adam(model_d.parameters(), **h_paras[\"optim_hparas\"])\n",
        "\n",
        "    # The number of training epochs.\n",
        "    n_epochs = h_paras[\"n_epochs\"]\n",
        "\n",
        "    # record training accuracy\n",
        "    acc_record = {'train': [], \"val\": []}\n",
        "    # record training loss\n",
        "    loss_record = {'train': [], \"val\": []}\n",
        "\n",
        "    # accuracy paras\n",
        "    best_acc = 0\n",
        "    # early-stoping paras\n",
        "    early_stop_cnt = 0\n",
        "\n",
        "\n",
        "    #for semi-supervised learning\n",
        "    if do_semi == True:\n",
        "      data_origin = np.array([])\n",
        "      label_origin = np.array([])\n",
        "      for data , label in tqdm(training_loader):\n",
        "        if len(data_origin) ==0:\n",
        "          data_origin = data.numpy()\n",
        "          label_origin = np.array(label)\n",
        "        else:\n",
        "          data_origin = np.concatenate((data_origin, data.numpy()), axis=0)\n",
        "          label_origin = np.concatenate((label_origin, np.array(label)), axis=0)\n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # ---------- Training ----------\n",
        "        train_acc , train_loss_list = train(training_loader,model_d,optimizer,device)\n",
        "        # save accuracy to acc_record['train']\n",
        "        acc_record['train'].append(train_acc)\n",
        "      # save loss to loss_record['train']\n",
        "        loss_record['train'].append(train_loss_list)\n",
        "\n",
        "        # ---------- Do semi-supervised learning ----------\n",
        "        if ((do_semi == True) & (early_stop_cnt >= 1 )):\n",
        "\n",
        "          training_loader = get_pseudo_labels(model_d, training_loader , h_paras)\n",
        "\n",
        "\n",
        "        # ---------- Validation ----------\n",
        "        val_acc , val_loss = val(validation_loader,model_d,device)\n",
        "        # Print the information.\n",
        "        acc_record[\"val\"].append(val_acc)\n",
        "        # save loss to loss_record[\"val\"]\n",
        "        loss_record[\"val\"].append(val_loss)\n",
        "\n",
        "        print(' model epoch = {:4d}, train_loss = {:.4f} , val_loss = {:.4f})'\\\n",
        "        .format(epoch+1 , train_loss_list[-1] , val_loss))\n",
        "        print('train set accuracy = {:.3f}'.format(train_acc))\n",
        "\n",
        "        # ---------- Early Stop ----------\n",
        "        if val_acc > best_acc:\n",
        "          best_acc = val_acc\n",
        "          torch.save(model.state_dict(), h_paras[\"save_path\"])\n",
        "          print('saving model with acc {:.3f}'.format(best_acc))\n",
        "          early_stop_cnt = 0\n",
        "        else:\n",
        "          early_stop_cnt += 1\n",
        "        # Check early stop criteria\n",
        "        if early_stop_cnt > h_paras['early_stop']:\n",
        "            # Stop training if your model stops improving\n",
        "            # for \"h_paras['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    return acc_record , loss_record\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3r2xj_0FqTbQ"
      },
      "outputs": [],
      "source": [
        "def test(test_loader, model_d, device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "    pred_index = []\n",
        "    pred_loss = []\n",
        "    # iterate through the dataloader\n",
        "    for imgs, incorrect_labels in tqdm(test_loader):\n",
        "      # move data to device (cpu/cuda)\n",
        "      imgs_d = imgs.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = model_d(imgs_d)\n",
        "        # get the index of the class with the highest probability\n",
        "        max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "        # collect prediction\n",
        "        pred_index += (max_prob_indexs.tolist())\n",
        "        pred_loss += (pred.mean(dim = 1).tolist())\n",
        "    # concatenate all predictions and convert to a numpy array\n",
        "    np_pred_index , np_pred_loss = np.array(pred_index), np.array(pred_loss)\n",
        "    pred_dict = { \"pred_index\" : np_pred_index , \"pred_loss\" : np_pred_loss }\n",
        "    return pred_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P50yBDcnqTbQ"
      },
      "outputs": [],
      "source": [
        "def save_pred(preds, file_path):\n",
        "    import pandas as pd\n",
        "    print('Saving results to {}'.format(file_path))\n",
        "    df = pd.DataFrame(preds,columns=[\"tested_positive\"])\n",
        "    df.to_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Visualization"
      ],
      "metadata": {
        "id": "QfU7yI5Z1x2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kWsS_dCRT5Fl"
      },
      "outputs": [],
      "source": [
        "#%conda install -c conda-forge matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "def plot_learning_curve_loss(loss_record, title=''):\n",
        "\n",
        "    #plot1 : train loss\n",
        "    #plot2 : val loss\n",
        "    train_data = []\n",
        "    t = np.array(loss_record['train'])\n",
        "    for i in t:\n",
        "      train_data.append(statistics.mean(i))\n",
        "    val_data = np.array(loss_record['val'])\n",
        "\n",
        "    #setting index range\n",
        "    total_steps = len(train_data)\n",
        "    x_1 = range(total_steps)\n",
        "\n",
        "    x_2 = x_1[::len(train_data) // len(val_data)]\n",
        "    #figure size setting\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    #plot train data\n",
        "    plt.plot(x_1, train_data, c='tab:red', label='train')\n",
        "    #plot val data\n",
        "    plt.plot(x_2, val_data, c='tab:cyan', label='val')\n",
        "\n",
        "    plt.ylim(0.0, 4.)\n",
        "    #title & label setting\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('Cross Entropy loss')\n",
        "    #show legend\n",
        "    plt.legend()\n",
        "    #show plot\n",
        "    plt.show()\n",
        "def plot_learning_curve_acc(acc_record, title=''):\n",
        "\n",
        "    #plot1 : train acc\n",
        "    #plot2 : val acc\n",
        "    train_data = np.array(acc_record['train'])\n",
        "    val_data = np.array(acc_record['val'])\n",
        "\n",
        "    #setting index range\n",
        "    x_1 = range(len(train_data))\n",
        "    x_2 = range(len(val_data))\n",
        "\n",
        "    #figure size setting\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    #plot train data\n",
        "    plt.plot(x_1, train_data, c='tab:red', label='train')\n",
        "    #plot val data\n",
        "    plt.plot(x_2, val_data, c='tab:cyan', label='val')\n",
        "\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    #title & label setting\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('Cross Entropy loss')\n",
        "    #show legend\n",
        "    plt.legend()\n",
        "    #show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting"
      ],
      "metadata": {
        "id": "iVSrN2791ndn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OIekqubSqTbN"
      },
      "outputs": [],
      "source": [
        "#create a dict of functions and path w.r.t. different mode\n",
        "data_info = {\n",
        "    \"train_origin\":{\"path\":\"/content/food-11/training\"},\n",
        "    \"train\":{\"path\":\"/content/food-11/training_unlabeled\"},\n",
        "    \"val\":{\"path\":\"/content/food-11/validation\"},\n",
        "    \"test\":{\"path\":\"/content/food-11/testing\"},\n",
        "\n",
        "    \"size\" :(64,64)\n",
        "}\n",
        "\n",
        "h_paras = {\n",
        "    # maximum number of epochs\n",
        "    'n_epochs': 20,\n",
        "    # mini-batch size for dataloader\n",
        "    'batch_size': 128,\n",
        "    # optimization algorithm (optimizer in torch.optim)\n",
        "    'optimizer': 'Adam',\n",
        "    # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "    'optim_hparas': {\n",
        "        # learning rate of Adam\n",
        "        'lr': 0.0003,\n",
        "        \"weight_decay\" : 1e-5\n",
        "    },\n",
        "    # your model will be saved here\n",
        "    'save_path': './model.pth',\n",
        "    'early_stop': 10,\n",
        "    'threshold': 0.8,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Main"
      ],
      "metadata": {
        "id": "NS5BmWvE1reX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099mNJXHqTbQ",
        "outputId": "ff0c88ff-b359-45db-dfae-385ad23b7929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "#install package with the following command\n",
        "#conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
        "#import pytorch and set CNN algorithm\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda'\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    else :\n",
        "        return 'cpu'\n",
        "device = get_device()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(torch.cuda.is_available())\n",
        "\n",
        "#set random variable\n",
        "myseed = 1\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct data loaders.\n",
        "train_loader = DataLoader(food_f(\"train_origin\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "valid_loader = DataLoader(food_f(\"val\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(food_f(\"test\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=False)"
      ],
      "metadata": {
        "id": "kMdIJZw_9ECo",
        "outputId": "37cc7961-cd36-4640-9c34-9efb01e2b1a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train_origin data: 19732\n",
            "Size of val data: 660\n",
            "Size of test data: 3347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start training\n",
        "model = Classifier()\n",
        "model_acc_record, model_loss_record = train_val_process(train_loader, valid_loader, model, h_paras, device, do_semi = True)"
      ],
      "metadata": {
        "id": "k6qTo2o79IY4",
        "outputId": "4c33a44f-33cc-40d1-c9a7-26a284a1bb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c63152b58a54f6a882a4b8e4af131a9",
            "a5ac19fb7183481ea44e197b83a77220",
            "5fb5e356405d431baebe6f0fda7128ed",
            "58832bec2d924518906b7d9d804d8105",
            "276a8625a7c145109bc09fe391738085",
            "f41599a0d65a408cb4e75abf5c1ed429",
            "1ffd30aa1815450c8f1120176121bb3c",
            "7b84979b2e0c4afcbb4b2c23b4b0688f",
            "7a30fab1ba204db786b422bc9836c2a9",
            "2e9bb897b73a4863baea9a3a0028c013",
            "83c425c2795549efb541b6a2ef9ba812"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/155 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c63152b58a54f6a882a4b8e4af131a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save prediction and plotting\n",
        "preds = test(test_loader, model, device)\n",
        "save_pred(preds, 'pred.csv')\n",
        "plot_learning_curve_loss(model_loss_record, title='deep model')\n",
        "plot_learning_curve_acc(model_acc_record, title='deep model')"
      ],
      "metadata": {
        "id": "aY1qeU4k9Rvg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c63152b58a54f6a882a4b8e4af131a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5ac19fb7183481ea44e197b83a77220",
              "IPY_MODEL_5fb5e356405d431baebe6f0fda7128ed",
              "IPY_MODEL_58832bec2d924518906b7d9d804d8105"
            ],
            "layout": "IPY_MODEL_276a8625a7c145109bc09fe391738085"
          }
        },
        "a5ac19fb7183481ea44e197b83a77220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41599a0d65a408cb4e75abf5c1ed429",
            "placeholder": "​",
            "style": "IPY_MODEL_1ffd30aa1815450c8f1120176121bb3c",
            "value": " 29%"
          }
        },
        "5fb5e356405d431baebe6f0fda7128ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b84979b2e0c4afcbb4b2c23b4b0688f",
            "max": 155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a30fab1ba204db786b422bc9836c2a9",
            "value": 45
          }
        },
        "58832bec2d924518906b7d9d804d8105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e9bb897b73a4863baea9a3a0028c013",
            "placeholder": "​",
            "style": "IPY_MODEL_83c425c2795549efb541b6a2ef9ba812",
            "value": " 45/155 [00:34&lt;01:29,  1.23it/s]"
          }
        },
        "276a8625a7c145109bc09fe391738085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41599a0d65a408cb4e75abf5c1ed429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffd30aa1815450c8f1120176121bb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b84979b2e0c4afcbb4b2c23b4b0688f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a30fab1ba204db786b422bc9836c2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e9bb897b73a4863baea9a3a0028c013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c425c2795549efb541b6a2ef9ba812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}