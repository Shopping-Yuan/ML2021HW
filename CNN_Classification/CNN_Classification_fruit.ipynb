{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shopping-Yuan/ML_Project/blob/Shopping_vscode_branch/CNN_Classification/CNN_Classification_fruit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Data"
      ],
      "metadata": {
        "id": "I_7n-RiO2czn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDo4n9HGqTbH",
        "outputId": "2136f1ed-f0c4-4845-bd37-75fd025c91b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  megatools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 207 kB of archives.\n",
            "After this operation, 898 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 megatools amd64 1.10.3-1build1 [207 kB]\n",
            "Fetched 207 kB in 0s (1,304 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package megatools.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../megatools_1.10.3-1build1_amd64.deb ...\n",
            "Unpacking megatools (1.10.3-1build1) ...\n",
            "Setting up megatools (1.10.3-1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[0KDownloaded food-11.zip\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install megatools\n",
        "!megadl \"https://mega.nz/#!zt1TTIhK!ZuMbg5ZjGWzWX1I6nEUbfjMZgCmAgeqJlwDkqdIryfg\"\n",
        "# Unzip the dataset.\n",
        "# This may take some time.\n",
        "!unzip -q /content/food-11.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare Dataset"
      ],
      "metadata": {
        "id": "kza4JCYB4DDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6RhmTvYcqTbL"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import v2\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from torch.utils.data import ConcatDataset\n",
        "from PIL import Image\n",
        "def get_tfm(data_info):\n",
        "    tfm = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(data_info[\"size\"]),\n",
        "    ])\n",
        "    return tfm\n",
        "def get_tfm_flip(data_info):\n",
        "    tfm_flip = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Resize(data_info[\"size\"]),\n",
        "    v2.RandomHorizontalFlip(p=1),\n",
        "    ])\n",
        "    return tfm_flip\n",
        "def food_f(mode,data_info):\n",
        "    dataset = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm(data_info))\n",
        "    if mode in [\"train_origin\"]:\n",
        "      dataset_flip = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm_flip(data_info))\n",
        "      dataset = ConcatDataset([dataset,dataset_flip])\n",
        "    print('Size of {} data: {}'.format(mode,len(list(dataset))))\n",
        "    return dataset\n",
        "\n",
        "# This part is for semi- supervised learning\n",
        "class Label_Changable_dsf(DatasetFolder):\n",
        "    def __init__(self,root,loader,extensions,transform):\n",
        "            super().__init__(root, loader, extensions , transform,)\n",
        "    def change_targets(self ,correct_target):\n",
        "      for i , t in enumerate(correct_target):\n",
        "        self.targets[i] = t\n",
        "\n",
        "def food_semi_f(mode,data_info,DatasetFolder):\n",
        "    dataset = DatasetFolder(data_info[mode][\"path\"], \\\n",
        "          loader=lambda x: Image.open(x), \\\n",
        "          extensions=\"jpg\", transform=get_tfm(data_info))\n",
        "\n",
        "    print('Size of data for semi-supervised-learning: {}'.format(len(list(dataset))))\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x_uSxJ1bqTbO"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "        # The arguments for commonly used modules:\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
        "\n",
        "        # input image size: [3, 32, 32]\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(2, 2, 0),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool2d(4, 4, 0),\n",
        "        )\n",
        "        self.flat_layer = nn.Flatten()\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(int(256 * data_info[\"size\"][0]/16 * data_info[\"size\"][1]/16), 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, 11)\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "    def forward(self, x):\n",
        "        # input (x): [batch_size, 3, 128, 128]\n",
        "        # output: [batch_size, 11]\n",
        "\n",
        "        # Extract features by convolutional layers.\n",
        "        x = self.cnn_layers(x)\n",
        "\n",
        "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
        "        x = self.flat_layer(x)\n",
        "\n",
        "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "    def cal_loss(self, pred, target):\n",
        "        return self.criterion(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QOWwbIscgbm7"
      },
      "outputs": [],
      "source": [
        "def get_pseudo_labels(model, training_loader ,h_paras):\n",
        "\n",
        "    softmax = nn.Softmax(dim=-1)\n",
        "    model.eval()\n",
        "    # Construct a data loader.\n",
        "    semi_datasetfolder = food_semi_f(\"train\",data_info,Label_Changable_dsf)\n",
        "    semi_dataset_loader = \\\n",
        "    DataLoader(semi_datasetfolder, \\\n",
        "               batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "    correct_label = []\n",
        "    correct_index = []\n",
        "\n",
        "    for batch_num , batch in enumerate(tqdm(semi_dataset_loader)):\n",
        "        img = batch[0]\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            img_d = img.to(device)\n",
        "            prep = model(img_d)\n",
        "        predicts = softmax(prep)\n",
        "        max_prob , max_column_index = predicts.max(dim = -1)\n",
        "\n",
        "        max_prob_list = max_prob.tolist()\n",
        "        max_column_index_list = max_column_index.tolist()\n",
        "        correct_label += [max_column_index_list[i]  \\\n",
        "                          for i in range(len(max_column_index_list)) if max_prob_list[i] > h_paras[\"threshold\"]]\n",
        "        correct_index += [(i + batch_num * h_paras[\"batch_size\"]) \\\n",
        "                          for i in range(len(max_column_index_list)) if max_prob_list[i] > h_paras[\"threshold\"]]\n",
        "\n",
        "    if len(correct_index)>0:\n",
        "      semi_datasetfolder.change_targets(correct_label)\n",
        "      add_train_set = Subset(semi_datasetfolder,correct_index)\n",
        "\n",
        "      new_train_set = ConcatDataset([food_f(\"train_origin\",data_info),add_train_set])\n",
        "      training_loader = DataLoader(new_train_set, batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "\n",
        "      #build a dic to print the number of label of each class added to add_train_set\n",
        "      label_dict = {}\n",
        "      label_set = set(correct_label)\n",
        "      for i in label_set:\n",
        "        label_dict[i] = correct_label.count(i)\n",
        "      print(\"add total {} datas to training dataset, each label numbers as follow {}\".format(len(correct_index),label_dict))\n",
        "\n",
        "    return training_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QgdT2JdtqTbP"
      },
      "outputs": [],
      "source": [
        "def train(train_loader,model_d,optimizer,device):\n",
        "    # set model to training mode\n",
        "    model_d.train()\n",
        "    total_correct_number = 0\n",
        "    train_loss_list = []\n",
        "#    print(type(train_loader))\n",
        "    # iterate through the dataloader\n",
        "    for data , label in tqdm(train_loader):\n",
        "      # move data to device (cpu/cuda)\n",
        "      data_d , label_d = data.to(device), label.to(device)\n",
        "      # forward pass (compute output tensor)\n",
        "      pred = (model_d(data_d))\n",
        "      # get the index of the class with the highest probability\n",
        "      max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "      correct_number = (max_prob_indexs.cpu() == label_d.cpu()).sum().item()\n",
        "#      print(correct_number)\n",
        "      total_correct_number += correct_number\n",
        "      # compute loss\n",
        "      loss = model_d.cal_loss(pred , label_d)\n",
        "      # compute gradient (backpropagation)\n",
        "      loss.backward()\n",
        "      # Clip the gradient norms for stable training.\n",
        "      nn.utils.clip_grad_norm_(model_d.parameters(), max_norm=10)\n",
        "      # update model with optimizer\n",
        "      optimizer.step()\n",
        "      # set optimizer gradient to zero\n",
        "      optimizer.zero_grad()\n",
        "      train_loss_list.append(loss.detach().cpu().item())\n",
        "    acc = total_correct_number/len(train_loader.dataset)\n",
        "#    print(acc , train_loss_list)\n",
        "    return acc , train_loss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NEn8YBfVqTbP"
      },
      "outputs": [],
      "source": [
        "def val(val_loader,model_d,device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "    total_correct_number = 0\n",
        "    total_loss = 0\n",
        "    # iterate through the dataloader\n",
        "    for data , label in tqdm(val_loader):\n",
        "    # move data to device (cpu/cuda)\n",
        "      data_d, label_d = data.to(device), label.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = model_d(data_d)\n",
        "        # get the index of the class with the highest probability\n",
        "        max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "        total_correct_number += (max_prob_indexs.cpu() == label_d.cpu()).sum().item()\n",
        "        # compute loss\n",
        "        mse_loss = model_d.cal_loss(pred, label_d)\n",
        "      # accumulate loss\n",
        "      batch_size = len(data_d)\n",
        "      total_loss += mse_loss.detach().cpu().item() * batch_size\n",
        "\n",
        "    # compute averaged loss\n",
        "    totol_size = len(val_loader.dataset)\n",
        "    acc = total_correct_number/totol_size\n",
        "    avg_loss =  total_loss/totol_size\n",
        "    return acc, avg_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E5PRQVp6qTbP"
      },
      "outputs": [],
      "source": [
        "def train_val_process(training_loader, validation_loader, model, h_paras, device , do_semi = False):\n",
        "    # Initialize a model, and put it on the device specified.\n",
        "    model_d = model.to(device)\n",
        "    model_d.device = device\n",
        "    optimizer = torch.optim.Adam(model_d.parameters(), **h_paras[\"optim_hparas\"])\n",
        "\n",
        "    # The number of training epochs.\n",
        "    n_epochs = h_paras[\"n_epochs\"]\n",
        "\n",
        "    # record training accuracy\n",
        "    acc_record = {'train': [], \"val\": []}\n",
        "    # record training loss\n",
        "    loss_record = {'train': [], \"val\": []}\n",
        "\n",
        "    # accuracy paras\n",
        "    best_acc = 0\n",
        "    # early-stoping paras\n",
        "    early_stop_cnt = 0\n",
        "\n",
        "\n",
        "    #for semi-supervised learning\n",
        "    if do_semi == True:\n",
        "      data_origin = np.array([])\n",
        "      label_origin = np.array([])\n",
        "      for data , label in tqdm(training_loader):\n",
        "        if len(data_origin) ==0:\n",
        "          data_origin = data.numpy()\n",
        "          label_origin = np.array(label)\n",
        "        else:\n",
        "          data_origin = np.concatenate((data_origin, data.numpy()), axis=0)\n",
        "          label_origin = np.concatenate((label_origin, np.array(label)), axis=0)\n",
        "\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # ---------- Training ----------\n",
        "        train_acc , train_loss_list = train(training_loader,model_d,optimizer,device)\n",
        "        # save accuracy to acc_record['train']\n",
        "        acc_record['train'].append(train_acc)\n",
        "      # save loss to loss_record['train']\n",
        "        loss_record['train'].append(train_loss_list)\n",
        "\n",
        "        # ---------- Do semi-supervised learning ----------\n",
        "        if ((do_semi == True) & (early_stop_cnt >= 1 )):\n",
        "\n",
        "          training_loader = get_pseudo_labels(model_d, training_loader , h_paras)\n",
        "\n",
        "\n",
        "        # ---------- Validation ----------\n",
        "        val_acc , val_loss = val(validation_loader,model_d,device)\n",
        "        # Print the information.\n",
        "        acc_record[\"val\"].append(val_acc)\n",
        "        # save loss to loss_record[\"val\"]\n",
        "        loss_record[\"val\"].append(val_loss)\n",
        "\n",
        "        print(' model epoch = {:4d}, train_loss = {:.4f} , val_loss = {:.4f})'\\\n",
        "        .format(epoch+1 , train_loss_list[-1] , val_loss))\n",
        "        print('train set accuracy = {:.3f}'.format(train_acc))\n",
        "\n",
        "        # ---------- Early Stop ----------\n",
        "        if val_acc > best_acc:\n",
        "          best_acc = val_acc\n",
        "          torch.save(model.state_dict(), h_paras[\"save_path\"])\n",
        "          print('saving model with acc {:.3f}'.format(best_acc))\n",
        "          early_stop_cnt = 0\n",
        "        else:\n",
        "          early_stop_cnt += 1\n",
        "        # Check early stop criteria\n",
        "        if early_stop_cnt > h_paras['early_stop']:\n",
        "            # Stop training if your model stops improving\n",
        "            # for \"h_paras['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    return acc_record , loss_record\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3r2xj_0FqTbQ"
      },
      "outputs": [],
      "source": [
        "def test(test_loader, model_d, device):\n",
        "    # set model to evalutation mode\n",
        "    model_d.eval()\n",
        "    pred_index = []\n",
        "    pred_loss = []\n",
        "    # iterate through the dataloader\n",
        "    for imgs, incorrect_labels in tqdm(test_loader):\n",
        "      # move data to device (cpu/cuda)\n",
        "      imgs_d = imgs.to(device)\n",
        "      # disable gradient calculation\n",
        "      with torch.no_grad():\n",
        "        # forward pass (compute output)\n",
        "        pred = model_d(imgs_d)\n",
        "        # get the index of the class with the highest probability\n",
        "        max_prob_values, max_prob_indexs = torch.max(pred, dim = 1)\n",
        "        # collect prediction\n",
        "        pred_index += (max_prob_indexs.tolist())\n",
        "        pred_loss += (pred.mean(dim = 1).tolist())\n",
        "    # concatenate all predictions and convert to a numpy array\n",
        "    np_pred_index , np_pred_loss = np.array(pred_index), np.array(pred_loss)\n",
        "    pred_dict = { \"pred_index\" : np_pred_index , \"pred_loss\" : np_pred_loss }\n",
        "    return pred_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "P50yBDcnqTbQ"
      },
      "outputs": [],
      "source": [
        "def save_pred(preds, file_path):\n",
        "    import pandas as pd\n",
        "    print('Saving results to {}'.format(file_path))\n",
        "    df = pd.DataFrame(preds,columns=[\"tested_positive\"])\n",
        "    df.to_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Visualization"
      ],
      "metadata": {
        "id": "QfU7yI5Z1x2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kWsS_dCRT5Fl"
      },
      "outputs": [],
      "source": [
        "#%conda install -c conda-forge matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "def plot_learning_curve_loss(loss_record, title=''):\n",
        "\n",
        "    #plot1 : train loss\n",
        "    #plot2 : val loss\n",
        "    train_data = []\n",
        "    t = np.array(loss_record['train'])\n",
        "    for i in t:\n",
        "      train_data.append(statistics.mean(i))\n",
        "    val_data = np.array(loss_record['val'])\n",
        "\n",
        "    #setting index range\n",
        "    total_steps = len(train_data)\n",
        "    x_1 = range(total_steps)\n",
        "\n",
        "    x_2 = x_1[::len(train_data) // len(val_data)]\n",
        "    #figure size setting\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    #plot train data\n",
        "    plt.plot(x_1, train_data, c='tab:red', label='train')\n",
        "    #plot val data\n",
        "    plt.plot(x_2, val_data, c='tab:cyan', label='val')\n",
        "\n",
        "    plt.ylim(0.0, 4.)\n",
        "    #title & label setting\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('Cross Entropy loss')\n",
        "    #show legend\n",
        "    plt.legend()\n",
        "    #show plot\n",
        "    plt.show()\n",
        "def plot_learning_curve_acc(acc_record, title=''):\n",
        "\n",
        "    #plot1 : train acc\n",
        "    #plot2 : val acc\n",
        "    train_data = np.array(acc_record['train'])\n",
        "    val_data = np.array(acc_record['val'])\n",
        "\n",
        "    #setting index range\n",
        "    x_1 = range(len(train_data))\n",
        "    x_2 = range(len(val_data))\n",
        "\n",
        "    #figure size setting\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    #plot train data\n",
        "    plt.plot(x_1, train_data, c='tab:red', label='train')\n",
        "    #plot val data\n",
        "    plt.plot(x_2, val_data, c='tab:cyan', label='val')\n",
        "\n",
        "    plt.ylim(0.0, 1.0)\n",
        "    #title & label setting\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('Cross Entropy loss')\n",
        "    #show legend\n",
        "    plt.legend()\n",
        "    #show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting"
      ],
      "metadata": {
        "id": "iVSrN2791ndn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OIekqubSqTbN"
      },
      "outputs": [],
      "source": [
        "#create a dict of functions and path w.r.t. different mode\n",
        "data_info = {\n",
        "    \"train_origin\":{\"path\":\"Data_preparing\\\\mysql_operation\\\\dataset_constuction\\\\food-11\\\\training\\\\labeled\"},\n",
        "    \"train\":{\"path\":\"Data_preparing\\\\mysql_operation\\\\dataset_constuction\\\\food-11\\\\training\\\\unlabeled\"},\n",
        "    \"val\":{\"path\":\"Data_preparing\\\\mysql_operation\\\\dataset_constuction\\\\food-11\\\\validation\"},\n",
        "    \"size\" :(64,64)\n",
        "}\n",
        "\n",
        "h_paras = {\n",
        "    # maximum number of epochs\n",
        "    'n_epochs': 20,\n",
        "    # mini-batch size for dataloader\n",
        "    'batch_size': 128,\n",
        "    # optimization algorithm (optimizer in torch.optim)\n",
        "    'optimizer': 'Adam',\n",
        "    # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "    'optim_hparas': {\n",
        "        # learning rate of Adam\n",
        "        'lr': 0.0003,\n",
        "        \"weight_decay\" : 1e-5\n",
        "    },\n",
        "    # your model will be saved here\n",
        "    'save_path': './model.pth',\n",
        "    'early_stop': 10,\n",
        "    'threshold': 0.8,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Main Function"
      ],
      "metadata": {
        "id": "NS5BmWvE1reX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "099mNJXHqTbQ",
        "outputId": "5039ce0f-5952-4a1c-fa5b-b3ee553f0f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data_preparing\\\\mysql_operation\\\\dataset_constuction\\\\food-11\\\\training\\\\labeled'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5f60680f337e>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Construct data loaders.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_origin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_paras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_paras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_paras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-8805d5e86f3e>\u001b[0m in \u001b[0;36mfood_f\u001b[0;34m(mode, data_info)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtfm_flip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfood_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     dataset = DatasetFolder(data_info[mode][\"path\"], \\\n\u001b[0m\u001b[1;32m     22\u001b[0m           \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m           extensions=\"jpg\", transform=get_tfm(data_info))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_preparing\\\\mysql_operation\\\\dataset_constuction\\\\food-11\\\\training\\\\labeled'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "#install package with the following command\n",
        "#conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia\n",
        "#import pytorch and set CNN algorithm\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda'\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    else :\n",
        "        return 'cpu'\n",
        "device = get_device()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(torch.cuda.is_available())\n",
        "\n",
        "#set random variable\n",
        "myseed = 1\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)\n",
        "\n",
        "# Construct data loaders.\n",
        "train_loader = DataLoader(food_f(\"train_origin\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "valid_loader = DataLoader(food_f(\"val\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(food_f(\"test\",data_info), batch_size=h_paras[\"batch_size\"], shuffle=False)\n",
        "model = Classifier()\n",
        "model_acc_record, model_loss_record = train_val_process(train_loader, valid_loader, data_info, model, h_paras, device, do_semi = True)\n",
        "preds = test(test_loader, model, device)\n",
        "save_pred(preds, 'pred.csv')\n",
        "plot_learning_curve_loss(model_loss_record, title='deep model')\n",
        "plot_learning_curve_acc(model_acc_record, title='deep model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}